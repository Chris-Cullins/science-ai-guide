{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Agentic AI for Scientists","text":"<p>This guide is for scientists who are not professional software developers, but who do write code, analyze data, and produce papers.</p> <p>The core idea: instead of using an AI model like a chat box, you use an agent that can take actions (read/write files, run commands, iterate) with you supervising.</p>"},{"location":"#recommended-reading-path","title":"Recommended reading path","text":"<p>If you are new:</p> <ol> <li><code>docs/overview.md</code></li> <li><code>docs/why-agentic.md</code></li> <li><code>docs/tooling.md</code></li> <li><code>docs/first-hour.md</code></li> <li><code>docs/workflows.md</code></li> <li><code>docs/verification.md</code></li> </ol> <p>If you are leading a lab:</p> <ol> <li><code>docs/lab-rollout.md</code></li> <li><code>docs/lab-policy-template.md</code></li> <li><code>docs/reproducibility.md</code></li> <li><code>docs/safety-privacy.md</code></li> </ol>"},{"location":"#where-to-start","title":"Where to start","text":"<ol> <li>Install and try Claude Code on a small, non-sensitive project: <code>docs/claude-code.md</code></li> <li>Learn the core workflow loop (plan -&gt; do -&gt; verify): <code>docs/workflows.md</code></li> <li>Set guardrails for privacy, safety, and reproducibility: <code>docs/safety-privacy.md</code></li> <li>Copy/paste prompt templates you can actually use: <code>docs/prompts.md</code></li> <li>Understand costs and avoid surprises: <code>docs/pricing.md</code></li> </ol> <p>If you are onboarding a lab:</p> <ul> <li>First hour checklist: <code>docs/first-hour.md</code></li> <li>Lab rollout: <code>docs/lab-rollout.md</code></li> <li>Disclosure/attribution: <code>docs/disclosure.md</code></li> <li>Reproducibility habits: <code>docs/reproducibility.md</code></li> </ul>"},{"location":"#a-quick-mental-model","title":"A quick mental model","text":"<ul> <li>Chat-only AI: you ask questions; you copy/paste results.</li> <li>Agentic AI: you give a task; it edits files and runs commands; you review diffs and outputs.</li> </ul> <p>If you can supervise work and verify results, agentic tools can compress days of \"yak shaving\" (setup, plumbing, debugging, refactors) into hours.</p>"},{"location":"ai-fluency/","title":"AI Fluency (A 1-Week Ramp)","text":"<p>The biggest gains come after you build a few habits.</p>"},{"location":"ai-fluency/#day-1-quick-win","title":"Day 1: Quick win","text":"<ul> <li>Do the \"First Hour\" task: <code>docs/first-hour.md</code></li> </ul>"},{"location":"ai-fluency/#day-2-make-verification-cheap","title":"Day 2: Make verification cheap","text":"<ul> <li>Add a <code>make test</code> and a <code>make run</code>.</li> <li>Add one tiny sanity check.</li> </ul>"},{"location":"ai-fluency/#day-3-convert-one-notebook","title":"Day 3: Convert one notebook","text":"<ul> <li>Turn one notebook into a script + config.</li> <li>Require identical outputs.</li> </ul>"},{"location":"ai-fluency/#day-4-refactor-for-a-new-lab-member","title":"Day 4: Refactor for a new lab member","text":"<ul> <li>Improve README.</li> <li>Pin dependencies.</li> <li>One-command run.</li> </ul>"},{"location":"ai-fluency/#day-5-literature-workflow","title":"Day 5: Literature workflow","text":"<ul> <li>Summarize 3 papers you provide.</li> <li>Produce a comparison table of assumptions and failure modes.</li> </ul>"},{"location":"ai-fluency/#day-6-writing-workflow","title":"Day 6: Writing workflow","text":"<ul> <li>Use AI for clarity-only editing.</li> <li>Verify every claim.</li> </ul>"},{"location":"ai-fluency/#day-7-make-a-lab-policy","title":"Day 7: Make a lab policy","text":"<ul> <li>Fill in: <code>docs/lab-policy-template.md</code></li> </ul> <p>If you do just this week, you will be far ahead of most people.</p>"},{"location":"checklists/","title":"Checklists","text":"<p>These are the habits that make agentic AI safe and useful.</p>"},{"location":"checklists/#pre-flight-before-you-delegate","title":"Pre-flight (before you delegate)","text":"<ul> <li>Is the data allowed to be shared with this tool?</li> <li>Is the task small enough to review?</li> <li>Do you have a definition of done?</li> <li>Do you have a verification command or sanity check?</li> <li>Is the project under version control?</li> </ul>"},{"location":"checklists/#during-flight-while-the-agent-works","title":"During flight (while the agent works)","text":"<ul> <li>Ask for a plan before large edits.</li> <li>Keep changes in small steps.</li> <li>Require it to explain assumptions and units.</li> <li>Stop if you do not understand what changed.</li> </ul>"},{"location":"checklists/#post-flight-before-you-trust-results","title":"Post-flight (before you trust results)","text":"<ul> <li>Review diffs.</li> <li>Run tests / scripts.</li> <li>Check units, limiting cases, and basic invariants.</li> <li>Verify citations manually.</li> <li>Record how to reproduce the result.</li> </ul>"},{"location":"checklists/#red-flags","title":"Red flags","text":"<ul> <li>\"It should work\" without running anything</li> <li>new citations you did not provide</li> <li>big refactors without tests</li> <li>plots with missing units or unclear preprocessing</li> </ul>"},{"location":"claude-code/","title":"Claude Code (Recommended)","text":"<p>Claude Code is an agentic coding tool that runs in your terminal and can edit files, run commands, and iterate.</p>"},{"location":"claude-code/#what-you-need","title":"What you need","text":"<ul> <li>A Claude subscription (Pro/Max/Team/Enterprise) or a Claude Console account</li> </ul> <p>Official docs: - https://docs.anthropic.com/en/docs/claude-code/overview</p>"},{"location":"claude-code/#install","title":"Install","text":"<p>From the official instructions (macOS/Linux/WSL):</p> <pre><code>curl -fsSL https://claude.ai/install.sh | bash\n</code></pre> <p>Then:</p> <pre><code>cd your-project\nclaude\n</code></pre>"},{"location":"claude-code/#how-scientists-should-use-it-default-guardrails","title":"How scientists should use it (default guardrails)","text":"<ul> <li>Start with a throwaway repo or a copy of your project.</li> <li>Tell it to propose a plan before editing.</li> <li>Require it to run tests / a minimal validation script.</li> <li>Review diffs for every change.</li> </ul>"},{"location":"claude-code/#the-30-minute-starter-task","title":"The 30-minute starter task","text":"<p>Pick one:</p> <ul> <li>\"Add a <code>Makefile</code> (or <code>justfile</code>) that runs <code>pytest</code>, <code>ruff</code>, and a quick smoke test.\"</li> <li>\"Turn my one-off analysis script into a reproducible pipeline with a config file and pinned dependencies.\"</li> <li>\"Write a small CLI that loads my CSV and produces the exact plot I need for Figure 2.\"</li> </ul>"},{"location":"cli-basics/","title":"Terminal Basics (For Non-Developers)","text":"<p>You do not need to become a software engineer. But agentic tools often live in the terminal.</p>"},{"location":"cli-basics/#three-commands-you-should-know","title":"Three commands you should know","text":"<pre><code>pwd   # where am I?\nls    # what files are here?\ncd .. # go up one folder\n</code></pre>"},{"location":"cli-basics/#paths","title":"Paths","text":"<ul> <li>A \"path\" is just a file location.</li> <li><code>.</code> means \"current folder\".</li> <li><code>..</code> means \"parent folder\".</li> </ul>"},{"location":"cli-basics/#a-safe-habit","title":"A safe habit","text":"<p>Before you run any command you do not recognize:</p> <ol> <li>ask the agent what it will do</li> <li>run it on a copy of the project first</li> </ol>"},{"location":"cli-basics/#common-research-commands","title":"Common research commands","text":"<pre><code>python3 script.py\npython3 -m venv .venv\nsource .venv/bin/activate\npip install -r requirements.txt\npytest\n</code></pre> <p>If those look unfamiliar, that is normal. You only need a small subset.</p>"},{"location":"coding/","title":"Coding and Refactors","text":"<p>Agentic AI is especially strong at:</p> <ul> <li>refactoring</li> <li>adding tests</li> <li>fixing errors</li> <li>wiring up CLIs</li> </ul>"},{"location":"coding/#your-job","title":"Your job","text":"<ul> <li>define what must not change (scientific assumptions)</li> <li>define what must improve (reproducibility, readability, speed)</li> <li>require verification</li> </ul>"},{"location":"coding/#a-safe-refactor-prompt","title":"A safe refactor prompt","text":"<pre><code>Refactor this project for readability and reproducibility.\n\nConstraints:\n- Do not change scientific logic without asking.\n- Keep outputs identical unless you explain why.\n\nDefinition of done:\n- `make test` passes\n- `make figures` regenerates the main figure(s)\n</code></pre>"},{"location":"coding/#when-to-stop","title":"When to stop","text":"<p>If you cannot explain what changed, you are moving too fast.</p>"},{"location":"context/","title":"Why This Guide Exists","text":"<p>This guide started from a YouTube video (https://www.youtube.com/watch?v=PctlBxRh0p4).</p> <p>We intentionally do not store the full transcript in this public repo.</p> <p>In that transcript, a scientist describes attending an internal meeting at the Institute for Advanced Study focused on how \"agentic AI\" tools (named examples: Claude and Cursor) are changing research work. Several themes show up repeatedly:</p> <ul> <li>The tools are now strong enough at coding (and often math/reasoning) to materially change day-to-day research workflows.</li> <li>Getting value requires AI fluency: learning how to define tasks, break problems down, and iterate.</li> <li>Human oversight is still necessary (diff review, cross-checks, validation), but the human role shifts toward \"manager / verifier.\"</li> <li>Privacy, ethics, and cost are real concerns; people will make different tradeoffs.</li> <li>Skill atrophy is a legitimate risk; you need deliberate habits to stay sharp.</li> </ul> <p>This guide tries to turn those themes into concrete, low-friction steps a working scientist can apply.</p>"},{"location":"cost-control/","title":"Cost Control (Avoid Surprises)","text":"<p>Costs can creep up, especially if you use multiple tools or run big jobs.</p>"},{"location":"cost-control/#the-two-main-cost-drivers","title":"The two main cost drivers","text":"<ol> <li>Volume: how many requests you make</li> <li>Size: how much context you feed each request (tokens)</li> </ol>"},{"location":"cost-control/#practical-ways-to-reduce-cost","title":"Practical ways to reduce cost","text":"<ul> <li>Keep tasks small and incremental.</li> <li>Reuse instructions instead of repeating long context.</li> <li>Provide small samples instead of full datasets.</li> <li>Ask for a plan before expensive execution.</li> </ul>"},{"location":"cost-control/#a-good-default-tier-your-work","title":"A good default: tier your work","text":"<ul> <li>Cheap model for drafting/refactors</li> <li>Strong model for final reasoning and tricky debugging</li> </ul>"},{"location":"cost-control/#institutional-budgeting","title":"Institutional budgeting","text":"<p>If your lab is paying:</p> <ul> <li>pick a single primary tool</li> <li>track usage monthly</li> <li>decide in advance when to approve upgrades</li> </ul> <p>See also: <code>docs/pricing.md</code></p>"},{"location":"data-analysis/","title":"Data Analysis (AI-Assisted)","text":"<p>AI can help you write analysis code quickly. The risk is silent wrongness.</p>"},{"location":"data-analysis/#what-to-insist-on","title":"What to insist on","text":"<ul> <li>a minimal reproducible script</li> <li>a config file for parameters</li> <li>sanity checks on shapes, units, and ranges</li> <li>deterministic outputs (seeded randomness)</li> </ul>"},{"location":"data-analysis/#typical-wins","title":"Typical wins","text":"<ul> <li>cleaning up messy scripts</li> <li>turning notebooks into pipelines</li> <li>adding tests and validations</li> <li>speeding up plotting and reporting</li> </ul>"},{"location":"data-analysis/#typical-traps","title":"Typical traps","text":"<ul> <li>incorrect joins / merges</li> <li>wrong filtering</li> <li>subtle unit conversions</li> <li>plotting post-processed data without recording steps</li> </ul>"},{"location":"data-analysis/#a-practical-definition-of-done","title":"A practical definition of done","text":"<ul> <li>\"Fresh clone -&gt; install deps -&gt; run one command -&gt; produces figure/table\"</li> </ul>"},{"location":"disclosure/","title":"Disclosure and Attribution","text":"<p>Norms are evolving. Your field, journal, and institution may have specific policies.</p>"},{"location":"disclosure/#safe-default","title":"Safe default","text":"<ul> <li>Disclose meaningful AI assistance (especially if it generated text, code, or figures).</li> <li>Do not list an AI system as an author.</li> <li>Do not allow AI to invent citations; verify every reference.</li> </ul>"},{"location":"disclosure/#suggested-disclosure-language-adapt","title":"Suggested disclosure language (adapt)","text":"<pre><code>We used AI-assisted tools to help with code refactoring and/or drafting text. All scientific claims, analyses, and final wording were reviewed and verified by the authors.\n</code></pre> <p>If a journal has a specific required statement, use theirs.</p>"},{"location":"faq/","title":"FAQ","text":""},{"location":"faq/#is-this-going-to-replace-scientists","title":"Is this going to replace scientists?","text":"<p>No one knows. But it is already changing the day-to-day work.</p> <p>The most robust stance is: learn to use it, keep your verification habits strong, and keep your scientific judgment sharp.</p>"},{"location":"faq/#will-i-lose-my-skills","title":"Will I lose my skills?","text":"<p>Skill atrophy is real if you stop thinking.</p> <p>Mitigations:</p> <ul> <li>keep doing some work \"by hand\" (derivations, small scripts)</li> <li>require the agent to explain reasoning</li> <li>use it to teach you, not just to produce output</li> </ul>"},{"location":"faq/#can-i-trust-citations","title":"Can I trust citations?","text":"<p>Not by default.</p> <p>If you did not provide sources, assume citations may be invented.</p>"},{"location":"faq/#should-i-give-it-access-to-my-emailfiles","title":"Should I give it access to my email/files?","text":"<p>Default recommendation: no.</p> <p>Only connect sensitive systems if you understand the permissions and your institution allows it.</p>"},{"location":"figures/","title":"Figures and Tables","text":"<p>Figures are where incorrect code becomes persuasive.</p>"},{"location":"figures/#the-standard","title":"The standard","text":"<ul> <li>One command regenerates figures.</li> <li>Every figure has a clear source script.</li> <li>Inputs and parameters are recorded.</li> </ul>"},{"location":"figures/#a-useful-pattern","title":"A useful pattern","text":"<ul> <li><code>scripts/make_fig_2.py</code></li> <li><code>configs/fig_2.yaml</code></li> <li><code>results/fig_2.png</code></li> </ul>"},{"location":"figures/#verification-checks","title":"Verification checks","text":"<ul> <li>plot a small random subsample to ensure it behaves</li> <li>include axis labels and units</li> <li>store intermediate summaries (counts, means) for sanity</li> </ul>"},{"location":"first-hour/","title":"First Hour: A Safe, Useful Win","text":"<p>Goal: get one small, real task done with an agentic tool, while keeping risk low.</p>"},{"location":"first-hour/#setup","title":"Setup","text":"<ul> <li>Use a non-sensitive project (or a copy).</li> <li>Make sure it's under version control.</li> </ul>"},{"location":"first-hour/#pick-one-task-30-60-minutes","title":"Pick one task (30-60 minutes)","text":"<ol> <li>\"Add a <code>README.md</code> that explains setup + a one-command run.\"</li> <li>\"Add a minimal test that checks the main function runs on a tiny sample.\"</li> <li>\"Make a <code>Makefile</code> (or <code>justfile</code>) with <code>make format</code>, <code>make test</code>, <code>make run</code>.\"</li> </ol>"},{"location":"first-hour/#the-prompt","title":"The prompt","text":"<pre><code>Act like a careful research software engineer.\n\nBefore editing anything:\n- summarize what you think this project does\n- propose a short plan\n\nRules:\n- keep changes small and reviewable\n- run a quick verification step\n- explain how to undo changes\n\nTask:\n&lt;paste the task you chose&gt;\n</code></pre>"},{"location":"first-hour/#what-success-looks-like","title":"What \"success\" looks like","text":"<ul> <li>You can point to a diff and say what changed.</li> <li>You can run one command and see it work.</li> <li>You didn't paste any sensitive data.</li> </ul>"},{"location":"git-basics/","title":"Git Basics (So You Can Review and Undo)","text":"<p>Git is the safety harness for agentic AI.</p>"},{"location":"git-basics/#the-mental-model","title":"The mental model","text":"<ul> <li>A repo is a folder where git tracks changes.</li> <li>A commit is a snapshot.</li> <li>A diff shows what changed.</li> </ul>"},{"location":"git-basics/#minimal-commands","title":"Minimal commands","text":"<pre><code>git status\ngit diff\ngit add -A\ngit commit -m \"message\"\n</code></pre>"},{"location":"git-basics/#why-scientists-should-care","title":"Why scientists should care","text":"<ul> <li>You can always see what changed.</li> <li>You can undo mistakes.</li> <li>You can reproduce exactly what produced a figure.</li> </ul>"},{"location":"git-basics/#recommended-workflow","title":"Recommended workflow","text":"<ul> <li>Make small commits.</li> <li>Keep analysis outputs out of the repo unless needed.</li> <li>Use branches for experiments.</li> </ul>"},{"location":"how-it-works/","title":"How Agentic AI Works (Mental Model)","text":"<p>You do not need deep ML knowledge. But you do need a usable mental model.</p>"},{"location":"how-it-works/#chat-model-vs-agent","title":"Chat model vs agent","text":"<ul> <li>Chat model: generates text.</li> <li>Agent: uses a chat model plus tools (file edits, commands, web, etc.) to do multi-step work.</li> </ul>"},{"location":"how-it-works/#the-agent-loop","title":"The agent loop","text":"<p>Most agentic systems follow a loop like:</p> <ol> <li>Read context (files, your instructions)</li> <li>Plan</li> <li>Take an action (edit file, run command)</li> <li>Observe the result (diffs, errors, output)</li> <li>Iterate until \"done\"</li> </ol>"},{"location":"how-it-works/#why-errors-happen","title":"Why errors happen","text":"<p>Common causes:</p> <ul> <li>Missing context (the agent did not see the relevant file)</li> <li>Ambiguous goal (no definition of done)</li> <li>Overconfident guesses (hallucinations)</li> <li>Hidden assumptions (units, conventions)</li> </ul>"},{"location":"how-it-works/#context-window-and-tokens","title":"Context window and tokens","text":"<ul> <li>Models do not see your whole computer.</li> <li>They only see what is placed in their context.</li> <li>Longer context generally costs more and can be noisier.</li> </ul>"},{"location":"how-it-works/#what-makes-agentic-ai-powerful","title":"What makes agentic AI powerful","text":"<ul> <li>It can try something, see it fail, and fix it.</li> <li>It can make consistent changes across many files.</li> <li>It can automate repetitive steps.</li> </ul>"},{"location":"how-it-works/#what-makes-it-dangerous","title":"What makes it dangerous","text":"<ul> <li>It can change many files quickly.</li> <li>It can produce outputs that look right.</li> <li>It can run commands you did not understand.</li> </ul> <p>Your control points are: scope, diffs, and verification.</p>"},{"location":"lab-policy-template/","title":"Lab Policy Template (Fill In)","text":"<p>This is a starting point. Adapt it to your institution and field.</p>"},{"location":"lab-policy-template/#purpose","title":"Purpose","text":"<p>We use AI tools to improve productivity while maintaining scientific integrity, privacy, and reproducibility.</p>"},{"location":"lab-policy-template/#allowed-tools","title":"Allowed tools","text":"<ul> <li>Primary tool(s): ______</li> <li>Secondary tool(s): ____</li> </ul>"},{"location":"lab-policy-template/#data-rules","title":"Data rules","text":"<p>Never share:</p> <ul> <li>credentials / API keys</li> <li>patient data / human-subject raw data</li> <li>embargoed collaborator material</li> </ul> <p>Allowed to share:</p> <ul> <li>public papers</li> <li>public code</li> <li>synthetic data</li> <li>small anonymized examples (if permitted)</li> </ul>"},{"location":"lab-policy-template/#verification-rules","title":"Verification rules","text":"<ul> <li>Any AI-generated code must be reviewed via diff.</li> <li>Any analysis must have a reproducible run command.</li> <li>Any citations must be verified.</li> </ul>"},{"location":"lab-policy-template/#disclosure","title":"Disclosure","text":"<p>We disclose meaningful AI assistance in manuscripts and proposals according to venue requirements.</p>"},{"location":"lab-policy-template/#storage-and-logging","title":"Storage and logging","text":"<ul> <li>Store prompts and outputs for important analyses: yes/no</li> <li>Store the exact commands used to generate figures: yes/no</li> </ul>"},{"location":"lab-policy-template/#contact","title":"Contact","text":"<p>If unsure, ask: ______</p>"},{"location":"lab-rollout/","title":"Lab Rollout Playbook","text":"<p>This is a lightweight way to adopt agentic AI tools without creating chaos.</p>"},{"location":"lab-rollout/#1-decide-what-is-allowed","title":"1) Decide what is allowed","text":"<ul> <li>Allowed: public papers, public code, synthetic data, toy examples</li> <li>Caution: unpublished results, collaborator material, embargoed data</li> <li>Usually not allowed without explicit approval: human-subject data, patient data, credentials, proprietary industry data</li> </ul> <p>Write the decision down (one page) and make it easy to follow.</p>"},{"location":"lab-rollout/#2-standardize-the-workflow","title":"2) Standardize the workflow","text":"<ul> <li>Use repos for analysis (even if small).</li> <li>Require diffs and \"verification commands\" for code changes.</li> <li>Prefer small PRs / small changes.</li> </ul>"},{"location":"lab-rollout/#3-standardize-prompts-seriously","title":"3) Standardize prompts (seriously)","text":"<p>Put a few prompt templates in a shared doc and encourage people to reuse them. See: <code>docs/prompts.md</code>.</p>"},{"location":"lab-rollout/#4-track-what-the-tool-did","title":"4) Track what the tool did","text":"<ul> <li>For analysis: record parameters, versions, seeds, and data hashes.</li> <li>For writing: record which sections were AI-assisted and how you validated claims.</li> </ul>"},{"location":"lab-rollout/#5-teach-verification-thinking","title":"5) Teach \"verification thinking\"","text":"<ul> <li>Always ask: \"What would prove this wrong?\"</li> <li>Build tiny checks: limiting cases, invariants, synthetic datasets.</li> </ul>"},{"location":"literature/","title":"Literature and Notes","text":"<p>This is an area where AI can help a lot, but it is also where it hallucinates the most.</p>"},{"location":"literature/#safe-approach","title":"Safe approach","text":"<ul> <li>Use AI to summarize papers you provide.</li> <li>Use AI to generate questions, hypotheses, and comparisons.</li> <li>Do not trust it to \"know\" the literature without sources.</li> </ul>"},{"location":"literature/#good-tasks","title":"Good tasks","text":"<ul> <li>\"Summarize this paper in 10 bullets, then list 10 weaknesses.\"</li> <li>\"Compare these two methods and tell me when each fails.\"</li> <li>\"Extract all datasets, hyperparameters, and evaluation metrics.\"</li> </ul>"},{"location":"literature/#bad-tasks-unless-you-verify","title":"Bad tasks (unless you verify)","text":"<ul> <li>\"Give me citations for X\"</li> <li>\"What is the state of the art in Y\" (without forcing sources)</li> </ul>"},{"location":"literature/#a-workflow-that-works","title":"A workflow that works","text":"<ol> <li>Put PDFs in a folder.</li> <li>Ask the agent to create structured notes per paper.</li> <li>Ask for a synthesis across papers, explicitly citing which paper supports which claim.</li> </ol>"},{"location":"literature/#output-format-suggestion","title":"Output format suggestion","text":"<ul> <li>One note per paper</li> <li>One synthesis note per topic</li> <li>A table of methods vs assumptions vs failure modes</li> </ul>"},{"location":"mcp/","title":"MCP and Connectors (Advanced)","text":"<p>MCP (Model Context Protocol) is a way for agentic tools to use external tools and data sources.</p> <p>Examples of what connectors can enable:</p> <ul> <li>read Google Drive docs</li> <li>pull issues from Jira/GitHub</li> <li>use internal datasets or search indexes</li> </ul>"},{"location":"mcp/#why-scientists-should-care","title":"Why scientists should care","text":"<p>The biggest productivity wins often come from connecting the agent to your actual working context:</p> <ul> <li>lab docs</li> <li>protocols</li> <li>shared notes</li> <li>code repos</li> </ul>"},{"location":"mcp/#the-risk","title":"The risk","text":"<p>More access increases blast radius.</p> <p>Rules of thumb:</p> <ul> <li>start with read-only</li> <li>avoid connecting anything sensitive until you understand the permissions</li> <li>log what the agent did</li> </ul> <p>If your institution has policies, follow them.</p>"},{"location":"overview/","title":"What This Guide Is","text":"<p>This is a practical guide for scientists adopting agentic AI tools.</p> <p>It assumes:</p> <ul> <li>You write some code (often Python/R/Matlab) but you are not a professional software engineer.</li> <li>You care about correctness, reproducibility, and not embarrassing yourself in a paper.</li> <li>You want a workflow that is faster, not just \"cool\".</li> </ul>"},{"location":"overview/#the-promise","title":"The promise","text":"<p>Agentic AI can:</p> <ul> <li>turn vague goals into concrete code changes</li> <li>automate the boring parts (setup, refactors, glue code)</li> <li>accelerate debugging</li> <li>help you explore literature and write more clearly</li> </ul>"},{"location":"overview/#the-catch","title":"The catch","text":"<p>Agentic AI also:</p> <ul> <li>makes mistakes confidently</li> <li>can create plausible but wrong plots, stats, or citations</li> <li>can leak data if you paste sensitive content</li> <li>can change many files quickly (reproducibility risk)</li> </ul> <p>The goal of this guide is to help you get the upside without eating the downside.</p>"},{"location":"overview/#a-simple-rule","title":"A simple rule","text":"<p>If the agent can take actions, you must:</p> <ol> <li>review diffs</li> <li>run verification</li> <li>keep a reproducible record</li> </ol>"},{"location":"overview/#glossary-quick","title":"Glossary (quick)","text":"<ul> <li>Agentic AI: an AI system that can take actions (edit files, run commands, call tools).</li> <li>Diff: a view of what changed in files.</li> <li>Repo: a project folder tracked by git (version control).</li> <li>Context window: how much information the model can consider at once.</li> <li>Tokens: the model's \"units\" of text; cost is often per token.</li> </ul>"},{"location":"pricing/","title":"Pricing (Double-Check Before Publishing)","text":"<p>Pricing changes frequently. This page is a snapshot of publicly listed pricing as of 2026-02-01.</p>"},{"location":"pricing/#claude-subscriptions-includes-claude-code","title":"Claude subscriptions (includes Claude Code)","text":"<p>From Anthropic's pricing page (Individual plans):</p> <ul> <li>Free: $0</li> <li>Pro: $17/month with annual discount ($200 billed up front) or $20 billed monthly; includes access to Claude Code</li> <li>Max: from $100/month</li> </ul> <p>Source: https://www.anthropic.com/pricing</p>"},{"location":"pricing/#claude-api-pricing-if-you-build-custom-tools","title":"Claude API pricing (if you build custom tools)","text":"<p>From Anthropic's pricing page (API):</p> <ul> <li>Opus 4.5: $5/MTok input, $25/MTok output</li> <li>Sonnet 4.5: $3/MTok input and $15/MTok output for prompts &lt;= 200K tokens (higher prices for &gt;200K)</li> <li>Haiku 4.5: $1/MTok input, $5/MTok output</li> </ul> <p>Tools pricing shown there also includes (examples):</p> <ul> <li>Web search: $10 / 1K searches (not including tokens)</li> <li>Code execution: $0.05 per hour per container (after free daily hours per org)</li> </ul> <p>Source: https://www.anthropic.com/pricing</p>"},{"location":"pricing/#alternatives-for-comparison","title":"Alternatives (for comparison)","text":"<ul> <li> <p>Cursor: Free tier; Pro $20/month; Pro+ $60/month; Ultra $200/month   Source: https://cursor.com/pricing</p> </li> <li> <p>GitHub Copilot (individual): Free; Pro $10/month; Pro+ $39/month   Source: https://github.com/features/copilot/plans</p> </li> <li> <p>ChatGPT plans are listed at: https://openai.com/pricing</p> </li> </ul>"},{"location":"pricing/#cost-control-tips","title":"Cost control tips","text":"<ul> <li>Prefer smaller tasks and incremental diffs (reduces rework).</li> <li>Save reusable instructions in a project-level \"rules\" file (reduces repeated context).</li> <li>Don't upload giant datasets when a small sample + schema is enough.</li> </ul>"},{"location":"project-structure/","title":"Project Structure That Works With Agents","text":"<p>Most pain comes from messy structure. Fixing structure pays off.</p>"},{"location":"project-structure/#a-simple-layout","title":"A simple layout","text":"<p>This works for many labs:</p> <pre><code>project/\n  README.md\n  pyproject.toml (or requirements.txt)\n  data/            # raw or external data references\n  src/             # code\n  notebooks/       # exploratory work\n  scripts/         # entry points\n  results/         # generated outputs (often gitignored)\n  configs/         # parameter sets for runs\n  tests/           # sanity checks\n</code></pre>"},{"location":"project-structure/#one-command-runs","title":"One-command runs","text":"<p>Pick a canonical command, for example:</p> <ul> <li><code>make figures</code></li> <li><code>make test</code></li> <li><code>python -m yourpackage.run --config configs/paper.yaml</code></li> </ul> <p>Agents are much more reliable when \"done\" is defined as \"this command passes\".</p>"},{"location":"prompting/","title":"Prompting Patterns (That Actually Work)","text":"<p>Good prompting is not poetry. It is specifications.</p>"},{"location":"prompting/#the-5-things-to-include","title":"The 5 things to include","text":"<ol> <li>Goal: what you want</li> <li>Context: what the agent should look at</li> <li>Constraints: what it must not do</li> <li>Definition of done: how you will verify</li> <li>Output format: what artifacts you want</li> </ol>"},{"location":"prompting/#a-default-template","title":"A default template","text":"<pre><code>You are helping me with a scientific project.\n\nGoal:\n- &lt;what you want&gt;\n\nContext:\n- &lt;where to look, what files exist&gt;\n\nConstraints:\n- Do not change scientific assumptions without asking.\n- Do not invent citations or factual claims.\n- Keep changes small and reviewable.\n\nDefinition of done:\n- &lt;tests / commands / checks that must pass&gt;\n\nDeliverables:\n- &lt;files or outputs&gt;\n</code></pre>"},{"location":"prompting/#high-leverage-patterns","title":"High-leverage patterns","text":""},{"location":"prompting/#ask-for-a-plan-first","title":"Ask for a plan first","text":"<p>\"Propose a plan before editing files.\" reduces thrash.</p>"},{"location":"prompting/#force-the-agent-to-be-explicit-about-assumptions","title":"Force the agent to be explicit about assumptions","text":"<p>\"List assumptions and units.\" catches many scientific errors early.</p>"},{"location":"prompting/#add-an-adversarial-check","title":"Add an adversarial check","text":"<p>\"Tell me how this could be wrong.\" makes verification easier.</p>"},{"location":"prompting/#common-failure-patterns","title":"Common failure patterns","text":"<ul> <li>Vague tasks: \"make this better\"</li> <li>No definition of done</li> <li>No tests or sanity checks</li> <li>Asking for citations without giving sources</li> </ul>"},{"location":"prompts/","title":"Prompt Templates for Scientists","text":"<p>These are designed to be copy/pasted into an agentic tool like Claude Code.</p>"},{"location":"prompts/#1-paper-to-code-replication","title":"1) Paper-to-code replication","text":"<pre><code>I want to replicate a figure from a paper.\n\nContext:\n- I will provide the paper PDF (or key equations) and my dataset.\n\nRules:\n- Start by listing all assumptions you are making.\n- Implement a minimal, reproducible script first.\n- Add unit tests or numeric spot-checks against limiting cases.\n\nDeliverables:\n- `src/` code\n- `data/README.md` describing inputs\n- `results/` with generated figure\n- `README.md` with exact run steps\n</code></pre>"},{"location":"prompts/#2-convert-my-messy-notebook-into-a-pipeline","title":"2) \"Convert my messy notebook into a pipeline\"","text":"<pre><code>Turn this notebook into a reproducible pipeline.\n\nConstraints:\n- Keep outputs identical unless you explain why they change.\n- Add a config file for parameters.\n- Pin dependencies.\n- Add a `make run` (or equivalent).\n\nDeliverables:\n- `pipeline/` or `src/`\n- `configs/`\n- `README.md`\n</code></pre>"},{"location":"prompts/#3-grantpaper-writing-assistant-safe-mode","title":"3) Grant/paper writing assistant (safe mode)","text":"<pre><code>Help me improve clarity without inventing facts.\n\nRules:\n- Do not add citations.\n- Do not change scientific claims.\n- Only propose edits that improve structure, clarity, and readability.\n\nOutput:\n- Provide a revised version and a short list of what changed.\n</code></pre>"},{"location":"publishing/","title":"Publishing as a GitHub Page","text":"<p>This repo is set up to publish an MkDocs site (nice theme, sidebar navigation, built-in search).</p>"},{"location":"publishing/#option-a-github-actions-recommended","title":"Option A: GitHub Actions (recommended)","text":"<p>This repo includes a workflow that builds MkDocs and deploys to the <code>gh-pages</code> branch:</p> <ul> <li><code>.github/workflows/deploy-mkdocs.yml</code></li> </ul> <p>Steps:</p> <ol> <li>Push to a GitHub repo.</li> <li>Ensure your default branch is <code>main</code>.</li> <li>In GitHub: Settings -&gt; Pages.</li> <li>Set Source to \"Deploy from a branch\".</li> <li>Select branch <code>gh-pages</code> and folder <code>/ (root)</code>.</li> </ol> <p>Every push to <code>main</code> will rebuild and redeploy.</p>"},{"location":"publishing/#option-b-plain-markdown-from-docs-simpler-fewer-features","title":"Option B: Plain Markdown from /docs (simpler, fewer features)","text":"<p>If you do not want a build step, GitHub Pages can render Markdown directly from <code>/docs</code>, but you lose nice navigation/search.</p> <p>Steps:</p> <ol> <li>In GitHub: Settings -&gt; Pages.</li> <li>Set Source to \"Deploy from a branch\".</li> <li>Choose your default branch and select the <code>/docs</code> folder.</li> </ol>"},{"location":"reproducibility/","title":"Reproducibility Habits (AI-Assisted Work)","text":"<p>Agentic AI can change many files quickly. Reproducibility is how you keep that power from becoming chaos.</p>"},{"location":"reproducibility/#the-minimum-bar","title":"The minimum bar","text":"<ul> <li>\"Fresh clone -&gt; one command -&gt; same key outputs.\"</li> </ul>"},{"location":"reproducibility/#what-to-capture","title":"What to capture","text":"<ul> <li>Inputs: where data came from, which version, any preprocessing</li> <li>Parameters: config files, command-line flags</li> <li>Environment: pinned dependencies, OS assumptions</li> <li>Randomness: seeds and deterministic settings</li> <li>Outputs: figures/tables written to a predictable location</li> </ul>"},{"location":"reproducibility/#two-practical-patterns","title":"Two practical patterns","text":"<ol> <li>A <code>Makefile</code> (or <code>justfile</code>) that encodes the canonical commands.</li> <li>A <code>configs/</code> folder with \"paper-ready\" configs checked into the repo.</li> </ol>"},{"location":"safety-privacy/","title":"Safety, Privacy, and Policy","text":"<p>This is the \"don't get fired / don't leak data / don't fool yourself\" page.</p>"},{"location":"safety-privacy/#defaults-recommended","title":"Defaults (recommended)","text":"<ul> <li>Don't put unpublished results, sensitive human-subject data, credentials, or embargoed material into any tool unless your institution explicitly allows it.</li> <li>Treat AI output as untrusted until you verify it.</li> <li>Prefer working in a repository with version control so you can review diffs.</li> </ul>"},{"location":"safety-privacy/#data-classification-simple-version","title":"Data classification (simple version)","text":"<p>Default to these categories:</p> <ul> <li>Public: papers, public code, public datasets</li> <li>Internal: lab notes, non-public drafts, internal docs</li> <li>Sensitive: human-subject data, patient data, credentials, export-controlled data</li> </ul> <p>Rule of thumb:</p> <ul> <li>Public is usually OK.</li> <li>Internal might be OK depending on your institution.</li> <li>Sensitive is usually NOT OK without explicit approvals and the right tooling.</li> </ul>"},{"location":"safety-privacy/#secrets","title":"Secrets","text":"<p>Never paste:</p> <ul> <li>API keys</li> <li>passwords</li> <li>private tokens</li> <li>SSH keys</li> </ul> <p>If the agent needs to access something, use environment variables or local config files that are not committed.</p>"},{"location":"safety-privacy/#human-oversight","title":"Human oversight","text":""},{"location":"safety-privacy/#human-oversight_1","title":"Human oversight","text":"<p>Even if agentic AI can do a lot, you still need to:</p> <ul> <li>inspect diffs</li> <li>run checks</li> <li>validate math and statistics</li> <li>verify citations and claims</li> </ul>"},{"location":"safety-privacy/#citations-and-factual-claims","title":"Citations and factual claims","text":"<p>Default rule:</p> <ul> <li>If you did not provide sources, assume citations can be wrong or invented.</li> </ul> <p>Better pattern:</p> <ul> <li>Provide the PDFs or URLs.</li> <li>Ask the agent to quote and attribute specific claims to specific sources.</li> </ul>"},{"location":"safety-privacy/#code-execution-safety","title":"Code execution safety","text":"<p>Agents can run commands. That is powerful and risky.</p> <p>Safe defaults:</p> <ul> <li>run in a repo, not your whole home directory</li> <li>prefer throwaway copies for early experiments</li> <li>review commands before running if you do not recognize them</li> </ul>"},{"location":"safety-privacy/#common-failure-modes","title":"Common failure modes","text":""},{"location":"safety-privacy/#common-failure-modes_1","title":"Common failure modes","text":"<ul> <li>Confident wrong answers (especially on niche domain facts)</li> <li>\"Looks right\" plots with incorrect preprocessing</li> <li>Silent changes in assumptions (units, coordinate conventions)</li> <li>Fake citations</li> </ul>"},{"location":"safety-privacy/#a-simple-policy-for-a-lab","title":"A simple policy for a lab","text":"<ul> <li>No sensitive data in external tools.</li> <li>All code changes reviewed via diff.</li> <li>All key results reproducible via a one-command run.</li> <li>All citations verified.</li> </ul>"},{"location":"setup/","title":"Setup Checklist","text":"<p>This page is intentionally practical.</p>"},{"location":"setup/#accounts-and-billing","title":"Accounts and billing","text":"<ul> <li>Pick one primary tool (recommendation: Claude Code).</li> <li>Decide who pays: you personally vs lab vs institution.</li> <li>Turn on billing alerts where possible.</li> </ul>"},{"location":"setup/#local-machine-basics","title":"Local machine basics","text":"<p>Minimum you want:</p> <ul> <li>a terminal you are comfortable using</li> <li>Python (or your language) installed</li> <li>a way to create isolated environments (venv/conda)</li> <li>git installed</li> </ul>"},{"location":"setup/#project-hygiene-do-this-once","title":"Project hygiene (do this once)","text":"<ul> <li>Put the project in a repo (git).</li> <li>Add a <code>README.md</code> with setup and the \"one command\" run.</li> <li>Add a <code>Makefile</code> or similar task runner.</li> <li>Add a tiny test / sanity check.</li> </ul>"},{"location":"setup/#your-first-guardrails","title":"Your first guardrails","text":"<p>In your first sessions, make these rules explicit:</p> <ul> <li>propose a plan before editing</li> <li>keep changes small and reviewable</li> <li>run verification commands</li> <li>do not add citations or claims you cannot verify</li> </ul>"},{"location":"setup/#if-you-are-in-a-regulated-environment","title":"If you are in a regulated environment","text":"<p>Stop and get clarity on:</p> <ul> <li>human-subject data rules</li> <li>patient/clinical data policies</li> <li>export controls / ITAR</li> <li>data retention and sharing policies</li> </ul> <p>Default safe policy: do not paste sensitive data into any external tool.</p>"},{"location":"tooling/","title":"Pick Your Tools","text":"<p>There is no single best tool. Choose based on your comfort level, your workflow, and your institution.</p>"},{"location":"tooling/#recommended-default-claude-code","title":"Recommended default: Claude Code","text":"<p>Why:</p> <ul> <li>works in a terminal (fits research workflows)</li> <li>edits files and runs commands</li> <li>good at larger refactors and multi-step tasks</li> </ul> <p>Start here: <code>docs/claude-code.md</code></p>"},{"location":"tooling/#alternatives-common","title":"Alternatives (common)","text":"<ul> <li>Cursor: AI-first code editor with agent features</li> <li>GitHub Copilot: agent/chat inside IDEs + GitHub</li> <li>ChatGPT: strong general assistant; can be great for planning, math, writing, and \"explain this\"</li> </ul>"},{"location":"tooling/#what-matters-more-than-the-tool","title":"What matters more than the tool","text":"<ul> <li>Your verification habits</li> <li>A reproducible project structure</li> <li>Good prompts that define constraints and \"done\"</li> </ul>"},{"location":"tooling/#suggested-stack-for-a-typical-lab","title":"Suggested stack for a typical lab","text":"<ul> <li>Agentic coding: Claude Code</li> <li>General assistant + deep research: whichever your institution supports</li> <li>Version control: Git + GitHub (or your institution's GitLab)</li> <li>Reproducibility: pinned environments + a one-command run</li> </ul>"},{"location":"troubleshooting/","title":"Troubleshooting","text":"<p>Agentic tools fail in predictable ways. Most fixes are workflow fixes.</p>"},{"location":"troubleshooting/#when-the-agent-thrashes","title":"When the agent \"thrashes\"","text":"<p>Symptoms:</p> <ul> <li>repeated edits without progress</li> <li>long responses that do not change the outcome</li> </ul> <p>Fix:</p> <ul> <li>stop and restate the goal</li> <li>ask for a smaller plan</li> <li>reduce scope to a minimal reproducible example</li> </ul>"},{"location":"troubleshooting/#when-results-are-wrong-but-plausible","title":"When results are wrong but plausible","text":"<p>Fix:</p> <ul> <li>add explicit sanity checks</li> <li>test on synthetic data</li> <li>require units and assumptions</li> </ul>"},{"location":"troubleshooting/#when-the-environment-breaks","title":"When the environment breaks","text":"<p>Fix:</p> <ul> <li>pin dependencies</li> <li>use a virtual environment</li> <li>add a one-command setup</li> </ul>"},{"location":"troubleshooting/#if-you-get-lost","title":"If you get lost","text":"<ul> <li>use <code>git diff</code> to see what changed</li> <li>make a commit before big changes</li> <li>revert or back out changes rather than trying to patch blindly</li> </ul>"},{"location":"verification/","title":"Verification and Rigor (How Not to Fool Yourself)","text":"<p>Agentic AI can be fast. It is not inherently careful.</p> <p>Your job is to make correctness cheap.</p>"},{"location":"verification/#what-to-verify","title":"What to verify","text":""},{"location":"verification/#code","title":"Code","text":"<ul> <li>Does it run?</li> <li>Do tests pass?</li> <li>Are edge cases handled?</li> </ul>"},{"location":"verification/#math-and-statistics","title":"Math and statistics","text":"<ul> <li>Units and dimensional analysis</li> <li>Limiting cases</li> <li>Known benchmarks</li> <li>Synthetic data tests</li> </ul>"},{"location":"verification/#plots-and-figures","title":"Plots and figures","text":"<ul> <li>Are axes labeled correctly?</li> <li>Are you plotting what you think you are plotting?</li> <li>Are preprocessing steps recorded?</li> </ul>"},{"location":"verification/#writing","title":"Writing","text":"<ul> <li>No invented citations</li> <li>Claims match the data</li> <li>Clear separation between results and speculation</li> </ul>"},{"location":"verification/#a-verification-mindset","title":"A verification mindset","text":"<p>Ask:</p> <ul> <li>What would prove this wrong?</li> <li>What is the simplest test that would catch the most likely mistake?</li> </ul>"},{"location":"verification/#cross-checking","title":"Cross-checking","text":"<p>Useful pattern:</p> <ul> <li>Use one model to propose.</li> <li>Use another model (or your own reasoning) to critique.</li> </ul> <p>But do not confuse \"two models agree\" with truth. They can share the same blind spots.</p>"},{"location":"verification/#reproducibility-is-part-of-verification","title":"Reproducibility is part of verification","text":"<p>If you cannot rerun it reliably, you cannot really verify it.</p>"},{"location":"why-agentic/","title":"Why Agentic AI (Instead of Chat)","text":"<p>Chat-only AI is useful for:</p> <ul> <li>explaining concepts</li> <li>brainstorming</li> <li>writing help</li> </ul> <p>But for real research work, the friction is often:</p> <ul> <li>your messy file system</li> <li>inconsistent scripts</li> <li>environment setup</li> <li>refactors and reproducibility</li> </ul> <p>Agentic tools reduce that friction because they can:</p> <ul> <li>inspect your project structure</li> <li>edit the actual files</li> <li>run commands (tests, scripts)</li> <li>iterate until it works</li> </ul>"},{"location":"why-agentic/#the-real-shift","title":"The real shift","text":"<p>Your job becomes less \"do every step\" and more:</p> <ul> <li>define the goal</li> <li>define constraints</li> <li>verify the result</li> </ul> <p>That is a managerial skill, not a coding trick.</p>"},{"location":"why-agentic/#when-not-to-use-agentic-ai","title":"When NOT to use agentic AI","text":"<ul> <li>Sensitive data you are not allowed to share</li> <li>High-stakes decisions without verification (clinical, safety-critical)</li> <li>Tasks where you cannot define a test or check</li> </ul> <p>If you cannot verify it, do not delegate it.</p>"},{"location":"workflows/","title":"Workflows (Plan -&gt; Do -&gt; Verify)","text":"<p>Agentic tools feel magical when you treat them like a junior colleague: they move fast, but you own correctness.</p>"},{"location":"workflows/#the-default-loop","title":"The default loop","text":"<ol> <li>Plan: ask for a short plan and the expected artifacts.</li> <li>Do: let it implement in small chunks.</li> <li>Verify: run checks (tests, plots, unit sanity checks) and review diffs.</li> <li>Record: write down what changed and how to reproduce it.</li> </ol>"},{"location":"workflows/#what-to-verify-in-science-work","title":"What to verify in science work","text":"<ul> <li>Data provenance: exactly which files/versions were used</li> <li>Determinism: fixed seeds, pinned versions, saved configs</li> <li>Sanity checks: units, limiting cases, back-of-the-envelope estimates</li> <li>Reproducibility: \"fresh clone -&gt; one command -&gt; same figures\"</li> </ul>"},{"location":"workflows/#two-example-task-prompts","title":"Two example task prompts","text":""},{"location":"workflows/#reproducible-analysis","title":"Reproducible analysis","text":"<pre><code>You are helping me make this analysis reproducible.\n\nRules:\n- Propose a plan first.\n- Do not change scientific logic without asking.\n- Add a single command that reproduces the main figure(s).\n- Add quick sanity checks (units, basic invariants).\n\nGoal:\n- When I run `make figures` (or similar), it produces the same outputs.\n</code></pre>"},{"location":"workflows/#take-over-the-annoying-parts","title":"\"Take over the annoying parts\"","text":"<pre><code>Please refactor this project so a new lab member can run it.\n\nDeliverables:\n- README with setup + one-command run\n- pinned dependencies\n- scripts organized into a minimal pipeline\n- a short checklist for verifying outputs are sensible\n</code></pre>"},{"location":"writing/","title":"Writing and Grants","text":"<p>AI is very good at clarity and structure. It is also very good at sounding confident while being wrong.</p>"},{"location":"writing/#safe-uses","title":"Safe uses","text":"<ul> <li>rewrite for clarity</li> <li>improve structure</li> <li>tighten abstract/intro</li> <li>generate outlines</li> </ul>"},{"location":"writing/#risky-uses","title":"Risky uses","text":"<ul> <li>adding claims</li> <li>adding citations</li> <li>summarizing things you did not provide as sources</li> </ul>"},{"location":"writing/#a-workflow-that-works","title":"A workflow that works","text":"<ol> <li>You provide the facts (results, figures, key points).</li> <li>The AI improves clarity and structure.</li> <li>You verify every claim.</li> </ol>"},{"location":"writing/#a-good-prompt","title":"A good prompt","text":"<pre><code>Edit for clarity and structure only.\n\nRules:\n- Do not add citations.\n- Do not change scientific claims.\n- If something is unclear, ask questions instead of guessing.\n</code></pre>"}]}