{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Agentic AI for Scientists","text":"<p>This guide is for scientists who are not professional software developers, but who do write code, analyze data, and produce papers.</p> <p>The core idea: instead of using an AI model like a chat box, you use an agent that can take actions (read/write files, run commands, iterate) with you supervising.</p>"},{"location":"#recommended-reading-path","title":"Recommended reading path","text":"<p>If you are new:</p> <ol> <li>What This Is</li> <li>Why Agentic AI</li> <li>Pick Your Tools</li> <li>Oh I Get It (Guided Tour)</li> <li>Bootcamp (2 Days)</li> <li>Quick Win (First Hour)</li> <li>Workflows (Plan-Do-Verify)</li> <li>Verification and Rigor</li> </ol> <p>If you are leading a lab:</p> <ol> <li>Lab Rollout</li> <li>Lab Policy Template</li> <li>Reproducibility</li> <li>Safety, Privacy, and Policy</li> </ol>"},{"location":"#where-to-start","title":"Where to start","text":"<ol> <li>Install and try a terminal agent on a small, non-sensitive project: Claude Code</li> <li>If you already pay for ChatGPT, you can use OpenAI Codex CLI instead.</li> <li>Learn the core workflow loop (plan -&gt; do -&gt; verify): Workflows</li> <li>Set guardrails for privacy, safety, and reproducibility: Safety &amp; Privacy</li> <li>Copy/paste prompt templates you can actually use: Prompt Templates</li> <li>Understand costs and avoid surprises: Pricing</li> </ol> <p>If you are onboarding a lab:</p> <ul> <li>First hour checklist: First Hour</li> <li>Lab rollout: Lab Rollout</li> <li>Disclosure/attribution: Disclosure</li> <li>Reproducibility habits: Reproducibility</li> </ul>"},{"location":"#a-quick-mental-model","title":"A quick mental model","text":"<ul> <li>Chat-only AI: you ask questions; you copy/paste results.</li> <li>Agentic AI: you give a task; it edits files and runs commands; you review diffs and outputs.</li> </ul> <p>If you can supervise work and verify results, agentic tools can compress days of \"yak shaving\" (setup, plumbing, debugging, refactors) into hours.</p>"},{"location":"advanced-usage/","title":"Advanced Usage (Your Tool of Choice)","text":"<p>This page is about taking your agent tool to the next level: reusable prompts, persistent instructions, and \"background\" execution.</p> <p>If you are not comfortable yet with the basics (plan -&gt; do -&gt; verify, diffs, sanity checks), do that first:</p> <ul> <li>Workflows</li> <li>Verification and Rigor</li> </ul>"},{"location":"advanced-usage/#the-big-unlocks","title":"The big unlocks","text":"<p>Across most agent tools, these are the high-leverage features for scientists:</p> <ol> <li>Persistent instructions (project rules, memory) - tell the agent your conventions once</li> <li>Reusable prompts (slash commands, skills, prompt files) - encode your lab's workflows</li> <li>Background mode (async tasks, non-interactive runs) - start a task and come back later</li> </ol>"},{"location":"advanced-usage/#persistent-instructions-tell-it-once","title":"Persistent instructions: tell it once","text":"<p>Instead of repeating \"do not change scientific assumptions\" every session, you can store instructions that load automatically.</p> <p>Most tools support a project-level file (like <code>CLAUDE.md</code> or <code>AGENTS.md</code>) where you write:</p> <ul> <li>coding conventions</li> <li>verification requirements</li> <li>\"always do X before Y\" rules</li> <li>project-specific context</li> </ul> <p>This is the single highest-leverage feature. Start here.</p>"},{"location":"advanced-usage/#reusable-prompts-stop-retyping-yourself","title":"Reusable prompts: stop retyping yourself","text":"<p>Good reusable prompts encode your lab's defaults:</p> <ul> <li>\"Propose a plan first\"</li> <li>\"Do not change scientific assumptions without asking\"</li> <li>\"Run verification\"</li> <li>\"Summarize the diff\"</li> </ul> <p>Most tools let you save these as slash commands (like <code>/review</code> or <code>/deploy</code>) that you can invoke instead of typing the full prompt each time.</p>"},{"location":"advanced-usage/#background-mode-delegate-and-come-back","title":"Background mode: delegate and come back","text":"<p>Different tools implement this differently:</p> <ul> <li>cloud tasks you can start and review later</li> <li>non-interactive CLI runs in CI</li> <li>agents that open PRs for review</li> </ul> <p>The rule is the same: do not trust results until you review diffs and run checks.</p>"},{"location":"advanced-usage/#official-docs-to-go-deeper","title":"Official docs to go deeper","text":""},{"location":"advanced-usage/#claude-code","title":"Claude Code","text":"<p>Claude Code is the default tool in this guide.</p> <p>Start here:</p> <ul> <li>Memory (CLAUDE.md - persistent project instructions)</li> <li>Skills (custom slash commands / reusable prompts)</li> <li>Claude Code on the web (background/async tasks)</li> <li>Cost management</li> </ul> <p>Reference:</p> <ul> <li>Extend overview (full feature summary)</li> <li>CLI reference</li> <li>Settings</li> <li>Sandboxing</li> </ul> <p>For developers:</p> <ul> <li>Hooks guide (automate workflows with scripts)</li> <li>Subagents (spawn specialized workers)</li> <li>Headless mode (run programmatically)</li> </ul>"},{"location":"advanced-usage/#openai-codex","title":"OpenAI Codex","text":"<p>If you already pay for a ChatGPT plan, Codex can be a great way to get an agentic workflow without adding another subscription.</p> <ul> <li>Codex overview</li> <li>Codex CLI overview</li> <li>Codex CLI reference (flags/options)</li> <li>Codex CLI slash commands (reusable prompts)</li> <li>Rules (persistent project instructions)</li> <li>AGENTS.md (agent coordination patterns)</li> <li>Skills (create reusable skills)</li> <li>Codex CLI repo (install instructions and releases)</li> </ul>"},{"location":"advanced-usage/#github-copilot","title":"GitHub Copilot","text":"<p>Copilot has a large docs set. These are the most relevant advanced topics:</p> <ul> <li>Main docs index</li> <li>Custom instructions (personal/repo/org)</li> <li>Prompt files (reusable prompts/templates)</li> <li>Agent skills</li> <li>Hooks (for Copilot coding agent)</li> <li>MCP</li> </ul>"},{"location":"advanced-usage/#cursor","title":"Cursor","text":"<p>Cursor moves quickly and its docs are the best source of truth:</p> <ul> <li>Docs</li> <li>Pricing (to understand \"background agents\" and plan limits)</li> </ul>"},{"location":"advanced-usage/#a-scientist-friendly-way-to-use-advanced-features","title":"A scientist-friendly way to use advanced features","text":"<p>If you want to adopt one advanced feature at a time, do it in this order:</p> <ol> <li>Persistent instructions - set up a project rules file with your conventions</li> <li>Reusable prompts - save your top 3 workflows as slash commands</li> <li>Background tasks - learn to start longer tasks and review them later</li> <li>Tool integrations (MCP) - connect to databases, Slack, or other services if needed</li> </ol> <p>Each step should make your work more reproducible and less error-prone.</p>"},{"location":"advanced-usage/#for-developers-hooks","title":"For developers: hooks","text":"<p>If you have software engineering experience, hooks let you run scripts automatically when specific events happen (file edits, before commits, etc.). They're powerful for enforcing guardrails like:</p> <ul> <li>auto-format code on file edits</li> <li>block secrets from being committed</li> <li>require tests to pass before marking done</li> </ul> <p>Most scientists can skip this feature initially. The verification habits in this guide give you the same safety without writing code.</p>"},{"location":"advanced-usage/#see-also","title":"See also","text":"<ul> <li>MCP &amp; Connectors</li> <li>Scaling Up Your Usage</li> <li>Cost Control</li> </ul>"},{"location":"ai-fluency/","title":"AI Fluency (A 1-Week Ramp)","text":"<p>The biggest gains come after you build a few habits.</p>"},{"location":"ai-fluency/#day-1-quick-win","title":"Day 1: Quick win","text":"<ul> <li>Do the \"First Hour\" task: First Hour</li> </ul>"},{"location":"ai-fluency/#day-2-make-verification-cheap","title":"Day 2: Make verification cheap","text":"<ul> <li>Add a <code>make test</code> and a <code>make run</code>.</li> <li>Add one tiny sanity check.</li> </ul>"},{"location":"ai-fluency/#day-3-convert-one-notebook","title":"Day 3: Convert one notebook","text":"<ul> <li>Turn one notebook into a script + config.</li> <li>Require identical outputs.</li> </ul>"},{"location":"ai-fluency/#day-4-refactor-for-a-new-lab-member","title":"Day 4: Refactor for a new lab member","text":"<ul> <li>Improve README.</li> <li>Pin dependencies.</li> <li>One-command run.</li> </ul>"},{"location":"ai-fluency/#day-5-literature-workflow","title":"Day 5: Literature workflow","text":"<ul> <li>Summarize 3 papers you provide.</li> <li>Produce a comparison table of assumptions and failure modes.</li> </ul>"},{"location":"ai-fluency/#day-6-writing-workflow","title":"Day 6: Writing workflow","text":"<ul> <li>Use AI for clarity-only editing.</li> <li>Verify every claim.</li> </ul>"},{"location":"ai-fluency/#day-7-make-a-lab-policy","title":"Day 7: Make a lab policy","text":"<ul> <li>Fill in: Lab Policy Template</li> </ul> <p>If you do just this week, you will be far ahead of most people.</p>"},{"location":"bootcamp/","title":"Bootcamp: Agentic AI for Scientists (2 Days)","text":"<p>This is a practical bootcamp plan you can run solo or as a lab.</p> <p>The goal is not to \"learn AI\". The goal is to build habits that produce correct, reproducible work faster.</p>"},{"location":"bootcamp/#day-0-30-minutes-safety-first","title":"Day 0 (30 minutes): Safety first","text":"<ol> <li>Decide what data you will NOT share.</li> <li>Default: no unpublished results, no human-subject data, no credentials.</li> <li>Decide whether you want a sandbox setup.</li> <li>See: Burner Machine and Sandboxes</li> <li>Pick one primary tool.</li> <li>Recommended: Claude Code (Claude Code)</li> <li>If you already pay for ChatGPT, consider OpenAI Codex CLI as a Claude Code alternative.</li> </ol>"},{"location":"bootcamp/#day-1-get-a-real-win-with-guardrails","title":"Day 1: Get a real win with guardrails","text":""},{"location":"bootcamp/#module-1-install-and-run-your-first-session-30-minutes","title":"Module 1: Install and run your first session (30 minutes)","text":"<ul> <li>Follow: Claude Code</li> <li>If you get stuck, use: Troubleshooting</li> </ul>"},{"location":"bootcamp/#module-2-first-win-60-minutes","title":"Module 2: First win (60 minutes)","text":"<p>Use: First Hour</p> <p>Target outcome:</p> <ul> <li>a README</li> <li>a one-command run</li> <li>a tiny sanity check</li> </ul>"},{"location":"bootcamp/#module-3-learn-the-workflow-loop-60-minutes","title":"Module 3: Learn the workflow loop (60 minutes)","text":"<p>Read: Workflows Practice:</p> <ul> <li>Ask for a plan.</li> <li>Make one small edit.</li> <li>Run one verification command.</li> <li>Review diffs.</li> </ul>"},{"location":"bootcamp/#module-4-verification-mindset-60-minutes","title":"Module 4: Verification mindset (60 minutes)","text":"<p>Read: Verification and Rigor Practice:</p> <ul> <li>Add one limiting-case check or synthetic-data test.</li> <li>Write down assumptions and units.</li> </ul>"},{"location":"bootcamp/#day-2-use-it-on-real-science","title":"Day 2: Use it on real science","text":""},{"location":"bootcamp/#module-5-a-literature-workflow-60-minutes","title":"Module 5: A literature workflow (60 minutes)","text":"<p>Read: Literature and Notes Practice:</p> <ul> <li>Pick 2-3 papers.</li> <li>Create structured notes.</li> <li>Build a comparison table (assumptions, failure modes).</li> </ul>"},{"location":"bootcamp/#module-6-a-reproducible-analysis-workflow-90-minutes","title":"Module 6: A reproducible analysis workflow (90 minutes)","text":"<p>Read: Data Analysis Practice:</p> <ul> <li>Convert one notebook or script into a pipeline.</li> <li>Add a config file.</li> <li>Make \"fresh clone -&gt; one command\" work.</li> </ul>"},{"location":"bootcamp/#module-7-figures-you-can-trust-60-minutes","title":"Module 7: Figures you can trust (60 minutes)","text":"<p>Read: Figures and Tables Practice:</p> <ul> <li>Add labels, units, and provenance.</li> <li>Add a lightweight sanity summary (counts, means, ranges).</li> </ul>"},{"location":"bootcamp/#module-8-cost-and-multi-model-usage-30-minutes","title":"Module 8: Cost and multi-model usage (30 minutes)","text":"<p>Read: - Cost Control - Multi-Model Strategy</p> <p>Goal:</p> <ul> <li>know when a second tool is worth paying for</li> <li>know how to avoid runaway usage</li> </ul>"},{"location":"bootcamp/#graduation-criteria","title":"Graduation criteria","text":"<p>You are \"agentic AI fluent\" when:</p> <ul> <li>you can define \"done\" as a command that passes</li> <li>you can read diffs and explain changes</li> <li>you can identify at least 3 ways an output could be wrong</li> <li>you have a reproducible workflow for one real project</li> </ul>"},{"location":"burner-machine/","title":"Burner Machine and Sandboxes","text":"<p>Do you need a \"burner machine\"?</p> <p>Usually: no. Sometimes: yes.</p> <p>This page is a practical way to think about risk.</p>"},{"location":"burner-machine/#what-people-mean-by-burner","title":"What people mean by \"burner\"","text":"<ul> <li>A dedicated laptop or desktop used for AI-assisted work</li> <li>A separate OS account</li> <li>A VM (virtual machine)</li> <li>A cloud dev environment</li> </ul> <p>The point is to reduce blast radius:</p> <ul> <li>fewer sensitive files accessible</li> <li>fewer saved credentials in browsers</li> <li>less risk if you mis-click \"yes\" on something</li> </ul>"},{"location":"burner-machine/#when-you-should-consider-it","title":"When you should consider it","text":"<ul> <li>You routinely handle sensitive human-subject or clinical data.</li> <li>You have export-controlled or proprietary data.</li> <li>Your institution has strict compliance requirements.</li> <li>You want to try agentic tools before you trust them.</li> </ul>"},{"location":"burner-machine/#lightweight-option-recommended-for-most","title":"Lightweight option (recommended for most)","text":"<ol> <li>Create a dedicated folder for AI-assisted projects.</li> <li>Use a separate browser profile for AI tools.</li> <li>Keep secrets out of repos.</li> <li>Work in copies of projects until you trust the workflow.</li> </ol>"},{"location":"burner-machine/#stronger-option-separate-os-user","title":"Stronger option: separate OS user","text":"<ul> <li>Create a new user account on your machine.</li> <li>Use it only for agentic AI work.</li> <li>Do not sign into personal email or password managers there.</li> </ul>"},{"location":"burner-machine/#strongest-option-vm-or-cloud-environment","title":"Strongest option: VM or cloud environment","text":"<ul> <li>Use a VM (or a cloud dev box) that contains only the project.</li> <li>Destroy and recreate when you are done.</li> </ul> <p>This is higher effort, but it is clean.</p>"},{"location":"burner-machine/#the-bigger-win-permissions-discipline","title":"The bigger win: permissions discipline","text":"<p>Even with a burner machine, you still need:</p> <ul> <li>diffs</li> <li>verification</li> <li>no secrets in prompts</li> </ul> <p>Burner setups reduce risk. They do not replace good habits.</p>"},{"location":"checklists/","title":"Checklists","text":"<p>These are the habits that make agentic AI safe and useful.</p>"},{"location":"checklists/#pre-flight-before-you-delegate","title":"Pre-flight (before you delegate)","text":"<ul> <li>Is the data allowed to be shared with this tool?</li> <li>Is the task small enough to review?</li> <li>Do you have a definition of done?</li> <li>Do you have a verification command or sanity check?</li> <li>Is the project under version control?</li> </ul>"},{"location":"checklists/#during-flight-while-the-agent-works","title":"During flight (while the agent works)","text":"<ul> <li>Ask for a plan before large edits.</li> <li>Keep changes in small steps.</li> <li>Require it to explain assumptions and units.</li> <li>Stop if you do not understand what changed.</li> </ul>"},{"location":"checklists/#post-flight-before-you-trust-results","title":"Post-flight (before you trust results)","text":"<ul> <li>Review diffs.</li> <li>Run tests / scripts.</li> <li>Check units, limiting cases, and basic invariants.</li> <li>Verify citations manually.</li> <li>Record how to reproduce the result.</li> </ul>"},{"location":"checklists/#red-flags","title":"Red flags","text":"<ul> <li>\"It should work\" without running anything</li> <li>new citations you did not provide</li> <li>big refactors without tests</li> <li>plots with missing units or unclear preprocessing</li> </ul>"},{"location":"checklists/#see-also","title":"See also","text":"<ul> <li>Verification and Rigor</li> <li>Workflows (Plan-Do-Verify)</li> <li>Troubleshooting</li> </ul>"},{"location":"claude-code/","title":"Claude Code (Recommended)","text":"<p>Claude Code is an agentic coding tool that runs in your terminal and can edit files, run commands, and iterate.</p>"},{"location":"claude-code/#what-you-need","title":"What you need","text":"<ul> <li>A Claude subscription (Pro/Max/Team/Enterprise) or a Claude Console account</li> </ul> <p>Notes:</p> <ul> <li>If you are just getting started, Pro is often enough.</li> <li>If you use it heavily (long sessions, large repos), you may need a higher tier.</li> <li>Pricing changes; verify at Anthropic's pricing page</li> </ul> <p>Alternative if you already pay for ChatGPT</p> <ul> <li>If you already have a ChatGPT plan (Plus/Pro/Team/Edu/Enterprise), consider OpenAI Codex CLI as a Claude Code alternative. It is also a terminal-based coding agent and can be used by signing in with your ChatGPT account.</li> </ul> <p>Official docs: - Claude Code overview</p>"},{"location":"claude-code/#install","title":"Install","text":"<p>From the official instructions:</p> <p>macOS / Linux / WSL</p> <pre><code>curl -fsSL https://claude.ai/install.sh | bash\n</code></pre> <p>Windows PowerShell</p> <pre><code>irm https://claude.ai/install.ps1 | iex\n</code></pre> <p>Windows CMD</p> <pre><code>curl -fsSL https://claude.ai/install.cmd -o install.cmd &amp;&amp; install.cmd &amp;&amp; del install.cmd\n</code></pre> <p>Windows (WinGet)</p> <pre><code>winget install Anthropic.ClaudeCode\n</code></pre> <p>macOS (Homebrew)</p> <pre><code>brew install --cask claude-code\n</code></pre> <p>Then:</p> <pre><code>cd your-project\nclaude\n</code></pre> <p>If you're prompted to log in on first use, follow the browser flow.</p>"},{"location":"claude-code/#how-scientists-should-use-it-default-guardrails","title":"How scientists should use it (default guardrails)","text":"<ul> <li>Start with a throwaway repo or a copy of your project.</li> <li>Tell it to propose a plan before editing.</li> <li>Require it to run tests / a minimal validation script.</li> <li>Review diffs for every change.</li> </ul>"},{"location":"claude-code/#the-30-minute-starter-task","title":"The 30-minute starter task","text":"<p>Pick one:</p> <ul> <li>\"Add a <code>Makefile</code> (or <code>justfile</code>) that runs <code>pytest</code>, <code>ruff</code>, and a quick smoke test.\"</li> <li>\"Turn my one-off analysis script into a reproducible pipeline with a config file and pinned dependencies.\"</li> <li>\"Write a small CLI that loads my CSV and produces the exact plot I need for Figure 2.\"</li> </ul>"},{"location":"cli-basics/","title":"Terminal Basics (For Non-Developers)","text":"<p>You do not need to become a software engineer. But agentic tools often live in the terminal.</p> <p>If you do not know how to open a terminal, start here: Open a Terminal</p>"},{"location":"cli-basics/#three-commands-you-should-know","title":"Three commands you should know","text":"<pre><code>pwd   # where am I?\nls    # what files are here?\ncd .. # go up one folder\n</code></pre>"},{"location":"cli-basics/#paths","title":"Paths","text":"<ul> <li>A \"path\" is just a file location.</li> <li><code>.</code> means \"current folder\".</li> <li><code>..</code> means \"parent folder\".</li> </ul>"},{"location":"cli-basics/#a-safe-habit","title":"A safe habit","text":"<p>Before you run any command you do not recognize:</p> <ol> <li>ask the agent what it will do</li> <li>run it on a copy of the project first</li> </ol>"},{"location":"cli-basics/#common-research-commands","title":"Common research commands","text":"<pre><code>python3 script.py\npython3 -m venv .venv\nsource .venv/bin/activate\npip install -r requirements.txt\npytest\n</code></pre> <p>If those look unfamiliar, that is normal. You only need a small subset.</p>"},{"location":"coding/","title":"Coding and Refactors","text":"<p>Agentic AI excels at the mechanical parts of coding\u2014the parts that take time but don't require deep scientific judgment. This page covers how to use it effectively while keeping your science correct.</p>"},{"location":"coding/#what-ai-is-genuinely-good-at","title":"What AI is genuinely good at","text":""},{"location":"coding/#refactoring","title":"Refactoring","text":"<p>Turning messy code into clean code without changing behavior. This is where AI shines brightest: - Extracting functions from long scripts - Renaming variables for clarity - Reorganizing file structure - Converting notebooks to modules</p>"},{"location":"coding/#adding-tests","title":"Adding tests","text":"<p>Writing test cases for existing code: - Unit tests for individual functions - Integration tests for pipelines - Edge case coverage - Regression tests that catch future bugs</p>"},{"location":"coding/#fixing-errors","title":"Fixing errors","text":"<p>When you have a stack trace or error message: - Diagnosing the root cause - Proposing fixes - Explaining why the error occurred</p>"},{"location":"coding/#wiring-up-clis-and-configs","title":"Wiring up CLIs and configs","text":"<p>The boring but necessary plumbing: - Adding command-line argument parsing - Reading config files - Setting up logging - Handling input/output paths</p>"},{"location":"coding/#documentation","title":"Documentation","text":"<p>Writing docstrings, README files, and usage examples from existing code.</p>"},{"location":"coding/#what-ai-is-risky-at","title":"What AI is risky at","text":""},{"location":"coding/#scientific-logic","title":"Scientific logic","text":"<p>The agent does not understand your domain. It will happily: - Change units without telling you - Swap coordinate conventions - Simplify equations incorrectly - Remove \"unnecessary\" constants that matter</p>"},{"location":"coding/#statistical-choices","title":"Statistical choices","text":"<p>Choosing the right test, handling multiple comparisons, interpreting p-values\u2014these require judgment the agent doesn't have.</p>"},{"location":"coding/#novel-algorithms","title":"Novel algorithms","text":"<p>If you're implementing something new, the agent may confidently produce plausible-looking code that's subtly wrong.</p>"},{"location":"coding/#your-job-as-the-human","title":"Your job as the human","text":"<p>For every coding task, define:</p> <ol> <li>What must not change - scientific assumptions, core logic, validated results</li> <li>What should improve - readability, reproducibility, performance, test coverage</li> <li>How you'll verify - a test, a command, a comparison to known output</li> </ol> <p>If you can't define these, the task isn't ready to delegate.</p>"},{"location":"coding/#common-coding-tasks-with-prompts","title":"Common coding tasks with prompts","text":""},{"location":"coding/#clean-up-a-messy-script","title":"Clean up a messy script","text":"<pre><code>Refactor this script for readability and maintainability.\n\nRules:\n- Do not change the scientific logic or numerical outputs\n- Extract repeated code into functions\n- Add type hints to function signatures\n- Keep the same input/output behavior\n\nVerification:\n- Running the script with the same inputs produces identical outputs\n- Show me the diff so I can review what changed\n</code></pre>"},{"location":"coding/#add-tests-to-existing-code","title":"Add tests to existing code","text":"<pre><code>Add tests for the functions in src/analysis.py.\n\nRequirements:\n- Use pytest\n- Cover normal cases, edge cases, and at least one failure case\n- Tests should run in under 5 seconds total\n- Do not modify the original code unless necessary for testability\n\nIf you need to refactor for testability, propose the change first and explain why.\n</code></pre>"},{"location":"coding/#convert-a-notebook-to-a-script","title":"Convert a notebook to a script","text":"<pre><code>Convert this Jupyter notebook into a reproducible Python script.\n\nRequirements:\n- Move all parameters to a config file or CLI arguments\n- Remove interactive/exploratory code that isn't needed for the final result\n- Add a main() function as the entry point\n- Ensure outputs are identical to the notebook\n\nDo not change any scientific logic. If you're unsure whether something is \"exploratory\" or \"essential,\" ask.\n</code></pre>"},{"location":"coding/#fix-a-bug-from-a-stack-trace","title":"Fix a bug from a stack trace","text":"<pre><code>I'm getting this error:\n[paste stack trace]\n\nContext:\n- The code is in [file path]\n- It's supposed to [describe expected behavior]\n- It fails when [describe when it fails]\n\nPlease:\n1. Identify the root cause\n2. Propose a fix\n3. Explain why this error occurred\n4. Suggest how to prevent similar bugs\n</code></pre>"},{"location":"coding/#speed-up-slow-code","title":"Speed up slow code","text":"<pre><code>This script takes too long to run. Profile it and suggest optimizations.\n\nConstraints:\n- Do not change outputs (results must be numerically identical)\n- Prefer simple optimizations over clever ones\n- If you suggest using a different library, explain the tradeoff\n\nShow me the before/after timing for any changes you make.\n</code></pre>"},{"location":"coding/#add-a-cli-interface","title":"Add a CLI interface","text":"<pre><code>Add a command-line interface to this script.\n\nRequirements:\n- Use argparse (or click if you prefer)\n- Required arguments: input_file, output_dir\n- Optional arguments: --config, --verbose, --seed\n- Include --help with clear descriptions\n- Add a main() entry point that parses args and runs the analysis\n</code></pre>"},{"location":"coding/#the-refactor-workflow","title":"The refactor workflow","text":"<ol> <li>Commit first - make sure you can undo everything</li> <li>Define \"same behavior\" - a test, a checksum, a comparison</li> <li>Ask for small changes - one refactor at a time</li> <li>Verify after each change - run the test before continuing</li> <li>Review the diff - understand what changed</li> </ol> <p>If a refactor breaks something, it's much easier to find the problem when changes are small.</p>"},{"location":"coding/#when-to-stop","title":"When to stop","text":"<p>Signs you're moving too fast:</p> <ul> <li>You can't explain what the agent changed</li> <li>You're approving diffs without reading them</li> <li>Tests are passing but you don't know why</li> <li>The code \"looks cleaner\" but you're not sure it's correct</li> </ul> <p>Slow down. The goal is correct, maintainable code\u2014not fast code.</p>"},{"location":"coding/#a-safe-refactor-prompt","title":"A safe refactor prompt","text":"<pre><code>Refactor this project for readability and reproducibility.\n\nConstraints:\n- Do not change scientific logic without asking\n- Keep outputs identical unless you explain why they differ\n- Make changes incrementally so I can review each step\n\nDefinition of done:\n- `make test` passes\n- `make figures` regenerates the main figures identically\n- I can read the diff and understand every change\n</code></pre>"},{"location":"coding/#see-also","title":"See also","text":"<ul> <li>Verification and Rigor</li> <li>Workflows (Plan-Do-Verify)</li> <li>Troubleshooting</li> </ul>"},{"location":"context/","title":"Why This Guide Exists","text":"<p>This guide started from a YouTube video.</p> <p>We intentionally do not store the full transcript in this public repo.</p> <p>In that transcript, a scientist describes attending an internal meeting at the Institute for Advanced Study focused on how \"agentic AI\" tools (named examples: Claude and Cursor) are changing research work. Several themes show up repeatedly:</p> <ul> <li>The tools are now strong enough at coding (and often math/reasoning) to materially change day-to-day research workflows.</li> <li>Getting value requires AI fluency: learning how to define tasks, break problems down, and iterate.</li> <li>Human oversight is still necessary (diff review, cross-checks, validation), but the human role shifts toward \"manager / verifier.\"</li> <li>Privacy, ethics, and cost are real concerns; people will make different tradeoffs.</li> <li>Skill atrophy is a legitimate risk; you need deliberate habits to stay sharp.</li> </ul> <p>This guide tries to turn those themes into concrete, low-friction steps a working scientist can apply.</p>"},{"location":"cost-control/","title":"Cost Control (Avoid Surprises)","text":"<p>AI tools cost money. Costs can creep up, especially if you use multiple tools, run long sessions, or feed large contexts. This page covers how to manage costs without sacrificing productivity.</p>"},{"location":"cost-control/#understanding-the-costs","title":"Understanding the costs","text":""},{"location":"cost-control/#subscription-models","title":"Subscription models","text":"<p>Most agentic tools use subscriptions:</p> Tool Free tier Paid tier Notes Claude Code Limited $20/mo (Pro), $100/mo (Max) Max includes 5x more usage Cursor Limited $20/mo (Pro), $40/mo (Business) Pro includes fast requests Codex CLI Limited Uses existing OpenAI/ChatGPT plan $20/mo ChatGPT Plus GitHub Copilot None $10/mo (Individual), $19/mo (Business) Free for students/OSS <p>For most scientists, a single $20/month subscription is sufficient to start.</p>"},{"location":"cost-control/#apiusage-based-costs","title":"API/usage-based costs","text":"<p>Some tools (or advanced usage) charge per token:</p> <ul> <li>Input tokens: The context you provide (code, docs, conversation history)</li> <li>Output tokens: What the model generates (usually more expensive)</li> </ul> <p>Rough pricing (varies by model): - Claude Opus 4.5: ~$15 per million input tokens, ~$75 per million output tokens - GPT-5.2: Similar range - Smaller models: 10-50x cheaper</p> <p>For most interactive use, subscription plans are more predictable. API pricing matters for automation or heavy usage.</p>"},{"location":"cost-control/#the-two-main-cost-drivers","title":"The two main cost drivers","text":""},{"location":"cost-control/#1-volume-how-many-requests-you-make","title":"1. Volume: How many requests you make","text":"<p>Each back-and-forth with the agent costs something. More iterations = more cost.</p> <p>Cost-saving strategies: - Be specific upfront (fewer clarification rounds) - Batch related requests together - Don't start over unnecessarily\u2014resume existing sessions</p>"},{"location":"cost-control/#2-size-how-much-context-you-feed","title":"2. Size: How much context you feed","text":"<p>Every time you ask something, the model sees your entire conversation history plus any files it's reading. Long contexts = higher costs.</p> <p>Cost-saving strategies: - Keep conversations focused - Start fresh sessions for unrelated tasks - Don't dump entire codebases\u2014point to specific files - Use project instructions (CLAUDE.md) instead of repeating context</p>"},{"location":"cost-control/#practical-ways-to-reduce-cost","title":"Practical ways to reduce cost","text":""},{"location":"cost-control/#keep-tasks-small-and-incremental","title":"Keep tasks small and incremental","text":"<p>Instead of: <pre><code>Refactor this entire codebase for better organization\n</code></pre></p> <p>Try: <pre><code>Refactor the data loading functions in src/data.py\n</code></pre></p> <p>Smaller tasks = less context = fewer iterations = lower cost.</p>"},{"location":"cost-control/#reuse-instructions-instead-of-repeating-context","title":"Reuse instructions instead of repeating context","text":"<p>If you always want the agent to follow certain rules, put them in your project configuration (CLAUDE.md, .cursorrules, etc.) rather than repeating them each time.</p> <p>Expensive (repeated every time): <pre><code>Remember, don't change scientific logic without asking.\nAlso, always run tests after changes.\nAnd use numpy, not loops.\n...\n[50 lines of instructions]\n</code></pre></p> <p>Cheap (set once): <pre><code># CLAUDE.md\n- Never change scientific logic without approval\n- Run pytest after each code change\n- Prefer numpy vectorization over loops\n</code></pre></p>"},{"location":"cost-control/#provide-small-samples-instead-of-full-datasets","title":"Provide small samples instead of full datasets","text":"<p>Don't paste 10,000 lines of data. Give a representative sample:</p> <pre><code>Here's a sample of the data format (first 20 rows):\n[paste sample]\n\nThe full file has 50,000 rows in the same format.\nProcess data/full_dataset.csv using this format.\n</code></pre>"},{"location":"cost-control/#ask-for-a-plan-before-expensive-execution","title":"Ask for a plan before expensive execution","text":"<p>Before the agent spends tokens on implementation:</p> <pre><code>Before writing code, outline your approach.\nI'll review and we can adjust before you implement.\n</code></pre> <p>This catches misunderstandings before they become expensive rewrites.</p>"},{"location":"cost-control/#use-appropriate-models-for-each-task","title":"Use appropriate models for each task","text":"<p>Not every task needs the most powerful (expensive) model.</p> <p>Use powerful models (Opus 4.5, GPT-5.2 High) for: - Complex debugging - Tricky algorithmic problems - Tasks where correctness is critical - Multi-step reasoning</p> <p>Use faster/cheaper models for: - Simple refactoring - Writing tests for existing code - Generating boilerplate - Formatting and cleanup</p> <p>Some tools let you switch models mid-session. Others require configuration.</p>"},{"location":"cost-control/#tier-your-work","title":"Tier your work","text":"<p>A good default strategy:</p> Task type Model tier Example Drafting, exploration Cheap/fast \"What approaches could work for X?\" Implementation Standard \"Write a function that does Y\" Critical debugging Premium \"This calculation is wrong and I can't figure out why\" Final review Premium \"Review this for correctness before I publish\""},{"location":"cost-control/#watch-for-runaway-costs","title":"Watch for runaway costs","text":""},{"location":"cost-control/#signs-of-trouble","title":"Signs of trouble","text":"<ul> <li>Very long conversations (100+ turns)</li> <li>Repeatedly pasting large files</li> <li>The agent going in circles</li> <li>Sessions that span multiple days without progress</li> </ul>"},{"location":"cost-control/#what-to-do","title":"What to do","text":"<ol> <li>Start fresh: Long conversations accumulate context. A new session is often more efficient.</li> <li>Be more specific: Vague prompts lead to more back-and-forth.</li> <li>Check your understanding: If the agent keeps misunderstanding, the problem might be your prompt.</li> <li>Take a break: Sometimes stepping away and returning with fresh eyes is the most cost-effective solution.</li> </ol>"},{"location":"cost-control/#institutional-budgeting","title":"Institutional budgeting","text":"<p>If your lab or institution is paying:</p>"},{"location":"cost-control/#pick-a-primary-tool","title":"Pick a primary tool","text":"<p>Don't let everyone use different tools. Standardize on one to: - Simplify billing - Enable shared knowledge - Make support easier</p>"},{"location":"cost-control/#track-usage-monthly","title":"Track usage monthly","text":"<p>Most tools provide usage dashboards. Review them: - Who's using how much? - Are costs stable or growing? - Is the value worth the cost?</p>"},{"location":"cost-control/#set-expectations","title":"Set expectations","text":"<p>Decide in advance: - What tier of subscription is standard? - What usage is \"normal\" vs. concerning? - How to handle requests for upgrades?</p>"},{"location":"cost-control/#consider-institutional-licenses","title":"Consider institutional licenses","text":"<p>Some tools offer team/institutional pricing that's cheaper per-seat than individual subscriptions. Worth asking about for groups of 5+.</p>"},{"location":"cost-control/#cost-vs-value","title":"Cost vs. value","text":"<p>Remember: the goal isn't minimizing cost, it's maximizing value per dollar.</p> <p>A $100/month subscription that saves 10 hours/month is a great deal ($10/hour for your time back). A $20/month subscription you never use is a waste.</p> <p>Questions to ask: - Is this tool saving me time? - Am I using it regularly? - Could a cheaper option work as well? - Is the premium tier worth 5x the cost?</p>"},{"location":"cost-control/#see-also","title":"See also","text":"<ul> <li>Which Models to Use</li> <li>Pick Your Tools</li> <li>Lab Rollout</li> </ul>"},{"location":"data-analysis/","title":"Data Analysis (AI-Assisted)","text":"<p>AI can help you write analysis code quickly. The risk is silent wrongness.</p>"},{"location":"data-analysis/#what-to-insist-on","title":"What to insist on","text":"<ul> <li>a minimal reproducible script</li> <li>a config file for parameters</li> <li>sanity checks on shapes, units, and ranges</li> <li>deterministic outputs (seeded randomness)</li> </ul>"},{"location":"data-analysis/#typical-wins","title":"Typical wins","text":"<ul> <li>cleaning up messy scripts</li> <li>turning notebooks into pipelines</li> <li>adding tests and validations</li> <li>speeding up plotting and reporting</li> </ul>"},{"location":"data-analysis/#typical-traps","title":"Typical traps","text":"<ul> <li>incorrect joins / merges</li> <li>wrong filtering</li> <li>subtle unit conversions</li> <li>plotting post-processed data without recording steps</li> </ul>"},{"location":"data-analysis/#common-pitfalls-in-pandas-numpy-code","title":"Common pitfalls in pandas / numpy code","text":"<p>AI-generated data analysis code often introduces subtle bugs. Watch for:</p> <p>Indexing and alignment: - Mixing <code>.loc</code> and <code>.iloc</code> incorrectly - Losing index alignment after operations - Off-by-one errors in slicing</p> <p>Data types: - Silent type coercion (strings to numbers, floats to ints) - Datetime parsing assumptions (timezone, format) - Categorical vs string confusion</p> <p>Missing data: - <code>NaN</code> propagation in calculations - <code>dropna()</code> applied too broadly or too narrowly - Filling missing values with inappropriate defaults</p> <p>Aggregation: - <code>groupby</code> dropping groups unexpectedly - Wrong aggregation function (mean vs sum vs count) - Multi-index confusion after groupby</p> <p>Joins and merges: - Wrong join type (inner vs outer vs left) - Duplicate rows from many-to-many joins - Key column mismatches (whitespace, case, type)</p>"},{"location":"data-analysis/#validation-patterns-for-statistical-code","title":"Validation patterns for statistical code","text":"<p>Before trusting any statistical result:</p> <ol> <li>Check shapes: Print <code>.shape</code> before and after every transformation.</li> <li>Check ranges: Are values in expected bounds? Any negative values where there should not be?</li> <li>Check distributions: Quick histograms or <code>.describe()</code> to catch anomalies.</li> <li>Synthetic data test: Run on data where you know the answer.</li> <li>Limiting cases: What happens with N=1, N=0, all identical values?</li> </ol>"},{"location":"data-analysis/#when-to-use-sql-vs-dataframes","title":"When to use SQL vs DataFrames","text":"<p>Prefer SQL when: - Data is already in a database - Joins are complex and well-defined - You want the database to optimize the query plan - Reproducibility is easier (query is a string you can save)</p> <p>Prefer DataFrames when: - Data is in files (CSV, Parquet, etc.) - You need iterative, exploratory analysis - Custom transformations are easier in Python/R - Integration with plotting and modeling libraries</p>"},{"location":"data-analysis/#a-practical-definition-of-done","title":"A practical definition of done","text":"<ul> <li>\"Fresh clone -&gt; install deps -&gt; run one command -&gt; produces figure/table\"</li> </ul>"},{"location":"data-analysis/#example-notebook-to-pipeline-prompt","title":"Example: notebook to pipeline prompt","text":"<pre><code>Convert this Jupyter notebook into a reproducible pipeline.\n\nRequirements:\n1. Extract all parameters into a config file (YAML or JSON).\n2. Create a single entry-point script that:\n   - Loads the config\n   - Runs the analysis\n   - Saves outputs to a predictable location\n3. Add shape/sanity checks after each major step.\n4. Pin dependencies in requirements.txt.\n5. Ensure outputs are identical to the notebook (or explain differences).\n\nDo not change the scientific logic without asking.\n</code></pre>"},{"location":"data-analysis/#see-also","title":"See also","text":"<ul> <li>Figures and Tables</li> <li>Reproducibility</li> <li>Verification and Rigor</li> </ul>"},{"location":"disclosure/","title":"Disclosure and Attribution","text":"<p>Using AI in research raises questions about transparency. What do you need to disclose? When? To whom? The norms are still evolving, but this page covers the current best practices.</p>"},{"location":"disclosure/#the-core-principle","title":"The core principle","text":"<p>Be honest about how your work was produced.</p> <p>If AI assistance materially contributed to your code, analysis, or writing, say so. Not because AI is bad, but because transparency is a scientific value.</p>"},{"location":"disclosure/#what-to-disclose","title":"What to disclose","text":""},{"location":"disclosure/#definitely-disclose","title":"Definitely disclose","text":"<ul> <li>AI-generated text that appears in the manuscript</li> <li>AI-assisted code that produced key results or figures</li> <li>AI-generated figures or visualizations</li> <li>Significant refactoring or debugging done by AI</li> </ul>"},{"location":"disclosure/#probably-disclose","title":"Probably disclose","text":"<ul> <li>AI-assisted literature review or summarization</li> <li>AI help with LaTeX formatting or equation typesetting</li> <li>AI-generated boilerplate (Makefiles, configs, tests)</li> </ul>"},{"location":"disclosure/#usually-not-necessary-to-disclose","title":"Usually not necessary to disclose","text":"<ul> <li>Using AI for grammar/spelling checks (similar to Grammarly)</li> <li>Asking AI to explain a concept you then applied yourself</li> <li>Using AI as a search engine or documentation lookup</li> </ul> <p>The line is: did the AI do substantive intellectual work that appears in the final output?</p>"},{"location":"disclosure/#how-to-disclose","title":"How to disclose","text":""},{"location":"disclosure/#in-papers-and-manuscripts","title":"In papers and manuscripts","text":"<p>Most journals now have specific policies. Check your target journal first.</p> <p>If they don't have a policy, add a disclosure in the methods or acknowledgments:</p> <p>Example (minimal): <pre><code>We used AI-assisted tools (Claude Code) for code refactoring and debugging.\nAll scientific analyses and conclusions were performed and verified by the authors.\n</code></pre></p> <p>Example (detailed): <pre><code>AI assistance was used in the following ways:\n- Code refactoring and test generation (Claude Code)\n- Clarity editing of manuscript text (Claude)\n- LaTeX formatting of equations\n\nAll scientific claims, analyses, statistical interpretations, and conclusions\nwere performed by the authors. AI-generated code was reviewed via diff and\nverified against expected outputs. No AI-generated citations were used; all\nreferences were verified by the authors.\n</code></pre></p>"},{"location":"disclosure/#in-grant-proposals","title":"In grant proposals","text":"<p>Check your funding agency's policy. NSF, NIH, and others are developing guidelines.</p> <p>A safe default: <pre><code>AI writing assistance was used to improve clarity and structure.\nAll scientific content, proposed methods, and claims of novelty are the\noriginal work of the investigators.\n</code></pre></p>"},{"location":"disclosure/#in-code-repositories","title":"In code repositories","text":"<p>Add a note to your README:</p> <pre><code>## AI Assistance\n\nThis codebase was developed with assistance from Claude Code.\nAI-generated code was reviewed and tested by the authors.\nCommit history shows the evolution of AI-assisted changes.\n</code></pre>"},{"location":"disclosure/#what-not-to-do","title":"What NOT to do","text":""},{"location":"disclosure/#dont-list-ai-as-an-author","title":"Don't list AI as an author","text":"<p>AI systems cannot take responsibility for the work, respond to reviewer comments, or be held accountable for errors. Author status requires accountability.</p>"},{"location":"disclosure/#dont-let-ai-invent-citations","title":"Don't let AI invent citations","text":"<p>AI will confidently generate plausible-looking citations that don't exist. Every reference must be verified by a human.</p> <p>Bad: \"According to Smith et al. (2023)...\" [AI generated this]</p> <p>Good: [You found and read the actual paper, then cited it]</p>"},{"location":"disclosure/#dont-hide-ai-involvement","title":"Don't hide AI involvement","text":"<p>If reviewers or readers later discover significant AI involvement that wasn't disclosed, it damages trust. Be upfront.</p>"},{"location":"disclosure/#dont-over-claim-ai-contribution","title":"Don't over-claim AI contribution","text":"<p>If you used AI for spell-checking, you don't need a paragraph about it. Match the disclosure to the significance.</p>"},{"location":"disclosure/#journal-policies-as-of-2026","title":"Journal policies (as of 2026)","text":"<p>Policies vary by journal and change frequently. Check your target journal directly.</p> <p>Common patterns:</p> <ul> <li>Nature family: Requires disclosure of AI use; AI cannot be an author</li> <li>Science family: Similar requirements; emphasis on human accountability</li> <li>PNAS: Requires disclosure; provides template language</li> <li>IEEE/ACM: Varies by specific journal; check guidelines</li> <li>arXiv: No specific policy; use your judgment</li> </ul> <p>To find a journal's policy:</p> <ol> <li>Check the \"Instructions for Authors\" or \"Author Guidelines\"</li> <li>Search for \"AI\" or \"artificial intelligence\" or \"language model\"</li> <li>If nothing found, contact the editor</li> </ol>"},{"location":"disclosure/#reproducibility-as-a-form-of-transparency","title":"Reproducibility as a form of transparency","text":"<p>The best disclosure is reproducibility. If your code is public and your workflow is documented:</p> <ul> <li>Others can see exactly what the AI did (via commit history)</li> <li>Others can verify results independently</li> <li>The AI's contribution is implicitly visible</li> </ul> <p>This is better than a vague disclosure statement.</p>"},{"location":"disclosure/#when-youre-unsure","title":"When you're unsure","text":"<p>Ask yourself:</p> <ol> <li>Would I be comfortable if a reviewer knew exactly how this was produced?</li> <li>Would I be comfortable if it appeared in a news story?</li> <li>Does the disclosure match what I would want to read if I were the reader?</li> </ol> <p>If the answer is \"no\" to any of these, add more transparency.</p>"},{"location":"disclosure/#the-evolving-landscape","title":"The evolving landscape","text":"<p>AI use in research is new. Norms will shift. The safe approach:</p> <ul> <li>Be more transparent than you think necessary</li> <li>Keep records of how AI was used</li> <li>Stay informed about your field's evolving standards</li> <li>When in doubt, disclose</li> </ul> <p>In five years, this will all be clearer. For now, err on the side of openness.</p>"},{"location":"disclosure/#see-also","title":"See also","text":"<ul> <li>Safety, Privacy, and Policy</li> <li>Reproducibility</li> <li>Lab Policy Template</li> </ul>"},{"location":"faq/","title":"FAQ","text":""},{"location":"faq/#is-this-going-to-replace-scientists","title":"Is this going to replace scientists?","text":"<p>No one knows. But it is already changing the day-to-day work.</p> <p>The most robust stance is: learn to use it, keep your verification habits strong, and keep your scientific judgment sharp.</p>"},{"location":"faq/#will-i-lose-my-skills","title":"Will I lose my skills?","text":"<p>Skill atrophy is real if you stop thinking.</p> <p>Mitigations:</p> <ul> <li>keep doing some work \"by hand\" (derivations, small scripts)</li> <li>require the agent to explain reasoning</li> <li>use it to teach you, not just to produce output</li> </ul>"},{"location":"faq/#can-i-trust-citations","title":"Can I trust citations?","text":"<p>Not by default.</p> <p>If you did not provide sources, assume citations may be invented.</p>"},{"location":"faq/#can-i-use-this-with-r-matlab-julia-other-languages","title":"Can I use this with R / Matlab / Julia / other languages?","text":"<p>Yes. Agentic tools work with any language that can be edited as text files and run from a terminal. Python examples dominate this guide because it is the most common in scientific computing, but the workflows apply equally to R scripts, Matlab <code>.m</code> files, Julia code, or shell scripts.</p> <p>The key is the same: define the goal, let the agent edit and run, verify the output.</p>"},{"location":"faq/#what-if-my-institution-blocks-these-tools","title":"What if my institution blocks these tools?","text":"<p>Options:</p> <ul> <li>Check if your institution has an approved alternative (some have enterprise agreements with specific vendors).</li> <li>Use a personal device on a personal network for non-sensitive, public-data work.</li> <li>Ask IT about the specific policy\u2014sometimes \"blocked\" means \"not yet evaluated.\"</li> <li>See Burner Machine and Sandboxes for isolation strategies.</li> </ul> <p>If you genuinely cannot use external tools, some of the prompting and verification habits in this guide still apply to local models or approved internal systems.</p>"},{"location":"faq/#how-do-i-explain-this-to-skeptical-colleagues-or-advisors","title":"How do I explain this to skeptical colleagues or advisors?","text":"<p>Focus on:</p> <ul> <li>Verification: \"I review every change and run tests before trusting results.\"</li> <li>Reproducibility: \"The workflow produces one-command reproducible outputs.\"</li> <li>Transparency: \"I disclose AI assistance and can show exactly what it did (diffs, logs).\"</li> </ul> <p>Skepticism is healthy. The goal is not to convince anyone that AI is magic, but to show that your specific workflow maintains scientific rigor.</p>"},{"location":"faq/#what-about-code-i-wrote-with-aido-i-own-it","title":"What about code I wrote with AI\u2014do I own it?","text":"<p>Generally, yes\u2014you own code you produce using AI tools, just as you own code you write with autocomplete or Stack Overflow snippets. However:</p> <ul> <li>Check your institution's IP policies.</li> <li>Check the terms of service of the specific tool.</li> <li>If you are working on proprietary or patentable code, consult your tech transfer office.</li> </ul> <p>This is not legal advice.</p>"},{"location":"faq/#which-model-is-best-for-x","title":"Which model is best for X?","text":"<p>It changes constantly. As of early 2026:</p> <ul> <li>Claude (Sonnet/Opus): strong at multi-file refactors, long context, and reasoning</li> <li>GPT-4 / GPT-4o: good general-purpose, wide tool ecosystem</li> <li>Gemini: strong at very long documents and multimodal tasks</li> </ul> <p>For most scientist workflows, any of the top-tier models will work. Pick based on what your institution supports and what you can afford.</p> <p>See: Multi-Model Strategy</p>"},{"location":"faq/#the-agent-made-a-mess-of-my-code-how-do-i-recover","title":"The agent made a mess of my code. How do I recover?","text":"<p>If you are using git (you should be):</p> <ul> <li><code>git diff</code> to see what changed</li> <li><code>git stash</code> to set aside changes temporarily</li> <li><code>git checkout .</code> to discard all uncommitted changes</li> <li><code>git reset --hard HEAD~1</code> to undo the last commit (use with caution)</li> </ul> <p>If you are not using git, your options are limited. This is why version control is non-negotiable for agentic workflows.</p> <p>See: Troubleshooting</p>"},{"location":"faq/#how-do-i-know-when-a-session-is-too-long","title":"How do I know when a session is \"too long\"?","text":"<p>Signs:</p> <ul> <li>The agent starts forgetting earlier instructions</li> <li>Responses become repetitive or less coherent</li> <li>It makes mistakes it would not have made earlier</li> </ul> <p>Rule of thumb: if a session has been running for more than 30-60 minutes of active work, or if you have pasted a lot of context, consider starting fresh. Summarize what you accomplished and begin a new session with a clean slate.</p>"},{"location":"faq/#see-also","title":"See also","text":"<ul> <li>Troubleshooting</li> <li>Safety, Privacy, and Policy</li> <li>Disclosure</li> </ul>"},{"location":"figures/","title":"Figures and Tables","text":"<p>Figures are where incorrect code becomes persuasive. A plot can look professional while being completely wrong. This page covers how to make figures you can trust.</p>"},{"location":"figures/#the-golden-standard","title":"The golden standard","text":"<p>Every figure in a paper should satisfy:</p> <ol> <li>One command regenerates it - <code>make fig2</code> or <code>python scripts/make_fig_2.py</code></li> <li>Clear source script - anyone can find the code that made it</li> <li>Recorded inputs - which data files, which parameters, which random seed</li> <li>Visible provenance - the figure itself (or a companion file) says how it was made</li> </ol> <p>If you cannot regenerate a figure from scratch, you cannot trust it.</p>"},{"location":"figures/#a-practical-file-structure","title":"A practical file structure","text":"<pre><code>project/\n  scripts/\n    make_fig_1.py\n    make_fig_2.py\n    make_all_figures.py\n  configs/\n    fig_1.yaml\n    fig_2.yaml\n  results/\n    figures/\n      fig_1.png\n      fig_1_provenance.json\n      fig_2.png\n      fig_2_provenance.json\n  data/\n    raw/\n    processed/\n</code></pre> <p>Each figure script reads a config and writes both the figure and a provenance record.</p>"},{"location":"figures/#what-to-put-in-a-config-file","title":"What to put in a config file","text":"<pre><code># configs/fig_2.yaml\ndata_file: data/processed/experiment_results.csv\noutput_path: results/figures/fig_2.png\nrandom_seed: 42\nfilter_condition: \"quality &gt; 0.8\"\nplot_style: paper\ndpi: 300\nfigure_size: [8, 6]\n</code></pre> <p>This makes it trivial to regenerate figures and see exactly what parameters produced them.</p>"},{"location":"figures/#provenance-records","title":"Provenance records","text":"<p>After generating a figure, write a small JSON file alongside it:</p> <pre><code>{\n  \"generated_at\": \"2026-01-15T14:32:00Z\",\n  \"script\": \"scripts/make_fig_2.py\",\n  \"config\": \"configs/fig_2.yaml\",\n  \"data_hash\": \"sha256:abc123...\",\n  \"git_commit\": \"d6958af\",\n  \"python_version\": \"3.11.5\",\n  \"key_packages\": {\n    \"matplotlib\": \"3.8.0\",\n    \"pandas\": \"2.1.0\"\n  }\n}\n</code></pre> <p>This answers the question \"how was this figure made?\" months later.</p>"},{"location":"figures/#verification-checks-for-figures","title":"Verification checks for figures","text":"<p>Before trusting any AI-generated figure code:</p>"},{"location":"figures/#visual-sanity-checks","title":"Visual sanity checks","text":"<ul> <li>Are axes labeled with units?</li> <li>Is the scale sensible? (Check min/max values)</li> <li>Are you plotting what you think you're plotting?</li> <li>Do colors/legends match what they claim to represent?</li> </ul>"},{"location":"figures/#data-sanity-checks","title":"Data sanity checks","text":"<ul> <li>How many data points? (Print the count)</li> <li>What's the range? (Print min/max/mean)</li> <li>Any unexpected NaNs or infinities?</li> <li>Does a random subsample look reasonable?</li> </ul>"},{"location":"figures/#reproducibility-checks","title":"Reproducibility checks","text":"<ul> <li>Run it twice with the same seed\u2014identical output?</li> <li>Run it on a fresh clone\u2014still works?</li> <li>Change one parameter\u2014output changes as expected?</li> </ul>"},{"location":"figures/#common-figure-mistakes-ai-makes","title":"Common figure mistakes AI makes","text":""},{"location":"figures/#wrong-column-plotted","title":"Wrong column plotted","text":"<p>The agent picks <code>column_a</code> when you meant <code>column_b</code>. Always verify which data is actually being plotted.</p> <p>Fix: Add a print statement showing the first few values of what's being plotted.</p>"},{"location":"figures/#silent-filtering","title":"Silent filtering","text":"<p>The agent adds a filter that drops half your data without telling you.</p> <p>Fix: Print data shape before and after any filtering step.</p>"},{"location":"figures/#incorrect-aggregation","title":"Incorrect aggregation","text":"<p>Mean vs median vs sum confusion, or grouping by the wrong key.</p> <p>Fix: Check aggregated values against a hand calculation on a small subset.</p>"},{"location":"figures/#preprocessing-not-recorded","title":"Preprocessing not recorded","text":"<p>The raw data was transformed (normalized, log-scaled, outliers removed) but this isn't documented.</p> <p>Fix: Every transformation should be in the script, not done manually beforehand.</p>"},{"location":"figures/#misleading-axis-scales","title":"Misleading axis scales","text":"<p>Log scales that hide important variation, or truncated axes that exaggerate differences.</p> <p>Fix: Always start with linear scales and full ranges. Adjust only with justification.</p>"},{"location":"figures/#a-prompt-for-figure-generation","title":"A prompt for figure generation","text":"<pre><code>Create a script to generate Figure 2 from my analysis.\n\nContext:\n- Data is in data/processed/results.csv\n- Columns are: [list your columns]\n- This figure shows [describe what it should show]\n\nRequirements:\n- Read parameters from a config file (configs/fig_2.yaml)\n- Print data shape and summary stats before plotting\n- Save figure to results/figures/fig_2.png\n- Save provenance info to results/figures/fig_2_provenance.json\n- Use a fixed random seed if any randomness is involved\n\nVerification:\n- Show me the first 5 rows of data being plotted\n- Print min/max/mean of the plotted values\n- The script should work from a fresh clone with `python scripts/make_fig_2.py`\n</code></pre>"},{"location":"figures/#tables-follow-the-same-rules","title":"Tables follow the same rules","text":"<p>Tables in papers should be:</p> <ul> <li>Generated by a script, not manually typed</li> <li>Reproducible from raw data</li> <li>Include the same provenance tracking</li> </ul> <p>For LaTeX tables, generate the <code>.tex</code> file programmatically:</p> <pre><code>df.to_latex('results/tables/table_1.tex', index=False, float_format='%.3f')\n</code></pre>"},{"location":"figures/#the-figure-audit-before-submission","title":"The \"figure audit\" before submission","text":"<p>Before submitting a paper, verify every figure:</p> <ol> <li>Can you regenerate it from <code>make figures</code>?</li> <li>Does the script show its data sources clearly?</li> <li>Is every preprocessing step in the code (not done manually)?</li> <li>Do the axis labels and legends match the actual data?</li> <li>Is there a provenance record?</li> </ol> <p>If any answer is \"no,\" fix it before submission.</p>"},{"location":"figures/#see-also","title":"See also","text":"<ul> <li>Data Analysis</li> <li>Reproducibility</li> <li>Prompt Templates</li> </ul>"},{"location":"first-hour/","title":"First Hour: A Safe, Useful Win","text":"<p>Goal: get one small, real task done with an agentic tool, while keeping risk low.</p> <p>This exercise takes 30-60 minutes. By the end, you'll have hands-on experience with the core loop: ask \u2192 review \u2192 verify \u2192 commit.</p>"},{"location":"first-hour/#before-you-start","title":"Before you start","text":""},{"location":"first-hour/#pick-a-safe-project","title":"Pick a safe project","text":"<p>Use something where mistakes don't matter:</p> <ul> <li>A personal side project</li> <li>A copy of a real project (not the original)</li> <li>An old analysis you're not actively using</li> <li>A fresh test repository</li> </ul> <p>Do not use: - Code with sensitive data - Production systems - Anything where breaking it would be a problem</p>"},{"location":"first-hour/#verify-its-under-version-control","title":"Verify it's under version control","text":"<pre><code>cd your-project\ngit status\n</code></pre> <p>If you see \"not a git repository,\" initialize one:</p> <pre><code>git init\ngit add .\ngit commit -m \"Initial state before AI assistance\"\n</code></pre> <p>This lets you see exactly what changes and undo anything you don't like.</p>"},{"location":"first-hour/#open-your-agentic-tool","title":"Open your agentic tool","text":"<p>Start Claude Code, Cursor, or whichever tool you chose:</p> <pre><code># Claude Code\nclaude\n\n# Codex CLI\ncodex\n</code></pre> <p>Navigate to your project folder.</p>"},{"location":"first-hour/#pick-one-task","title":"Pick one task","text":"<p>Choose one of these. Don't try to do everything at once.</p>"},{"location":"first-hour/#option-1-add-a-readme-easiest","title":"Option 1: Add a README (easiest)","text":"<p>Good for: any project without documentation</p> <pre><code>Create a README.md that explains:\n- What this project does (based on reading the code)\n- How to install dependencies\n- How to run the main script\n- What outputs to expect\n\nRead the existing code first to understand the project.\nKeep the README concise (under 100 lines).\n</code></pre> <p>What success looks like: A clear README that accurately describes your project.</p>"},{"location":"first-hour/#option-2-add-a-minimal-test","title":"Option 2: Add a minimal test","text":"<p>Good for: projects with no tests</p> <pre><code>Add a minimal test for the main functionality.\n\nRequirements:\n- Use pytest\n- Test that the main function runs without error on a tiny sample\n- Keep the test simple and fast\n\nRead the code first to understand what to test.\nCreate a tests/ directory if it doesn't exist.\nRun the test to verify it passes.\n</code></pre> <p>What success looks like: <code>pytest tests/</code> runs and passes.</p>"},{"location":"first-hour/#option-3-create-a-makefile","title":"Option 3: Create a Makefile","text":"<p>Good for: projects with multiple manual steps</p> <pre><code>Create a Makefile with these targets:\n- make install: install dependencies\n- make test: run tests (or a simple verification)\n- make run: run the main analysis/script\n\nLook at the existing code to understand what commands are needed.\nTest each target to make sure it works.\n</code></pre> <p>What success looks like: Each <code>make</code> command runs the right thing.</p>"},{"location":"first-hour/#option-4-clean-up-one-messy-script","title":"Option 4: Clean up one messy script","text":"<p>Good for: scripts that have gotten out of hand</p> <pre><code>Refactor this script for clarity:\n[paste or point to the script]\n\nRules:\n- Do not change what the script does\n- Extract functions where it improves readability\n- Add brief docstrings to functions\n- Keep the same inputs and outputs\n\nPropose a plan before making changes.\nRun the script before and after to verify outputs match.\n</code></pre> <p>What success looks like: Same output, cleaner code.</p>"},{"location":"first-hour/#the-prompt-template","title":"The prompt template","text":"<p>Whichever task you choose, wrap it in this template:</p> <pre><code>Act like a careful research software engineer.\n\nBefore editing anything:\n1. Summarize what you think this project does\n2. Propose a short plan for the task\n3. Wait for my approval before making changes\n\nRules:\n- Keep changes small and reviewable\n- Run verification after changes\n- Explain how to undo if something goes wrong\n\nTask:\n[paste your chosen task here]\n</code></pre> <p>This template enforces the plan-do-verify workflow from the start.</p>"},{"location":"first-hour/#what-to-expect","title":"What to expect","text":""},{"location":"first-hour/#the-agent-reads-your-project","title":"The agent reads your project","text":"<p>It will explore your files to understand the codebase. You'll see it reading various files. This is normal.</p>"},{"location":"first-hour/#the-agent-proposes-a-plan","title":"The agent proposes a plan","text":"<p>Before making changes, it should tell you what it intends to do. Review this. If it misunderstands something, correct it.</p>"},{"location":"first-hour/#the-agent-makes-changes","title":"The agent makes changes","text":"<p>You'll see edits being made to files. In Claude Code, you'll be asked to approve changes. In other tools, you might see them happen directly.</p>"},{"location":"first-hour/#the-agent-runs-verification","title":"The agent runs verification","text":"<p>It should run something to confirm the changes work\u2014tests, the script itself, a linter.</p>"},{"location":"first-hour/#after-the-agent-finishes","title":"After the agent finishes","text":""},{"location":"first-hour/#review-the-diff","title":"Review the diff","text":"<p>See exactly what changed:</p> <pre><code>git diff\n</code></pre> <p>or in your IDE's diff view.</p> <p>Read through the changes. Do they make sense? Did the agent change anything unexpected?</p>"},{"location":"first-hour/#run-verification-yourself","title":"Run verification yourself","text":"<p>Don't just trust that the agent's verification worked. Run it yourself:</p> <pre><code># For a test\npytest tests/\n\n# For a Makefile\nmake test\nmake run\n\n# For a script\npython your_script.py\n</code></pre>"},{"location":"first-hour/#commit-if-it-looks-good","title":"Commit if it looks good","text":"<pre><code>git add .\ngit commit -m \"Add README via Claude Code\n\nCo-Authored-By: Claude &lt;noreply@anthropic.com&gt;\"\n</code></pre>"},{"location":"first-hour/#or-revert-if-it-doesnt","title":"Or revert if it doesn't","text":"<pre><code>git checkout .\n</code></pre> <p>This undoes all changes. That's why version control matters.</p>"},{"location":"first-hour/#what-success-looks-like","title":"What \"success\" looks like","text":"<p>After your first hour, you should be able to say:</p> <ul> <li>\u2705 I can point to a diff and explain what changed</li> <li>\u2705 I can run one command and see it work</li> <li>\u2705 I didn't paste any sensitive data</li> <li>\u2705 I understand the plan \u2192 do \u2192 verify loop</li> <li>\u2705 I know how to undo changes if needed</li> </ul>"},{"location":"first-hour/#common-first-hour-problems","title":"Common first-hour problems","text":""},{"location":"first-hour/#the-agent-is-confused-about-my-project","title":"\"The agent is confused about my project\"","text":"<p>It might misunderstand what your code does. This is fine\u2014correct it:</p> <pre><code>That's not quite right. This script processes [X], not [Y].\nThe main entry point is [file]. Try again with that understanding.\n</code></pre>"},{"location":"first-hour/#the-changes-dont-work","title":"\"The changes don't work\"","text":"<p>Revert and try a more specific prompt:</p> <pre><code>The test you wrote fails because [reason].\nFix the test to handle [specific issue].\n</code></pre>"},{"location":"first-hour/#it-changed-things-i-didnt-ask-for","title":"\"It changed things I didn't ask for\"","text":"<p>Be more explicit about scope:</p> <pre><code>Only modify [specific file].\nDo not touch any other files.\n</code></pre>"},{"location":"first-hour/#i-dont-understand-the-changes","title":"\"I don't understand the changes\"","text":"<p>Ask for explanation:</p> <pre><code>Explain what this change does and why you made it.\n</code></pre> <p>Never accept changes you don't understand.</p>"},{"location":"first-hour/#whats-next","title":"What's next","text":"<p>Once you've completed this first hour:</p> <ol> <li>Try another task on the same project</li> <li>Move to a slightly more complex task</li> <li>Work through the AI Fluency week</li> <li>Set up a CLAUDE.md with your preferences</li> </ol> <p>The goal is building fluency through practice. The first hour is just the beginning.</p>"},{"location":"first-hour/#see-also","title":"See also","text":"<ul> <li>Why Agentic AI</li> <li>Workflows (Plan-Do-Verify)</li> <li>AI Fluency (1-Week Ramp)</li> <li>Troubleshooting</li> </ul>"},{"location":"git-basics/","title":"Git Basics (So You Can Review and Undo)","text":"<p>Git is the safety harness for agentic AI. When an agent can change dozens of files in seconds, you need a way to see exactly what changed and undo mistakes instantly. That's git.</p> <p>You don't need to master git. You need to know enough to stay safe.</p>"},{"location":"git-basics/#the-mental-model","title":"The mental model","text":"<ul> <li>Repository (repo): A folder where git tracks changes</li> <li>Commit: A snapshot of your project at a point in time</li> <li>Diff: A view of what changed between two points</li> <li>Branch: A parallel version of your project (for experiments)</li> <li>Staging area: Where you prepare changes before committing</li> </ul> <p>Think of commits like save points in a video game. You can always go back.</p>"},{"location":"git-basics/#the-essential-commands","title":"The essential commands","text":""},{"location":"git-basics/#see-whats-happening","title":"See what's happening","text":"<pre><code>git status              # What files changed? What's staged?\ngit diff                # Show unstaged changes (what you haven't added yet)\ngit diff --staged       # Show staged changes (what you're about to commit)\ngit log --oneline -10   # Show last 10 commits\n</code></pre> <p>Run <code>git status</code> constantly. It's your best friend.</p>"},{"location":"git-basics/#save-your-work","title":"Save your work","text":"<pre><code>git add filename.py     # Stage a specific file\ngit add -A              # Stage all changes (use carefully)\ngit commit -m \"message\" # Create a commit with a message\n</code></pre> <p>Write commit messages that explain why, not just what: - Bad: \"Update analysis.py\" - Good: \"Fix off-by-one error in bootstrap resampling\"</p>"},{"location":"git-basics/#undo-mistakes","title":"Undo mistakes","text":"<pre><code>git diff                 # See what changed before deciding\ngit checkout -- file.py  # Discard changes to one file\ngit checkout .           # Discard ALL uncommitted changes (careful!)\ngit reset HEAD~1         # Undo the last commit (keep changes as unstaged)\ngit reset --hard HEAD~1  # Undo the last commit AND discard changes (very careful!)\n</code></pre>"},{"location":"git-basics/#work-with-branches","title":"Work with branches","text":"<pre><code>git branch                    # List branches\ngit checkout -b experiment    # Create and switch to new branch\ngit checkout main             # Switch back to main\ngit merge experiment          # Merge experiment into current branch\n</code></pre>"},{"location":"git-basics/#why-scientists-should-care","title":"Why scientists should care","text":""},{"location":"git-basics/#you-can-always-see-what-changed","title":"You can always see what changed","text":"<p>When an agent makes 50 edits across 12 files, <code>git diff</code> shows you exactly what happened. You can review every line before committing.</p>"},{"location":"git-basics/#you-can-undo-anything","title":"You can undo anything","text":"<p>Made a mistake? Approved something you shouldn't have?</p> <pre><code>git checkout .   # Undo all uncommitted changes, instantly\n</code></pre> <p>This is why you should commit frequently. Each commit is a safe point you can return to.</p>"},{"location":"git-basics/#you-can-reproduce-exactly-what-produced-a-result","title":"You can reproduce exactly what produced a result","text":"<p>Every commit has a unique hash (like <code>d6958af</code>). When you record this hash alongside your figures and results, you can always recreate the exact state of the code that produced them.</p> <pre><code>git rev-parse HEAD   # Get current commit hash\n</code></pre>"},{"location":"git-basics/#you-can-experiment-safely","title":"You can experiment safely","text":"<p>Create a branch, try something risky, and if it fails, just delete the branch. Your main code is untouched.</p> <pre><code>git checkout -b risky-refactor\n# ... try things ...\n# If it works:\ngit checkout main &amp;&amp; git merge risky-refactor\n# If it fails:\ngit checkout main &amp;&amp; git branch -D risky-refactor\n</code></pre>"},{"location":"git-basics/#the-recommended-workflow-for-agentic-ai","title":"The recommended workflow for agentic AI","text":""},{"location":"git-basics/#before-starting-a-session","title":"Before starting a session","text":"<pre><code>git status                    # Make sure you're starting clean\ngit checkout -b ai-session-1  # Create a branch for this session\n</code></pre>"},{"location":"git-basics/#during-the-session","title":"During the session","text":"<p>After each significant change the agent makes:</p> <pre><code>git diff                      # Review what changed\ngit add -A &amp;&amp; git commit -m \"Description of change\"\n</code></pre> <p>Small, frequent commits mean easy rollbacks.</p>"},{"location":"git-basics/#after-the-session","title":"After the session","text":"<pre><code>git checkout main\ngit merge ai-session-1        # If everything looks good\n# or\ngit branch -D ai-session-1    # If you want to discard everything\n</code></pre>"},{"location":"git-basics/#common-scenarios","title":"Common scenarios","text":""},{"location":"git-basics/#the-agent-made-changes-i-dont-want","title":"\"The agent made changes I don't want\"","text":"<pre><code>git diff                      # See what changed\ngit checkout -- file.py       # Undo changes to specific file\n# or\ngit checkout .                # Undo ALL changes\n</code></pre>"},{"location":"git-basics/#i-committed-something-i-shouldnt-have","title":"\"I committed something I shouldn't have\"","text":"<pre><code>git reset HEAD~1              # Undo commit, keep changes as unstaged\ngit checkout -- bad-file.py   # Discard the bad changes\ngit add -A &amp;&amp; git commit -m \"Fixed version\"\n</code></pre>"},{"location":"git-basics/#i-want-to-see-what-a-file-looked-like-before","title":"\"I want to see what a file looked like before\"","text":"<pre><code>git log --oneline file.py     # See commits that touched this file\ngit show abc123:file.py       # Show file at commit abc123\n</code></pre>"},{"location":"git-basics/#i-want-to-go-back-to-a-previous-state","title":"\"I want to go back to a previous state\"","text":"<pre><code>git log --oneline             # Find the commit hash you want\ngit checkout abc123           # Go to that commit (detached HEAD)\n# Look around, copy what you need\ngit checkout main             # Go back to current state\n</code></pre>"},{"location":"git-basics/#what-to-keep-out-of-git","title":"What to keep out of git","text":"<p>Create a <code>.gitignore</code> file:</p> <pre><code># Data files (usually too large)\ndata/raw/\n*.csv\n*.h5\n\n# Results (regenerate from code)\nresults/\n*.png\n*.pdf\n\n# Environment\n.venv/\n__pycache__/\n*.pyc\n\n# Secrets (NEVER commit these)\n.env\n*credentials*\n*secret*\n</code></pre> <p>Keep your repo focused on code and config. Data and results should be regenerable.</p>"},{"location":"git-basics/#learning-more","title":"Learning more","text":"<p>You don't need to learn all of git. But if you want to go deeper:</p> <ul> <li>Git basics from GitHub</li> <li>Run <code>git help &lt;command&gt;</code> for any command</li> </ul> <p>The most important thing: commit frequently, review diffs, and remember that you can always undo.</p>"},{"location":"git-basics/#see-also","title":"See also","text":"<ul> <li>Project Structure</li> <li>Troubleshooting</li> <li>Reproducibility</li> </ul>"},{"location":"how-it-works/","title":"How Agentic AI Works (Mental Model)","text":"<p>You do not need deep ML knowledge. But you do need a usable mental model.</p>"},{"location":"how-it-works/#chat-model-vs-agent","title":"Chat model vs agent","text":"<ul> <li>Chat model: generates text.</li> <li>Agent: uses a chat model plus tools (file edits, commands, web, etc.) to do multi-step work.</li> </ul>"},{"location":"how-it-works/#the-agent-loop","title":"The agent loop","text":"<p>Most agentic systems follow a loop like:</p> <ol> <li>Read context (files, your instructions)</li> <li>Plan</li> <li>Take an action (edit file, run command)</li> <li>Observe the result (diffs, errors, output)</li> <li>Iterate until \"done\"</li> </ol>"},{"location":"how-it-works/#why-errors-happen","title":"Why errors happen","text":"<p>Common causes:</p> <ul> <li>Missing context (the agent did not see the relevant file)</li> <li>Ambiguous goal (no definition of done)</li> <li>Overconfident guesses (hallucinations)</li> <li>Hidden assumptions (units, conventions)</li> </ul>"},{"location":"how-it-works/#context-window-and-tokens","title":"Context window and tokens","text":"<ul> <li>Models do not see your whole computer.</li> <li>They only see what is placed in their context.</li> <li>Longer context generally costs more and can be noisier.</li> </ul> <p>Important: As conversations grow longer, model performance often degrades. A common rule of thumb: once you hit roughly 40-50% of the context window, the model may start getting confused, forgetting earlier instructions, or producing lower-quality output. The fix is to break large tasks into smaller sessions, or start fresh when you notice quality dropping.</p>"},{"location":"how-it-works/#what-makes-agentic-ai-powerful","title":"What makes agentic AI powerful","text":"<ul> <li>It can try something, see it fail, and fix it.</li> <li>It can make consistent changes across many files.</li> <li>It can automate repetitive steps.</li> </ul>"},{"location":"how-it-works/#what-makes-it-dangerous","title":"What makes it dangerous","text":"<ul> <li>It can change many files quickly.</li> <li>It can produce outputs that look right.</li> <li>It can run commands you did not understand.</li> </ul> <p>Your control points are: scope, diffs, and verification.</p>"},{"location":"how-it-works/#see-also","title":"See also","text":"<ul> <li>Workflows (Plan-Do-Verify)</li> <li>Verification and Rigor</li> <li>Troubleshooting</li> </ul>"},{"location":"install-order/","title":"Installation Order (Recommended)","text":"<p>There are many tools. Installing everything at once creates confusion.</p>"},{"location":"install-order/#recommended-order","title":"Recommended order","text":"<ol> <li>Start with one chat tool you already use.</li> <li>Use it for planning, explanations, and writing.</li> <li>Add one agentic tool that can edit files and run commands.</li> <li>Recommended: Claude Code.</li> <li>If you already pay for ChatGPT, consider OpenAI Codex CLI</li> <li>Only then add an IDE-based agent (optional).</li> <li>Example: Cursor or Copilot in your IDE.</li> <li>Add multi-model workflows only after you have verification habits.</li> </ol>"},{"location":"install-order/#why-this-order-works","title":"Why this order works","text":"<ul> <li>Most failures come from weak workflow and verification, not from \"the wrong model\".</li> <li>Agentic tools amplify your habits.</li> </ul>"},{"location":"install-order/#minimum-setup-for-a-scientist","title":"Minimum setup for a scientist","text":"<ul> <li>A repo (git)</li> <li>A virtual environment</li> <li>A one-command run</li> <li>A sanity check</li> </ul> <p>See: Setup Checklist</p>"},{"location":"install-order/#installing-claude-code","title":"Installing Claude Code","text":"<p>See: Claude Code</p>"},{"location":"lab-policy-template/","title":"Lab Policy Template (Fill In)","text":"<p>This is a starting point. Adapt it to your institution and field.</p>"},{"location":"lab-policy-template/#purpose","title":"Purpose","text":"<p>We use AI tools to improve productivity while maintaining scientific integrity, privacy, and reproducibility.</p>"},{"location":"lab-policy-template/#allowed-tools","title":"Allowed tools","text":"<ul> <li>Primary tool(s): ______</li> <li>Secondary tool(s): ____</li> </ul>"},{"location":"lab-policy-template/#data-rules","title":"Data rules","text":"<p>Never share:</p> <ul> <li>credentials / API keys</li> <li>patient data / human-subject raw data</li> <li>embargoed collaborator material</li> </ul> <p>Allowed to share:</p> <ul> <li>public papers</li> <li>public code</li> <li>synthetic data</li> <li>small anonymized examples (if permitted)</li> </ul>"},{"location":"lab-policy-template/#verification-rules","title":"Verification rules","text":"<ul> <li>Any AI-generated code must be reviewed via diff.</li> <li>Any analysis must have a reproducible run command.</li> <li>Any citations must be verified.</li> </ul>"},{"location":"lab-policy-template/#disclosure","title":"Disclosure","text":"<p>We disclose meaningful AI assistance in manuscripts and proposals according to venue requirements.</p>"},{"location":"lab-policy-template/#storage-and-logging","title":"Storage and logging","text":"<ul> <li>Store prompts and outputs for important analyses: yes/no</li> <li>Store the exact commands used to generate figures: yes/no</li> </ul>"},{"location":"lab-policy-template/#contact","title":"Contact","text":"<p>If unsure, ask: ______</p>"},{"location":"lab-rollout/","title":"Lab Rollout Playbook","text":"<p>Adopting agentic AI as a lab is different from adopting it as an individual. You need to think about consistency, training, policies, and making sure no one accidentally leaks sensitive data.</p> <p>This page is a practical playbook for lab leaders who want to introduce these tools without creating chaos.</p>"},{"location":"lab-rollout/#before-you-start","title":"Before you start","text":""},{"location":"lab-rollout/#understand-the-risks","title":"Understand the risks","text":"<p>Before rolling out to your lab, be clear-eyed about what can go wrong:</p> <ul> <li>Data leaks: Someone pastes patient data into an external tool</li> <li>Bad science: Someone trusts AI-generated statistics without checking</li> <li>Reproducibility failures: AI-assisted work can't be replicated</li> <li>Citation fraud: AI invents references that make it into papers</li> <li>Skill atrophy: Students never learn to code/debug properly</li> </ul> <p>None of these are reasons to avoid AI entirely. They're reasons to roll out carefully.</p>"},{"location":"lab-rollout/#know-your-institutions-policies","title":"Know your institution's policies","text":"<p>Before anything else:</p> <ol> <li>Check if your institution has an AI policy</li> <li>Check if your IRB has guidance on AI for human-subjects research</li> <li>Check if IT has approved specific tools</li> <li>Check if your funding agencies have requirements</li> </ol> <p>If policies exist, follow them. If they don't, document your own approach.</p>"},{"location":"lab-rollout/#step-1-decide-what-data-is-allowed","title":"Step 1: Decide what data is allowed","text":"<p>This is the most important decision. Get it wrong and you have a serious problem.</p>"},{"location":"lab-rollout/#create-a-clear-data-classification","title":"Create a clear data classification","text":"<p>Green (safe to share): - Published papers and public datasets - Open-source code - Synthetic or simulated data - General questions about methods</p> <p>Yellow (caution required): - Unpublished manuscripts (embargoed material) - Collaborator data without explicit permission - Internal lab protocols and methods - Pre-publication results</p> <p>Red (never share without explicit approval): - Human-subjects data (surveys, interviews, medical records) - Patient or clinical data - Student records - Proprietary industry data - Anything covered by NDA, HIPAA, FERPA, etc. - API keys, passwords, credentials</p>"},{"location":"lab-rollout/#write-it-down","title":"Write it down","text":"<p>Create a one-page document with your lab's classification. Make it impossible to misunderstand:</p> <pre><code># Lab AI Data Policy\n\n## What you CAN share with external AI tools:\n- Public datasets and code\n- Synthetic data\n- General coding questions\n- Published literature\n\n## What you CANNOT share:\n- Any data from human subjects\n- Any patient or clinical data\n- Unpublished results without PI approval\n- Anything from collaborators without their explicit permission\n\n## When in doubt: ASK FIRST\nContact: [your email]\n</code></pre> <p>Post this prominently. Include it in onboarding materials.</p>"},{"location":"lab-rollout/#step-2-standardize-the-tools","title":"Step 2: Standardize the tools","text":"<p>Having everyone use the same tool makes training easier, troubleshooting possible, and policies enforceable.</p>"},{"location":"lab-rollout/#pick-a-primary-tool","title":"Pick a primary tool","text":"<p>Choose one agentic tool as your lab's default. Recommended:</p> <ul> <li>Claude Code if you can budget Pro/Max subscriptions</li> <li>Codex CLI if everyone already has ChatGPT plans</li> <li>Cursor if your lab is IDE-centric</li> </ul> <p>See Pick Your Tools for details.</p>"},{"location":"lab-rollout/#set-up-consistent-access","title":"Set up consistent access","text":"<ul> <li>Get institutional/team accounts if available (better for billing, policies)</li> <li>If using individual accounts, ensure everyone has the same tier</li> <li>Document how to get access in your lab wiki/onboarding docs</li> </ul>"},{"location":"lab-rollout/#consider-a-shared-config","title":"Consider a shared config","text":"<p>For Claude Code, create a lab-wide <code>CLAUDE.md</code> template:</p> <pre><code># Lab Standards\n\nWhen working on this lab's code:\n\n- Do not change scientific logic without explicit approval\n- Always propose a plan before making large changes\n- Run verification after every significant edit\n- Do not add citations - we verify all references manually\n- Document any assumptions you make\n</code></pre> <p>New projects can start with this template.</p>"},{"location":"lab-rollout/#step-3-standardize-the-workflow","title":"Step 3: Standardize the workflow","text":"<p>Consistency reduces errors. Define how AI-assisted work should be done.</p>"},{"location":"lab-rollout/#the-default-workflow","title":"The default workflow","text":"<p>Train everyone to follow plan \u2192 do \u2192 verify:</p> <ol> <li>Plan: Ask the agent for a plan before large changes</li> <li>Do: Let it implement in small, reviewable steps</li> <li>Verify: Run tests, check outputs, review diffs</li> <li>Record: Commit with clear messages, document what was AI-assisted</li> </ol>"},{"location":"lab-rollout/#require-version-control","title":"Require version control","text":"<p>No exceptions. Every project should be in git:</p> <ul> <li>Creates an audit trail of what changed</li> <li>Enables easy rollback when AI makes mistakes</li> <li>Makes diff review natural</li> <li>Supports reproducibility</li> </ul>"},{"location":"lab-rollout/#define-verification-expectations","title":"Define verification expectations","text":"<p>What counts as \"verified\"? Define it:</p> <pre><code>Before merging AI-assisted code:\n1. Review the diff line-by-line\n2. Run the test suite (must pass)\n3. Verify key outputs against known values\n4. For figures: confirm axes, labels, units are correct\n5. For statistics: spot-check calculations manually\n</code></pre>"},{"location":"lab-rollout/#step-4-standardize-prompts","title":"Step 4: Standardize prompts","text":"<p>This sounds bureaucratic, but it prevents a lot of mistakes.</p>"},{"location":"lab-rollout/#create-lab-prompt-templates","title":"Create lab prompt templates","text":"<p>Put templates in a shared doc that everyone uses:</p> <pre><code>## For refactoring\n\nRefactor this code for clarity and maintainability.\n\nRules:\n- Do not change scientific logic\n- Keep numerical outputs identical\n- Explain any non-obvious changes\n\nVerification: Run [test command] and compare outputs to before.\n\n## For debugging\n\nI'm getting this error: [paste error]\nThe code is in [file path].\nIt should [expected behavior].\n\nPlease identify the root cause, propose a fix, and explain what went wrong.\n\n## For figure generation\n\nCreate a script for Figure [N] that:\n- Reads data from [path]\n- Uses parameters from a config file\n- Saves output to results/figures/\n- Prints summary stats for verification\n</code></pre> <p>See Prompt Templates for more examples.</p>"},{"location":"lab-rollout/#why-this-matters","title":"Why this matters","text":"<p>Standardized prompts: - Encode your lab's norms (verification, no changing science) - Reduce variability in quality - Make it easier to train new members - Prevent common mistakes</p>"},{"location":"lab-rollout/#step-5-train-the-lab","title":"Step 5: Train the lab","text":"<p>Don't just announce AI tools are available. Train people to use them well.</p>"},{"location":"lab-rollout/#recommended-training","title":"Recommended training","text":"<ol> <li>Group demo (1 hour): Show the tool, walk through a real example</li> <li>Bootcamp (2 days): Have everyone complete Bootcamp</li> <li>Paired sessions: New users work alongside experienced ones initially</li> <li>Office hours: Regular time for questions and troubleshooting</li> </ol>"},{"location":"lab-rollout/#focus-training-on-verification","title":"Focus training on verification","text":"<p>The biggest risk is people trusting AI output blindly. Emphasize:</p> <ul> <li>How to read and understand diffs</li> <li>How to write verification tests</li> <li>How to spot common AI mistakes</li> <li>When to be skeptical (statistics, citations, scientific logic)</li> </ul>"},{"location":"lab-rollout/#step-6-track-and-document","title":"Step 6: Track and document","text":""},{"location":"lab-rollout/#track-what-the-ai-did","title":"Track what the AI did","text":"<p>For important analyses, record:</p> <ul> <li>Which tool/model was used</li> <li>What prompts were given (or representative examples)</li> <li>What verification was performed</li> <li>Who reviewed the output</li> </ul> <p>This isn't bureaucracy for its own sake\u2014it's reproducibility.</p>"},{"location":"lab-rollout/#document-for-papers","title":"Document for papers","text":"<p>Create a standard way to document AI assistance for manuscripts:</p> <pre><code>## AI Assistance Log for [Paper Title]\n\n### Code assistance\n- Refactored data loading pipeline (Claude Code, reviewed by [name])\n- Generated pytest suite (Claude Code, all tests manually verified)\n- Debugged memory leak in simulation (Claude Code)\n\n### Writing assistance\n- Clarity editing of Methods section (Claude, reviewed by [name])\n- No AI-generated citations\n\n### Figures\n- All figure scripts written with AI assistance\n- All figures verified against expected values\n</code></pre> <p>This makes disclosure easy when it's time to submit.</p>"},{"location":"lab-rollout/#step-7-handle-mistakes","title":"Step 7: Handle mistakes","text":"<p>Mistakes will happen. Have a plan.</p>"},{"location":"lab-rollout/#when-ai-assisted-code-produces-wrong-results","title":"When AI-assisted code produces wrong results","text":"<ol> <li>Identify what's wrong and document it</li> <li>Revert to last known-good state (git makes this easy)</li> <li>Figure out why verification didn't catch it</li> <li>Improve verification for next time</li> </ol>"},{"location":"lab-rollout/#when-sensitive-data-is-accidentally-shared","title":"When sensitive data is accidentally shared","text":"<ol> <li>Document exactly what was shared and when</li> <li>Notify your PI and/or compliance office</li> <li>Follow your institution's incident response procedure</li> <li>Update policies/training to prevent recurrence</li> </ol>"},{"location":"lab-rollout/#when-someone-publishes-without-proper-verification","title":"When someone publishes without proper verification","text":"<p>This is a serious issue. Handle it like any other scientific error: - Issue corrections if needed - Understand how it happened - Improve processes</p>"},{"location":"lab-rollout/#making-it-sustainable","title":"Making it sustainable","text":""},{"location":"lab-rollout/#regular-check-ins","title":"Regular check-ins","text":"<p>Monthly or quarterly, ask:</p> <ul> <li>Is the tool saving time?</li> <li>What mistakes are happening?</li> <li>What should we do differently?</li> <li>Are policies still appropriate?</li> </ul>"},{"location":"lab-rollout/#stay-current","title":"Stay current","text":"<p>Tools and norms change rapidly. Assign someone to:</p> <ul> <li>Monitor updates to your chosen tools</li> <li>Track changes in journal/funder policies</li> <li>Share relevant news with the lab</li> </ul>"},{"location":"lab-rollout/#keep-the-bar-for-verification-high","title":"Keep the bar for verification high","text":"<p>As people get comfortable, there's a temptation to verify less carefully. Resist this. The verification habit is what makes AI assistance safe.</p>"},{"location":"lab-rollout/#see-also","title":"See also","text":"<ul> <li>Lab Policy Template</li> <li>Safety, Privacy, and Policy</li> <li>Disclosure</li> <li>Bootcamp (2 Days)</li> </ul>"},{"location":"latex/","title":"LaTeX and Math with Agentic AI","text":"<p>Agentic AI tools can help a lot with LaTeX: drafting sections, formatting equations, cleaning up tables, and converting sketches into typeset math.</p> <p>The key idea: models can read and write raw <code>.tex</code> files directly, and many \"harnesses\" can also accept images (screenshots, PDFs, whiteboard photos).</p>"},{"location":"latex/#what-ai-is-good-at","title":"What AI is good at","text":"<ul> <li>Converting plain English into LaTeX prose</li> <li>Converting equations in text form into LaTeX math</li> <li>Cleaning up LaTeX formatting (environments, alignment, tables)</li> <li>Refactoring a messy preamble and macros (carefully)</li> <li>Turning rough notes into a clean derivation outline</li> </ul>"},{"location":"latex/#what-ai-is-risky-at","title":"What AI is risky at","text":"<ul> <li>Inventing steps in a derivation</li> <li>\"Fixing\" equations incorrectly while making them look nicer</li> <li>Producing plausible but wrong notation</li> <li>Adding citations or claims without sources</li> </ul> <p>Your defense is the usual loop: diff + compile + sanity checks.</p>"},{"location":"latex/#working-with-raw-latex","title":"Working with raw LaTeX","text":"<p>You can paste LaTeX directly into the agent or point it at a <code>.tex</code> file.</p> <p>Good tasks:</p> <ul> <li>\"Rewrite this paragraph for clarity but keep the math and meaning unchanged.\"</li> <li>\"Turn this inline equation into a properly aligned display equation.\"</li> <li>\"Make this table readable and consistent with the paper style.\"</li> </ul>"},{"location":"latex/#image-latex-whiteboard-screenshots-pdfs","title":"Image -&gt; LaTeX (whiteboard, screenshots, PDFs)","text":"<p>Many AI interfaces can accept images.</p> <p>Practical workflow:</p> <ol> <li>Write an equation on a whiteboard (or notebook).</li> <li>Take a photo.</li> <li>Give the image to the tool (or save it into your project folder).</li> <li>Ask the agent to convert it into LaTeX.</li> </ol> <p>Notes:</p> <ul> <li>If the tool cannot accept images directly, you can often still do this by saving the image and giving the agent the file path.</li> <li>Always verify the result. OCR + math parsing is good, but not perfect.</li> </ul>"},{"location":"latex/#a-minimal-compile-loop","title":"A minimal compile loop","text":"<p>If you have a local TeX install:</p> <pre><code>latexmk -pdf main.tex\n</code></pre> <p>If you do not, consider Overleaf as the simplest path.</p>"},{"location":"latex/#prompt-templates","title":"Prompt templates","text":""},{"location":"latex/#1-convert-a-whiteboard-equation-to-latex-with-verification","title":"1) Convert a whiteboard equation to LaTeX (with verification)","text":"<pre><code>I am going to provide an image of a handwritten equation.\n\nTask:\n- Convert the equation into LaTeX.\n- If any symbols are ambiguous, list the ambiguity and provide 2-3 possible interpretations.\n- Output both:\n  1) a standalone LaTeX equation\n  2) the same equation inside an `align` environment\n\nRules:\n- Do not \"fix\" the math.\n- Preserve the structure as written.\n</code></pre>"},{"location":"latex/#2-clean-up-a-derivation-without-changing-meaning","title":"2) Clean up a derivation without changing meaning","text":"<pre><code>I will provide a LaTeX snippet.\n\nGoal:\n- Improve readability and formatting.\n\nConstraints:\n- Do not change the meaning.\n- Do not change variable names unless you ask.\n\nDefinition of done:\n- It compiles.\n- The math is structurally identical.\n</code></pre>"},{"location":"latex/#3-turn-rough-notes-into-a-paper-ready-subsection","title":"3) Turn rough notes into a paper-ready subsection","text":"<pre><code>Turn these rough notes into a LaTeX subsection.\n\nConstraints:\n- Do not add citations.\n- Do not invent results.\n- If a claim is not supported by what I provided, mark it as \"needs source\".\n\nDeliverable:\n- LaTeX text using standard environments (equation/align, itemize).\n</code></pre>"},{"location":"latex/#recommended-habits","title":"Recommended habits","text":"<ul> <li>Keep equations close to the code that generated results (where applicable).</li> <li>Use consistent notation; ask the agent to build a notation table.</li> <li>Compile frequently.</li> <li>When the math is important, cross-check with a second method (manual check, symbolic tool, or a second model).</li> </ul>"},{"location":"literature/","title":"Literature and Notes","text":"<p>This is an area where AI can help a lot, but it is also where it hallucinates the most.</p>"},{"location":"literature/#safe-approach","title":"Safe approach","text":"<ul> <li>Use AI to summarize papers you provide.</li> <li>Use AI to generate questions, hypotheses, and comparisons.</li> <li>Do not trust it to \"know\" the literature without sources.</li> </ul>"},{"location":"literature/#good-tasks","title":"Good tasks","text":"<ul> <li>\"Summarize this paper in 10 bullets, then list 10 weaknesses.\"</li> <li>\"Compare these two methods and tell me when each fails.\"</li> <li>\"Extract all datasets, hyperparameters, and evaluation metrics.\"</li> </ul>"},{"location":"literature/#bad-tasks-unless-you-verify","title":"Bad tasks (unless you verify)","text":"<ul> <li>\"Give me citations for X\"</li> <li>\"What is the state of the art in Y\" (without forcing sources)</li> </ul>"},{"location":"literature/#a-workflow-that-works","title":"A workflow that works","text":"<ol> <li>Put PDFs in a folder.</li> <li>Ask the agent to create structured notes per paper.</li> <li>Ask for a synthesis across papers, explicitly citing which paper supports which claim.</li> </ol>"},{"location":"literature/#output-format-suggestion","title":"Output format suggestion","text":"<ul> <li>One note per paper</li> <li>One synthesis note per topic</li> <li>A table of methods vs assumptions vs failure modes</li> </ul>"},{"location":"literature/#see-also","title":"See also","text":"<ul> <li>Writing and Grants</li> <li>Prompt Templates</li> <li>Verification and Rigor</li> </ul>"},{"location":"mcp/","title":"MCP and Connectors","text":"<p>MCP (Model Context Protocol) is a way for agentic tools to connect to external services and data sources. Instead of copy-pasting information into the agent, you can give it direct access to your databases, documents, and tools.</p> <p>This is powerful\u2014and risky. This page covers what MCP can do, when to use it, and how to stay safe.</p>"},{"location":"mcp/#what-mcp-enables","title":"What MCP enables","text":"<p>With MCP connectors, an agent can:</p>"},{"location":"mcp/#access-your-documents","title":"Access your documents","text":"<ul> <li>Read files from Google Drive</li> <li>Search your Notion workspace</li> <li>Pull pages from Confluence</li> <li>Access shared lab documentation</li> </ul>"},{"location":"mcp/#work-with-project-management","title":"Work with project management","text":"<ul> <li>Read and create GitHub issues</li> <li>Update Jira tickets</li> <li>Check Linear tasks</li> <li>Post to Slack channels</li> </ul>"},{"location":"mcp/#query-data-sources","title":"Query data sources","text":"<ul> <li>Run SQL queries against databases</li> <li>Search internal knowledge bases</li> <li>Access APIs you've set up</li> <li>Pull from data warehouses</li> </ul>"},{"location":"mcp/#control-tools","title":"Control tools","text":"<ul> <li>Run commands on remote servers</li> <li>Interact with lab equipment (if APIs exist)</li> <li>Trigger CI/CD pipelines</li> <li>Manage cloud resources</li> </ul>"},{"location":"mcp/#why-scientists-should-care","title":"Why scientists should care","text":"<p>The biggest productivity gains come from connecting AI to your actual working context.</p>"},{"location":"mcp/#your-documentation-becomes-accessible","title":"Your documentation becomes accessible","text":"<p>Instead of: - \"Let me explain our data format...\" - [paste 500 lines of documentation]</p> <p>You can say: - \"Read our data format docs and process this file accordingly\"</p> <p>The agent pulls the docs itself.</p>"},{"location":"mcp/#your-protocols-are-always-available","title":"Your protocols are always available","text":"<p>Lab protocols, standard operating procedures, analysis guidelines\u2014all accessible without copy-pasting.</p>"},{"location":"mcp/#your-project-context-is-persistent","title":"Your project context is persistent","text":"<p>The agent can see your GitHub issues, your shared notes, your experiment logs. It understands the context of what you're working on.</p>"},{"location":"mcp/#the-risk-bigger-blast-radius","title":"The risk: bigger blast radius","text":"<p>More access means more potential for damage.</p>"},{"location":"mcp/#what-can-go-wrong","title":"What can go wrong","text":"<ul> <li>Agent reads confidential documents it shouldn't</li> <li>Agent modifies data in a database (if write access is enabled)</li> <li>Agent posts to public channels accidentally</li> <li>Credentials are exposed through the connection</li> <li>Agent takes actions you didn't intend</li> </ul>"},{"location":"mcp/#the-principle-least-privilege","title":"The principle: least privilege","text":"<p>Give the agent the minimum access it needs, not everything it could possibly use.</p> <p>Bad: \"Connect to our entire Google Drive\"</p> <p>Good: \"Connect to the lab-protocols folder, read-only\"</p>"},{"location":"mcp/#getting-started-safely","title":"Getting started safely","text":""},{"location":"mcp/#start-with-read-only-access","title":"Start with read-only access","text":"<p>Most MCP connections can be configured as read-only. Start there.</p> <ul> <li>\u2705 Read GitHub issues</li> <li>\u274c Create or close GitHub issues (not yet)</li> </ul> <p>Once you trust the setup, you can expand permissions incrementally.</p>"},{"location":"mcp/#start-with-non-sensitive-data","title":"Start with non-sensitive data","text":"<p>Connect to: - Public documentation - Open-source code - General reference materials</p> <p>Don't connect to: - Patient data systems - Financial databases - Anything covered by compliance requirements</p>"},{"location":"mcp/#log-what-the-agent-does","title":"Log what the agent does","text":"<p>Enable logging for MCP connections so you can audit: - What did it read? - What did it modify? - When did access happen?</p>"},{"location":"mcp/#common-mcp-setups-for-scientists","title":"Common MCP setups for scientists","text":""},{"location":"mcp/#github-integration","title":"GitHub integration","text":"<p>Connect the agent to your lab's GitHub organization:</p> <p>Use cases: - \"What issues are assigned to me?\" - \"Create an issue for this bug I found\" - \"What's the status of PR #123?\"</p> <p>Permissions to consider: - Read issues: low risk - Create issues: medium risk (might spam) - Merge PRs: high risk (don't enable without review)</p>"},{"location":"mcp/#documentation-access","title":"Documentation access","text":"<p>Connect to your docs system (Notion, Confluence, Google Drive):</p> <p>Use cases: - \"Follow our style guide for this code\" - \"What does our protocol say about data normalization?\" - \"Find the onboarding doc for new lab members\"</p> <p>Permissions to consider: - Read docs: low risk - Edit docs: medium risk (agent might make changes) - Delete: high risk (don't enable)</p>"},{"location":"mcp/#database-access","title":"Database access","text":"<p>Connect to your lab's database:</p> <p>Use cases: - \"How many samples from experiment X are in the database?\" - \"Query the results table for entries matching Y\" - \"Generate a summary of data collected last month\"</p> <p>Permissions to consider: - Read/SELECT: low-medium risk - Write/INSERT: medium risk - Modify/UPDATE/DELETE: high risk (be very careful)</p>"},{"location":"mcp/#setting-up-mcp-connections","title":"Setting up MCP connections","text":"<p>The exact setup depends on your tool. Here's the general pattern:</p>"},{"location":"mcp/#for-claude-code","title":"For Claude Code","text":"<p>MCP servers are configured in your settings:</p> <pre><code>{\n  \"mcpServers\": {\n    \"github\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@anthropic-ai/mcp-server-github\"],\n      \"env\": {\n        \"GITHUB_TOKEN\": \"your-token-here\"\n      }\n    }\n  }\n}\n</code></pre> <p>See Claude Code MCP docs for details.</p>"},{"location":"mcp/#for-other-tools","title":"For other tools","text":"<ul> <li>Cursor: Check Settings \u2192 MCP</li> <li>Codex CLI: See Codex documentation for connector setup</li> <li>Copilot: Uses its own extension system</li> </ul>"},{"location":"mcp/#security-best-practices","title":"Security best practices","text":""},{"location":"mcp/#use-separate-credentials","title":"Use separate credentials","text":"<p>Don't use your personal credentials for MCP connections. Create service accounts with limited permissions.</p>"},{"location":"mcp/#review-permissions-regularly","title":"Review permissions regularly","text":"<p>Audit what's connected and what access it has:</p> <pre><code># In Claude Code\n/mcp  # Shows connected servers and their status\n</code></pre> <p>Remove connections you're not actively using.</p>"},{"location":"mcp/#dont-connect-sensitive-systems","title":"Don't connect sensitive systems","text":"<p>Some things should never be connected to external AI tools:</p> <ul> <li>Systems with patient/clinical data</li> <li>Financial systems</li> <li>HR databases</li> <li>Anything with credentials or secrets</li> <li>Compliance-regulated data stores</li> </ul>"},{"location":"mcp/#test-in-a-sandbox-first","title":"Test in a sandbox first","text":"<p>Before connecting to production systems:</p> <ol> <li>Set up a test/staging version</li> <li>Connect the agent to the test version</li> <li>Verify it behaves as expected</li> <li>Then (carefully) connect to production</li> </ol>"},{"location":"mcp/#when-mcp-is-worth-the-complexity","title":"When MCP is worth the complexity","text":"<p>MCP adds setup complexity. It's worth it when:</p> <ul> <li>You repeatedly need the same external context</li> <li>Copy-pasting documentation is eating your time</li> <li>You want the agent to stay up-to-date with changes</li> <li>The data source is frequently updated</li> </ul> <p>It's not worth it for:</p> <ul> <li>One-time tasks</li> <li>Small projects where copy-paste is fine</li> <li>Situations where security concerns outweigh convenience</li> </ul>"},{"location":"mcp/#a-cautious-rollout","title":"A cautious rollout","text":"<ol> <li>Week 1: Read-only access to non-sensitive docs</li> <li>Week 2: Add GitHub issue reading</li> <li>Week 3: Evaluate. Is it useful? Any problems?</li> <li>Week 4+: Incrementally add more connections</li> </ol> <p>Go slow. It's easy to add access, harder to undo damage.</p>"},{"location":"mcp/#see-also","title":"See also","text":"<ul> <li>Advanced Usage</li> <li>Safety, Privacy, and Policy</li> <li>Lab Rollout</li> </ul>"},{"location":"model-recommendations/","title":"Which Models Should I Use?","text":"<p>The short answer: use the best model your tool supports. As of early 2026, two models stand out for agentic coding work.</p>"},{"location":"model-recommendations/#the-top-tier","title":"The top tier","text":""},{"location":"model-recommendations/#claude-opus-45-anthropic","title":"Claude Opus 4.5 (Anthropic)","text":"<p>Use with: Claude Code, GitHub Copilot, Cursor</p> <p>Opus 4.5 is currently the best model for agentic coding tasks. It leads on real-world software engineering benchmarks (80.9% on SWE-bench Verified) and handles complex, multi-step workflows with fewer dead-ends than competitors.</p> <p>Why it works well for scientists:</p> <ul> <li>Fewer tokens, better results: Opus 4.5 uses dramatically fewer tokens than predecessors to reach the same outcomes\u201476% fewer in some benchmarks. This means lower costs and faster responses.</li> <li>Strong reasoning: Major improvements in abstract reasoning make it effective for task decomposition, planning, and multi-file changes.</li> <li>Reliable for long tasks: Designed for sustained work over hours, not just quick answers.</li> </ul> <p>Pricing: $5 / $25 per million tokens (input/output)\u2014significantly cheaper than earlier Opus models.</p>"},{"location":"model-recommendations/#gpt-52-high-thinking-openai","title":"GPT-5.2 High Thinking (OpenAI)","text":"<p>Use with: Codex CLI</p> <p>If you're using OpenAI's Codex CLI (because you already have a ChatGPT subscription), GPT-5.2 with high reasoning effort is the model to use.</p> <p>Why it works well for scientists:</p> <ul> <li>Optimized for agentic coding: GPT-5.2-Codex is specifically tuned for long-horizon coding tasks, with improvements in context handling and large refactors.</li> <li>Strong on math: Achieves 100% on AIME 2025 mathematical reasoning benchmarks.</li> <li>Reasoning effort settings: You can dial up \"thinking\" effort (low/medium/high/xhigh) depending on task complexity.</li> </ul> <p>Use <code>high</code> or <code>xhigh</code> reasoning effort for complex scientific code. Use <code>medium</code> for routine tasks to save tokens.</p>"},{"location":"model-recommendations/#how-to-set-the-model","title":"How to set the model","text":""},{"location":"model-recommendations/#claude-code","title":"Claude Code","text":"<p>Claude Code uses Opus 4.5 by default on Pro/Max plans. You can verify or change your model:</p> <pre><code>claude config get model\nclaude config set model claude-opus-4-5-20251101\n</code></pre> <p>For lighter tasks (drafts, simple refactors), you can switch to Sonnet to save costs:</p> <pre><code>claude config set model claude-sonnet-4-20250514\n</code></pre>"},{"location":"model-recommendations/#codex-cli","title":"Codex CLI","text":"<p>Codex CLI uses GPT-5.2-Codex by default for paid ChatGPT users. To set reasoning effort:</p> <pre><code>codex --reasoning high\n</code></pre> <p>Or in your config file, set <code>reasoning: high</code> as the default.</p>"},{"location":"model-recommendations/#cursor","title":"Cursor","text":"<p>In Cursor settings, select \"claude-opus-4-5\" as your primary model. Cursor supports multiple providers, so you can also configure fallbacks.</p>"},{"location":"model-recommendations/#github-copilot","title":"GitHub Copilot","text":"<p>GitHub Copilot's agent mode uses Claude Opus 4.5 when available. Check your Copilot settings to ensure you're on a plan that supports it (Pro or Enterprise).</p>"},{"location":"model-recommendations/#other-models-worth-knowing","title":"Other models worth knowing","text":""},{"location":"model-recommendations/#gemini-3-pro-google","title":"Gemini 3 Pro (Google)","text":"<p>Gemini 3 Pro has a massive 1 million token context window (5x larger than Claude, 2.5x larger than GPT-5.2). This is useful for:</p> <ul> <li>Processing entire codebases in one session</li> <li>Very long documents or research papers</li> <li>Multimodal tasks involving images</li> </ul> <p>However, for pure coding reliability, Opus 4.5 and GPT-5.2 currently outperform it on most benchmarks.</p>"},{"location":"model-recommendations/#sonnet-45-anthropic","title":"Sonnet 4.5 (Anthropic)","text":"<p>Anthropic's mid-tier model. Use it for:</p> <ul> <li>Routine refactors where you don't need maximum reasoning power</li> <li>Cost-sensitive work (significantly cheaper than Opus)</li> <li>Tasks where you'll verify results anyway</li> </ul> <p>A good workflow: use Sonnet for drafts and exploration, switch to Opus for final implementation and complex debugging.</p>"},{"location":"model-recommendations/#model-selection-by-task","title":"Model selection by task","text":"Task Recommended model Complex debugging, multi-file refactors Opus 4.5 or GPT-5.2 High Math-heavy code, numerical methods GPT-5.2 High or Opus 4.5 Routine refactors, simple scripts Sonnet 4.5 or GPT-5.2 Medium Processing very long documents Gemini 3 Pro Quick drafts, exploration Sonnet 4.5 High-stakes final implementation Opus 4.5"},{"location":"model-recommendations/#the-model-landscape-changes-fast","title":"The model landscape changes fast","text":"<p>This page reflects the state of things in early 2026. Model capabilities shift every few months. The general principle holds: use the best model your budget and tooling support for important work, and drop to cheaper models for routine tasks.</p> <p>Check the official pricing and model pages for current information:</p> <ul> <li>Anthropic models and pricing</li> <li>OpenAI models</li> <li>Google AI models</li> </ul>"},{"location":"model-recommendations/#see-also","title":"See also","text":"<ul> <li>Multi-Model Strategy</li> <li>Cost Control</li> <li>Pick Your Tools</li> </ul>"},{"location":"multi-model/","title":"Multi-Model Strategy (When and Why)","text":"<p>Some power users run the same problem through multiple systems (for example: Claude, Cursor, ChatGPT).</p> <p>This can improve reliability, but it can also waste time and money.</p>"},{"location":"multi-model/#when-it-is-worth-it","title":"When it is worth it","text":"<ul> <li>High-stakes correctness (math derivations, key results)</li> <li>Critical code paths</li> <li>You suspect hallucinations</li> <li>You want a second opinion on design decisions</li> </ul>"},{"location":"multi-model/#when-it-is-not-worth-it","title":"When it is not worth it","text":"<ul> <li>Routine refactors</li> <li>Simple scripts with good tests</li> <li>Tasks where you can quickly verify by running code</li> </ul>"},{"location":"multi-model/#the-best-cross-check-is-still-a-test","title":"The best cross-check is still a test","text":"<p>Two models agreeing is not proof.</p> <p>Best practice:</p> <ul> <li>define a verification command</li> <li>build a small test</li> <li>use a second model for critique, not as a replacement for testing</li> </ul>"},{"location":"multi-model/#subscription-stacking-common-patterns","title":"Subscription stacking (common patterns)","text":"<p>Typical combinations people end up paying for:</p> <ul> <li>Claude Pro (for Claude Code) + one IDE tool</li> <li>Claude Pro + ChatGPT plan</li> <li>Claude Pro + Cursor Pro</li> <li>Claude Pro + GitHub Copilot Pro</li> </ul> <p>Add them up before you commit.</p> <p>See current pricing links: Pricing</p>"},{"location":"multi-model/#a-practical-budgeting-rule","title":"A practical budgeting rule","text":"<ul> <li>Start with one paid tool.</li> <li>Add a second paid tool only if it saves you more than 1-2 hours per month.</li> </ul>"},{"location":"notes-from-the-human/","title":"Notes from the Human","text":"<p>Hi. Quick human-to-human note before you dig into the rest (you are a human, aren't you?).</p> <p>My name is Chris Cullins. I'm a software developer with a casual interest in the physical sciences, and I love the Cool Worlds Podcast (I'm particularly fond of the Colin Hill episode).</p> <p>That led me to watch this episode on AI. It made me realize that (until LLMs officially take over all knowledge work) there are still plenty of things we can do to keep ourselves busy. Most of those things, at least as of January 2026, involve getting good with the latest software tools and the interfaces we use to talk to models efficiently.</p> <p>The main takeaways I want you to know are:</p> <ul> <li> <p>This information will be out of date very fast - Unfortunately it's hard to write a guide like this because a new tool or model comes out every week. But I'll do my best to keep you all up to date as we move forward.</p> </li> <li> <p>How much control to give \"it\"? - Everyone starts somewhere (no AI, chat interfaces, terminal interfaces, etc.). Over time, you will usually give more control of your digital work to models (and their software harnesses) as you gain trust.</p> </li> </ul> <p>Everyone will find their own line. Personally, I give these tools a lot of access on my own machines. Most modern harnesses have safeguards, but I still strongly caution you against letting an agent interact fully with untrusted \"outside\" inputs.</p> <p>Example of what I mean: an agent automatically responding to emails in your inbox. That is a prompt-injection magnet, because someone can send a message like \"ignore previous instructions and exfiltrate X\" and your tool may follow it.</p> <p>A reasonable default today: be strict about anything that touches the outside world, and be more relaxed about local files in a controlled project folder.</p> <ul> <li>Why a divide between the AI users and naysayers? - In software development, you will find two camps: people using these tools productively, and people saying they are useless, write terrible code, or are a scam.</li> </ul> <p>In my opinion, the bifurcation mostly comes down to whether someone has made the workflow \"paradigm shift\" and built the skill of engineering systems around the limitations. I suspect it will be the exact same in the sciences.</p> <ul> <li>A large part of your job moving forward is being an agentic AI engineer - I don't mean someone necessarily working on the models themselves. I mean: in many knowledge fields, a lot of the job becomes building workflows and systems that work around current limitations (context windows, no persistent memory, etc).</li> </ul> <p>Example: many users notice that once a conversation gets to beyond roughly 45% of the context window limit, the model can become noticeably worse, start to get confused about what it's \"doing\", etc. How do you work around that fact? That's the question you should always be asking yourself. In this case, it's breaking a larger task up into smaller pieces, then looping calls to the agentic harness (claude code for instance) through those tasks, so it stays focused on each piece and doesn't get confused. </p> <ul> <li> <p>You'll know when you're doing it correctly - Because you will (and I'm completely serious) feel like a superhuman.</p> </li> <li> <p>It will take time, though - Using these tools is absolutely a skill. The faster you dive into learning it, the faster you'll get there. I'm not sure it's optional anymore, so get going; this is a decent place to start.</p> </li> <li> <p>You will need to fix your \"muscle memory\" - If you are reading something and think of a question, or you have an annoyance in your life you wish someone had fixed already, your first instinct should increasingly become: \"let me ask a model what my options are to fix this problem\".</p> </li> </ul> <p>It can feel unnatural at first (or even a bit slimy), but it will often get you to a solution much faster. In many cases, you will start solving problems you would not have bothered with before, because the ROI is so much better when the upfront effort drops close to zero.</p>"},{"location":"notes-from-the-human/#where-to-go-next","title":"Where to go next","text":"<ul> <li>Start reading: What This Guide Is</li> <li>Do the practical ramp: Bootcamp (2 Days)</li> <li>If you are very new to terminals: Open a Terminal</li> </ul>"},{"location":"oh-i-get-it/","title":"Oh I Get It (Guided Tour)","text":"<p>This is a deliberately \"aha\"-style experience.</p> <p>You will use an agentic tool to download this guide onto your computer, then have the agent walk you through it interactively.</p> <p>This guide uses Claude Code as the default tool, but you do not have to use Claude Code. Use whatever tool you already have and like.</p> <p>See: Pick Your Tools</p> <p>Note: if there is something in this guide you do not understand, ask your tool of choice to explain it. That is one of the best ways to learn fast.</p>"},{"location":"oh-i-get-it/#what-you-will-do","title":"What you will do","text":"<ol> <li>Install your agent tool</li> <li>Start it in a fresh folder</li> <li>Paste a single prompt</li> <li>Let the agent:</li> <li>download the guide (from GitHub)</li> <li>open the docs locally</li> <li>propose a fast learning path</li> <li>answer questions as you go</li> </ol>"},{"location":"oh-i-get-it/#safety-note","title":"Safety note","text":"<p>The prompt below asks the agent to run shell commands (<code>curl</code>, <code>tar</code>, etc.).</p> <p>If you do not recognize a command, ask it to explain before you approve it.</p>"},{"location":"oh-i-get-it/#step-1-install-an-agent-tool","title":"Step 1: Install an agent tool","text":"<p>Default path in this guide:</p> <ul> <li>Claude Code</li> </ul> <p>If you already pay for ChatGPT, you can do a very similar experience with OpenAI Codex CLI (a terminal-based coding agent).</p>"},{"location":"oh-i-get-it/#step-2-start-your-agent-tool","title":"Step 2: Start your agent tool","text":"<p>Open a terminal: Open a Terminal</p> <p>Then run:</p> <pre><code>mkdir -p ~/agentic-ai-guide-tour\ncd ~/agentic-ai-guide-tour\nclaude\n</code></pre> <p>If you are using Codex CLI instead:</p> <pre><code>mkdir -p ~/agentic-ai-guide-tour\ncd ~/agentic-ai-guide-tour\ncodex\n</code></pre>"},{"location":"oh-i-get-it/#step-3-paste-this-prompt-into-your-tool","title":"Step 3: Paste this prompt into your tool","text":"<p>Replace nothing; just paste.</p> <pre><code>I want an interactive walkthrough of the \"Science + Agentic AI Guide\".\n\nPlease do the following carefully:\n\n0) First, propose a short plan and list the exact commands you intend to run.\n1) Create a new subfolder called `science-ai-guide` inside the current directory.\n2) Download the latest guide content from GitHub into that folder (no git required).\n   - Use the repository tarball: https://github.com/Chris-Cullins/science-ai-guide/archive/refs/heads/main.tar.gz\n   - Use curl and tar.\n   - Extract it so that `science-ai-guide/docs/` exists and contains the Markdown files.\n3) After download, open and read:\n   - `science-ai-guide/docs/index.md`\n   - `science-ai-guide/docs/notes-from-the-human.md`\n4) Give me a 10-minute \"orientation\" of how this guide is structured and what to read first.\n5) Ask me 3 questions to personalize a learning path (my OS, how technical I am, what I want to use this for).\n6) Based on my answers, give me a short plan for the next 60 minutes.\n\nRules:\n- Keep it beginner-friendly.\n- Do not ask me to do complex setup unless it is necessary.\n- When you recommend running a command, explain what it does in one sentence.\n</code></pre>"},{"location":"oh-i-get-it/#if-you-are-on-windows","title":"If you are on Windows","text":"<p>If the <code>tar</code> command is not available, ask the agent to use a zip download + PowerShell <code>Expand-Archive</code> instead.</p>"},{"location":"oh-i-get-it/#what-success-looks-like","title":"What success looks like","text":"<ul> <li>You have a local copy of the guide in <code>~/agentic-ai-guide-tour/science-ai-guide/</code></li> <li>You understand the \"plan -&gt; do -&gt; verify\" loop</li> <li>You have one small task you can delegate safely today</li> </ul>"},{"location":"open-terminal/","title":"Open a Terminal (macOS, Windows, Linux)","text":"<p>Agentic tools like Claude Code run in a terminal.</p> <p>If you have never used one, that's normal. This page gets you to a working prompt.</p>"},{"location":"open-terminal/#macos","title":"macOS","text":"<p>Built-in Terminal (fastest)</p> <ol> <li>Press Command + Space (Spotlight Search)</li> <li>Type: Terminal</li> <li>Press Enter</li> </ol> <p>Alternative terminals (optional)</p> <ul> <li>Ghostty</li> <li>iTerm2</li> </ul> <p>Any of these work. Pick one and stick with it.</p>"},{"location":"open-terminal/#windows","title":"Windows","text":"<p>Windows Terminal (recommended)</p> <ol> <li>Press the Windows key</li> <li>Type: Windows Terminal</li> <li>Press Enter</li> </ol> <p>Then choose one shell:</p> <ul> <li>PowerShell (common default)</li> <li>Command Prompt (cmd)</li> </ul> <p>If you need Linux-style tooling</p> <ul> <li>Install WSL (Windows Subsystem for Linux) and use an Ubuntu shell inside Windows Terminal.</li> </ul>"},{"location":"open-terminal/#linux","title":"Linux","text":"<p>Most desktop Linux distributions include a terminal.</p> <p>Common ways to open it:</p> <ul> <li>Press Ctrl + Alt + T (works on many distros)</li> <li>Use the application launcher and search for: Terminal</li> </ul>"},{"location":"open-terminal/#a-quick-sanity-check","title":"A quick sanity check","text":"<p>Once the terminal opens, type:</p> <pre><code>pwd\n</code></pre> <p>If it prints a folder path, you are good.</p> <p>Next: Terminal Basics</p>"},{"location":"overview/","title":"What This Guide Is","text":"<p>This is a practical guide for scientists adopting agentic AI tools.</p> <p>It assumes:</p> <ul> <li>You write some code (often Python/R/Matlab) but you are not a professional software engineer.</li> <li>You care about correctness, reproducibility, and not embarrassing yourself in a paper.</li> <li>You want a workflow that is faster, not just \"cool\".</li> </ul>"},{"location":"overview/#the-promise","title":"The promise","text":"<p>Agentic AI can:</p> <ul> <li>turn vague goals into concrete code changes</li> <li>automate the boring parts (setup, refactors, glue code)</li> <li>accelerate debugging</li> <li>help you explore literature and write more clearly</li> </ul>"},{"location":"overview/#the-catch","title":"The catch","text":"<p>Agentic AI also:</p> <ul> <li>makes mistakes confidently</li> <li>can create plausible but wrong plots, stats, or citations</li> <li>can leak data if you paste sensitive content</li> <li>can change many files quickly (reproducibility risk)</li> </ul> <p>The goal of this guide is to help you get the upside without eating the downside.</p>"},{"location":"overview/#a-simple-rule","title":"A simple rule","text":"<p>If the agent can take actions, you must:</p> <ol> <li>review diffs</li> <li>run verification</li> <li>keep a reproducible record</li> </ol>"},{"location":"overview/#glossary-quick","title":"Glossary (quick)","text":"<ul> <li>Agentic AI: an AI system that can take actions (edit files, run commands, call tools).</li> <li>Diff: a view of what changed in files.</li> <li>Repo: a project folder tracked by git (version control).</li> <li>Context window: how much information the model can consider at once.</li> <li>Tokens: the model's \"units\" of text; cost is often per token.</li> </ul>"},{"location":"pricing/","title":"Pricing (Double-Check Before Publishing)","text":"<p>Pricing changes frequently. This page is a snapshot of publicly listed pricing as of 2026-02-01.</p>"},{"location":"pricing/#claude-subscriptions-includes-claude-code","title":"Claude subscriptions (includes Claude Code)","text":"<p>From Anthropic's pricing page (Individual plans):</p> <ul> <li>Free: $0</li> <li>Pro: $17/month with annual discount ($200 billed up front) or $20 billed monthly; includes access to Claude Code</li> <li>Max: from $100/month</li> </ul> <p>Source: Anthropic pricing</p>"},{"location":"pricing/#claude-api-pricing-if-you-build-custom-tools","title":"Claude API pricing (if you build custom tools)","text":"<p>From Anthropic's pricing page (API):</p> <ul> <li>Opus 4.5: $5/MTok input, $25/MTok output</li> <li>Sonnet 4.5: $3/MTok input and $15/MTok output for prompts &lt;= 200K tokens (higher prices for &gt;200K)</li> <li>Haiku 4.5: $1/MTok input, $5/MTok output</li> </ul> <p>Tools pricing shown there also includes (examples):</p> <ul> <li>Web search: $10 / 1K searches (not including tokens)</li> <li>Code execution: $0.05 per hour per container (after free daily hours per org)</li> </ul> <p>Source: Anthropic pricing</p>"},{"location":"pricing/#alternatives-for-comparison","title":"Alternatives (for comparison)","text":"<ul> <li> <p>Cursor: Free tier; Pro $20/month; Pro+ $60/month; Ultra $200/month   Source: Cursor pricing</p> </li> <li> <p>GitHub Copilot (individual): Free; Pro $10/month; Pro+ $39/month   Source: GitHub Copilot plans</p> </li> <li> <p>ChatGPT plans are listed at OpenAI pricing</p> </li> </ul>"},{"location":"pricing/#what-people-actually-end-up-paying-examples","title":"What people actually end up paying (examples)","text":"<p>These are example monthly totals based on the subscription prices listed above. Pricing changes often; verify before publishing.</p> <p>Starter (single tool)</p> <ul> <li>Claude Pro ($20/month billed monthly)</li> </ul> <p>Common \"two-tool\" stacks</p> <ul> <li>Claude Pro ($20) + GitHub Copilot Pro ($10) = $30/month</li> <li>Claude Pro ($20) + Cursor Pro ($20) = $40/month</li> </ul> <p>Heavy use</p> <ul> <li>Claude Pro ($20) + Cursor Pro+ ($60) = $80/month</li> </ul> <p>If you also add a ChatGPT plan, include that amount in your budget.</p>"},{"location":"pricing/#cost-control-tips","title":"Cost control tips","text":"<ul> <li>Prefer smaller tasks and incremental diffs (reduces rework).</li> <li>Save reusable instructions in a project-level \"rules\" file (reduces repeated context).</li> <li>Don't upload giant datasets when a small sample + schema is enough.</li> </ul>"},{"location":"project-structure/","title":"Project Structure That Works With Agents","text":"<p>Most pain in scientific computing comes from messy project structure: scattered scripts, unclear dependencies, outputs mixed with code, and no clear way to reproduce results. Agentic AI makes this worse (it can create chaos faster) but also better (it can help you organize).</p> <p>This page covers how to structure projects so both humans and agents can work effectively.</p>"},{"location":"project-structure/#why-structure-matters-for-agents","title":"Why structure matters for agents","text":"<p>Agents navigate your project by reading files and understanding their relationships. When structure is clear:</p> <ul> <li>The agent knows where to find things</li> <li>The agent knows where to put new things</li> <li>You know where to look when reviewing changes</li> <li>Reproducing results becomes trivial</li> </ul> <p>When structure is messy, the agent makes it messier.</p>"},{"location":"project-structure/#a-structure-that-works","title":"A structure that works","text":"<pre><code>project/\n\u251c\u2500\u2500 README.md              # What this is, how to run it\n\u251c\u2500\u2500 pyproject.toml         # Dependencies and project metadata\n\u251c\u2500\u2500 Makefile               # Canonical commands (make test, make figures)\n\u2502\n\u251c\u2500\u2500 configs/               # Parameter files for different runs\n\u2502   \u251c\u2500\u2500 default.yaml\n\u2502   \u251c\u2500\u2500 paper_fig1.yaml\n\u2502   \u2514\u2500\u2500 experiment_2.yaml\n\u2502\n\u251c\u2500\u2500 data/\n\u2502   \u251c\u2500\u2500 raw/               # Original data (never modify)\n\u2502   \u251c\u2500\u2500 processed/         # Cleaned/transformed data\n\u2502   \u2514\u2500\u2500 README.md          # Data sources and descriptions\n\u2502\n\u251c\u2500\u2500 src/                   # Your actual code\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 analysis.py\n\u2502   \u251c\u2500\u2500 preprocessing.py\n\u2502   \u2514\u2500\u2500 visualization.py\n\u2502\n\u251c\u2500\u2500 scripts/               # Entry points that use src/\n\u2502   \u251c\u2500\u2500 run_analysis.py\n\u2502   \u251c\u2500\u2500 make_figures.py\n\u2502   \u2514\u2500\u2500 preprocess_data.py\n\u2502\n\u251c\u2500\u2500 notebooks/             # Exploratory work (not for production)\n\u2502   \u2514\u2500\u2500 exploration.ipynb\n\u2502\n\u251c\u2500\u2500 tests/                 # Automated tests\n\u2502   \u251c\u2500\u2500 test_analysis.py\n\u2502   \u2514\u2500\u2500 test_preprocessing.py\n\u2502\n\u2514\u2500\u2500 results/               # Generated outputs (often gitignored)\n    \u251c\u2500\u2500 figures/\n    \u251c\u2500\u2500 tables/\n    \u2514\u2500\u2500 logs/\n</code></pre> <p>This isn't the only valid structure, but it's a good default that agents understand well.</p>"},{"location":"project-structure/#the-key-principles","title":"The key principles","text":""},{"location":"project-structure/#separate-code-from-data-from-results","title":"Separate code from data from results","text":"<ul> <li>Code (<code>src/</code>, <code>scripts/</code>): Versioned in git, the source of truth</li> <li>Data (<code>data/</code>): Usually not in git (too large), documented in README</li> <li>Results (<code>results/</code>): Generated from code + data, can be regenerated</li> </ul> <p>If you can regenerate something from code, don't put it in git.</p>"},{"location":"project-structure/#one-command-runs","title":"One-command runs","text":"<p>Define canonical commands that anyone (human or agent) can run:</p> <pre><code># Makefile\n\n.PHONY: test figures clean\n\ntest:\n    pytest tests/\n\nfigures:\n    python scripts/make_figures.py --config configs/paper.yaml\n\nclean:\n    rm -rf results/figures/*\n</code></pre> <p>When \"done\" means \"this command passes,\" both you and the agent have a clear target.</p>"},{"location":"project-structure/#configs-not-magic-numbers","title":"Configs, not magic numbers","text":"<p>Instead of hardcoding parameters in your code:</p> <pre><code># Bad\nlearning_rate = 0.001\nbatch_size = 32\n</code></pre> <p>Put them in config files:</p> <pre><code># configs/default.yaml\nmodel:\n  learning_rate: 0.001\n  batch_size: 32\ndata:\n  input_path: data/processed/dataset.csv\n  test_fraction: 0.2\noutput:\n  figures_dir: results/figures/\n  seed: 42\n</code></pre> <p>Then load them:</p> <pre><code># Good\nimport yaml\n\nwith open(\"configs/default.yaml\") as f:\n    config = yaml.safe_load(f)\n\nlearning_rate = config[\"model\"][\"learning_rate\"]\n</code></pre> <p>This makes it trivial to: - See what parameters were used - Reproduce a specific run - Try different settings</p>"},{"location":"project-structure/#raw-data-is-sacred","title":"Raw data is sacred","text":"<p>Never modify files in <code>data/raw/</code>. If you need to clean or transform data, write a script that reads from <code>raw/</code> and writes to <code>processed/</code>:</p> <pre><code># scripts/preprocess_data.py\ndef main():\n    raw = pd.read_csv(\"data/raw/experiment_output.csv\")\n    cleaned = preprocess(raw)  # Your cleaning logic\n    cleaned.to_csv(\"data/processed/cleaned_data.csv\", index=False)\n</code></pre> <p>This way you can always start over from the original data.</p>"},{"location":"project-structure/#document-data-sources","title":"Document data sources","text":"<p>Create a <code>data/README.md</code> that explains:</p> <pre><code># Data\n\n## raw/experiment_output.csv\n- Source: Lab instrument export, 2025-11-15\n- Contact: Jane Doe\n- Notes: Contains raw sensor readings, some NaN values expected\n\n## processed/cleaned_data.csv\n- Generated by: scripts/preprocess_data.py\n- From: raw/experiment_output.csv\n- Transformations: Remove NaN rows, normalize columns A-D\n</code></pre> <p>Future you will thank present you.</p>"},{"location":"project-structure/#a-prompt-for-organizing-a-messy-project","title":"A prompt for organizing a messy project","text":"<pre><code>Help me reorganize this project for reproducibility.\n\nCurrent state:\n- Scripts are scattered in the root directory\n- Parameters are hardcoded\n- No clear entry point\n\nTarget structure:\n- src/ for modules, scripts/ for entry points\n- configs/ for parameters\n- Makefile with `make test` and `make figures`\n- README explaining how to run\n\nRules:\n- Do not change scientific logic\n- Move files, don't delete (I'll review and clean up)\n- Create configs from hardcoded values\n- Propose a plan before making changes\n</code></pre>"},{"location":"project-structure/#common-mistakes-to-avoid","title":"Common mistakes to avoid","text":""},{"location":"project-structure/#too-much-in-one-file","title":"Too much in one file","text":"<p>If a file is &gt;500 lines, it probably does too much. Split into modules.</p>"},{"location":"project-structure/#notebooks-as-source-of-truth","title":"Notebooks as source of truth","text":"<p>Notebooks are great for exploration, but they're hard to diff, test, and reproduce. Convert important analyses to scripts.</p>"},{"location":"project-structure/#results-checked-into-git","title":"Results checked into git","text":"<p>Generated files bloat your repo and create merge conflicts. Gitignore them and regenerate as needed.</p>"},{"location":"project-structure/#no-readme","title":"No README","text":"<p>If someone (including future you) can't figure out how to run your code in 5 minutes, add a README.</p>"},{"location":"project-structure/#unclear-entry-points","title":"Unclear entry points","text":"<p>\"Which script do I run?\" should have an obvious answer. Use a Makefile or a single main script.</p>"},{"location":"project-structure/#setting-up-a-new-project","title":"Setting up a new project","text":"<p>When starting fresh, create the structure upfront:</p> <pre><code>mkdir -p project/{src,scripts,data/{raw,processed},configs,tests,results/{figures,tables}}\ntouch project/README.md project/Makefile project/pyproject.toml\ntouch project/src/__init__.py\n</code></pre> <p>Or ask an agent:</p> <pre><code>Set up a new Python project for scientific analysis.\n\nInclude:\n- Standard directory structure (src, scripts, data, configs, tests, results)\n- pyproject.toml with basic dependencies (numpy, pandas, matplotlib, pytest)\n- Makefile with test and figures targets\n- README template\n- .gitignore for Python projects\n\nDo not add any actual analysis code yet, just the structure.\n</code></pre>"},{"location":"project-structure/#see-also","title":"See also","text":"<ul> <li>Git Basics</li> <li>Reproducibility</li> <li>Data Analysis</li> </ul>"},{"location":"prompting/","title":"Prompting Patterns (That Actually Work)","text":"<p>Good prompting is not poetry. It is specifications.</p>"},{"location":"prompting/#the-5-things-to-include","title":"The 5 things to include","text":"<ol> <li>Goal: what you want</li> <li>Context: what the agent should look at</li> <li>Constraints: what it must not do</li> <li>Definition of done: how you will verify</li> <li>Output format: what artifacts you want</li> </ol>"},{"location":"prompting/#a-default-template","title":"A default template","text":"<pre><code>You are helping me with a scientific project.\n\nGoal:\n- &lt;what you want&gt;\n\nContext:\n- &lt;where to look, what files exist&gt;\n\nConstraints:\n- Do not change scientific assumptions without asking.\n- Do not invent citations or factual claims.\n- Keep changes small and reviewable.\n\nDefinition of done:\n- &lt;tests / commands / checks that must pass&gt;\n\nDeliverables:\n- &lt;files or outputs&gt;\n</code></pre>"},{"location":"prompting/#high-leverage-patterns","title":"High-leverage patterns","text":""},{"location":"prompting/#ask-for-a-plan-first","title":"Ask for a plan first","text":"<p>\"Propose a plan before editing files.\" reduces thrash.</p>"},{"location":"prompting/#force-the-agent-to-be-explicit-about-assumptions","title":"Force the agent to be explicit about assumptions","text":"<p>\"List assumptions and units.\" catches many scientific errors early.</p>"},{"location":"prompting/#add-an-adversarial-check","title":"Add an adversarial check","text":"<p>\"Tell me how this could be wrong.\" makes verification easier.</p>"},{"location":"prompting/#common-failure-patterns","title":"Common failure patterns","text":"<ul> <li>Vague tasks: \"make this better\"</li> <li>No definition of done</li> <li>No tests or sanity checks</li> <li>Asking for citations without giving sources</li> </ul>"},{"location":"prompts/","title":"Prompt Templates for Scientists","text":"<p>These are designed to be copy/pasted into an agentic tool like Claude Code.</p>"},{"location":"prompts/#1-paper-to-code-replication","title":"1) Paper-to-code replication","text":"<pre><code>I want to replicate a figure from a paper.\n\nContext:\n- I will provide the paper PDF (or key equations) and my dataset.\n\nRules:\n- Start by listing all assumptions you are making.\n- Implement a minimal, reproducible script first.\n- Add unit tests or numeric spot-checks against limiting cases.\n\nDeliverables:\n- `src/` code\n- `data/README.md` describing inputs\n- `results/` with generated figure\n- `README.md` with exact run steps\n</code></pre>"},{"location":"prompts/#2-convert-my-messy-notebook-into-a-pipeline","title":"2) \"Convert my messy notebook into a pipeline\"","text":"<pre><code>Turn this notebook into a reproducible pipeline.\n\nConstraints:\n- Keep outputs identical unless you explain why they change.\n- Add a config file for parameters.\n- Pin dependencies.\n- Add a `make run` (or equivalent).\n\nDeliverables:\n- `pipeline/` or `src/`\n- `configs/`\n- `README.md`\n</code></pre>"},{"location":"prompts/#3-grantpaper-writing-assistant-safe-mode","title":"3) Grant/paper writing assistant (safe mode)","text":"<pre><code>Help me improve clarity without inventing facts.\n\nRules:\n- Do not add citations.\n- Do not change scientific claims.\n- Only propose edits that improve structure, clarity, and readability.\n\nOutput:\n- Provide a revised version and a short list of what changed.\n</code></pre>"},{"location":"prompts/#4-debug-a-crashing-simulation-or-script","title":"4) Debug a crashing simulation or script","text":"<pre><code>My script crashes with the following error:\n&lt;paste error&gt;\n\nContext:\n- The script is in &lt;file path&gt;.\n- It is supposed to &lt;brief description of what it does&gt;.\n\nTask:\n- Identify the root cause.\n- Propose a fix.\n- Explain why it failed.\n\nRules:\n- Do not change the scientific logic without asking.\n- If you need to see more files, ask.\n</code></pre>"},{"location":"prompts/#5-review-code-for-correctness-before-trusting-results","title":"5) Review code for correctness before trusting results","text":"<pre><code>I need you to review this analysis code before I trust its outputs.\n\nTask:\n- Read the code carefully.\n- List any potential bugs, edge cases, or silent failures.\n- Check for common pitfalls: off-by-one errors, incorrect joins, unit mismatches, unintended type coercion.\n- Tell me what assumptions the code makes.\n\nOutput:\n- A numbered list of issues (or \"none found\").\n- Confidence level (high / medium / low) for each issue.\n</code></pre>"},{"location":"prompts/#6-generate-synthetic-test-data","title":"6) Generate synthetic test data","text":"<pre><code>I need synthetic test data to validate my analysis pipeline.\n\nContext:\n- The real data has columns: &lt;list columns and types&gt;\n- The pipeline should produce &lt;expected output&gt;\n\nTask:\n- Generate a small synthetic dataset (10-50 rows) that exercises:\n  - Normal cases\n  - Edge cases (empty values, extreme values, boundary conditions)\n  - At least one case that should trigger a known behavior\n\nOutput:\n- A CSV or code that generates the data.\n- A brief description of what each test case is meant to check.\n</code></pre>"},{"location":"prompts/#7-explain-inherited-or-unfamiliar-code","title":"7) Explain inherited or unfamiliar code","text":"<pre><code>I inherited this codebase and need to understand it.\n\nTask:\n- Summarize what this code does at a high level.\n- Identify the main entry points.\n- List the key functions and their purposes.\n- Flag any confusing or non-obvious parts.\n\nRules:\n- Do not change anything.\n- If something is unclear, say so rather than guessing.\n</code></pre>"},{"location":"prompts/#8-add-tests-to-existing-code","title":"8) Add tests to existing code","text":"<pre><code>Add tests for the following code.\n\nContext:\n- File(s): &lt;paths&gt;\n- Testing framework: &lt;pytest / unittest / other&gt;\n\nTask:\n- Write tests that cover:\n  - Normal operation\n  - Edge cases\n  - At least one failure case\n- Tests should be independent and fast.\n\nRules:\n- Do not modify the original code unless necessary to make it testable.\n- If you need to refactor for testability, propose the change first.\n</code></pre>"},{"location":"prompts/#9-domain-specific-physics-numerical-work","title":"9) Domain-specific: physics / numerical work","text":"<pre><code>You are helping with a physics or numerical analysis project.\n\nExtra rules:\n- Always state units explicitly.\n- Check dimensional consistency.\n- For numerical code, consider precision, stability, and convergence.\n- When in doubt, add a limiting-case check or a back-of-the-envelope sanity test.\n</code></pre>"},{"location":"prompts/#10-domain-specific-biology-life-sciences","title":"10) Domain-specific: biology / life sciences","text":"<pre><code>You are helping with a biology or life sciences project.\n\nExtra rules:\n- Be careful with sequence data (orientation, indexing conventions).\n- Statistical tests must be appropriate for the data type (counts, proportions, continuous).\n- Do not invent gene names, pathways, or biological claims.\n- If working with patient or human-subject data, remind me to check privacy constraints.\n</code></pre>"},{"location":"publishing/","title":"Publishing as a GitHub Page","text":"<p>This repo is set up to publish an MkDocs site (nice theme, sidebar navigation, built-in search).</p>"},{"location":"publishing/#option-a-github-actions-recommended","title":"Option A: GitHub Actions (recommended)","text":"<p>This repo includes a workflow that builds MkDocs and deploys to the <code>gh-pages</code> branch:</p> <ul> <li><code>.github/workflows/deploy-mkdocs.yml</code></li> </ul> <p>Steps:</p> <ol> <li>Push to a GitHub repo.</li> <li>Ensure your default branch is <code>main</code>.</li> <li>In GitHub: Settings -&gt; Pages.</li> <li>Set Source to \"Deploy from a branch\".</li> <li>Select branch <code>gh-pages</code> and folder <code>/ (root)</code>.</li> </ol> <p>Every push to <code>main</code> will rebuild and redeploy.</p>"},{"location":"publishing/#option-b-plain-markdown-from-docs-simpler-fewer-features","title":"Option B: Plain Markdown from /docs (simpler, fewer features)","text":"<p>If you do not want a build step, GitHub Pages can render Markdown directly from <code>/docs</code>, but you lose nice navigation/search.</p> <p>Steps:</p> <ol> <li>In GitHub: Settings -&gt; Pages.</li> <li>Set Source to \"Deploy from a branch\".</li> <li>Choose your default branch and select the <code>/docs</code> folder.</li> </ol>"},{"location":"reproducibility/","title":"Reproducibility Habits (AI-Assisted Work)","text":"<p>Agentic AI can change many files quickly. Reproducibility is how you keep that power from becoming chaos.</p> <p>This matters more, not less, when AI is involved. If you can't reproduce your results, you can't trust them\u2014and neither can reviewers.</p>"},{"location":"reproducibility/#the-minimum-bar","title":"The minimum bar","text":"<p>\"Fresh clone \u2192 one command \u2192 same key outputs.\"</p> <p>This is the reproducibility test. Someone (including future you) should be able to:</p> <ol> <li>Clone your repository</li> <li>Install dependencies</li> <li>Run one command</li> <li>Get the same figures/tables/results</li> </ol> <p>If that works, you're in good shape. If it doesn't, you have a reproducibility problem.</p>"},{"location":"reproducibility/#what-to-capture","title":"What to capture","text":""},{"location":"reproducibility/#inputs","title":"Inputs","text":"<ul> <li>Source data: Where did it come from? What version? When was it accessed?</li> <li>Preprocessing: What transformations were applied before analysis?</li> <li>External resources: Any APIs, databases, or services used?</li> </ul> <pre><code># data/README.md\n\n## raw/measurements.csv\n- Source: Lab instrument export, 2025-11-15\n- Instrument: Shimadzu LC-2050\n- Operator: Jane Doe\n- Notes: Contains raw peak areas, some saturated readings in column F\n\n## processed/cleaned_data.csv\n- Generated by: scripts/preprocess.py\n- From: raw/measurements.csv\n- Transformations: Remove saturated readings, normalize by internal standard\n</code></pre>"},{"location":"reproducibility/#parameters","title":"Parameters","text":"<p>Don't bury parameters in code. Make them explicit:</p> <pre><code># configs/paper_figure1.yaml\ndata:\n  input_path: data/processed/cleaned_data.csv\n  test_fraction: 0.2\n\nmodel:\n  learning_rate: 0.001\n  batch_size: 32\n  epochs: 100\n\noutput:\n  seed: 42\n  figures_dir: results/figures/\n</code></pre> <p>Then your script loads the config:</p> <pre><code>python scripts/make_figure.py --config configs/paper_figure1.yaml\n</code></pre> <p>Anyone can see exactly what parameters produced your results.</p>"},{"location":"reproducibility/#environment","title":"Environment","text":"<p>Pin your dependencies. \"It worked on my machine\" is not reproducibility.</p> <pre><code># Create requirements file\npip freeze &gt; requirements.txt\n\n# Or better, use a lockfile\npip-compile requirements.in &gt; requirements.txt\n</code></pre> <p>For conda: <pre><code>conda env export &gt; environment.yml\n</code></pre></p> <p>Document OS assumptions if they matter (they often do for numerical code).</p>"},{"location":"reproducibility/#randomness","title":"Randomness","text":"<p>Many analyses involve randomness. Control it:</p> <pre><code>import numpy as np\nimport random\n\n# Set seeds at the start of your script\nSEED = 42\nnp.random.seed(SEED)\nrandom.seed(SEED)\n\n# For PyTorch\nimport torch\ntorch.manual_seed(SEED)\ntorch.backends.cudnn.deterministic = True\n</code></pre> <p>Put the seed in your config file so it's documented and changeable.</p>"},{"location":"reproducibility/#outputs","title":"Outputs","text":"<p>Results should go to predictable locations:</p> <pre><code>results/\n\u251c\u2500\u2500 figures/\n\u2502   \u251c\u2500\u2500 figure1_main_result.pdf\n\u2502   \u2514\u2500\u2500 figure2_comparison.pdf\n\u251c\u2500\u2500 tables/\n\u2502   \u2514\u2500\u2500 table1_summary_stats.csv\n\u2514\u2500\u2500 logs/\n    \u2514\u2500\u2500 run_2025-11-15_14-32.log\n</code></pre>"},{"location":"reproducibility/#the-two-essential-patterns","title":"The two essential patterns","text":""},{"location":"reproducibility/#pattern-1-makefile-as-source-of-truth","title":"Pattern 1: Makefile as source of truth","text":"<p>A Makefile (or <code>justfile</code>) encodes the canonical commands:</p> <pre><code>.PHONY: install test figures clean all\n\ninstall:\n    pip install -r requirements.txt\n\ntest:\n    pytest tests/ -v\n\nfigures: data/processed/cleaned_data.csv\n    python scripts/make_figures.py --config configs/paper.yaml\n\ndata/processed/cleaned_data.csv: data/raw/measurements.csv\n    python scripts/preprocess.py\n\nclean:\n    rm -rf results/figures/*\n    rm -rf results/tables/*\n\nall: install test figures\n</code></pre> <p>Now anyone can run <code>make figures</code> and get your results.</p>"},{"location":"reproducibility/#pattern-2-configs-folder-with-paper-ready-configs","title":"Pattern 2: Configs folder with \"paper-ready\" configs","text":"<pre><code>configs/\n\u251c\u2500\u2500 default.yaml           # Development defaults\n\u251c\u2500\u2500 paper_figure1.yaml     # Exact config for Figure 1\n\u251c\u2500\u2500 paper_figure2.yaml     # Exact config for Figure 2\n\u2514\u2500\u2500 supplementary.yaml     # Supplementary material\n</code></pre> <p>Check these into git. They document exactly what produced each result.</p>"},{"location":"reproducibility/#ai-specific-reproducibility-concerns","title":"AI-specific reproducibility concerns","text":""},{"location":"reproducibility/#the-agent-changed-many-things","title":"The agent changed many things","text":"<p>When an agent makes changes across multiple files, reproducibility gets harder. Mitigations:</p> <ol> <li>Commit frequently: Small commits let you trace what changed when</li> <li>Review diffs carefully: The agent might change things you didn't expect</li> <li>Run verification after each change: Don't let errors accumulate</li> </ol>"},{"location":"reproducibility/#model-versions-matter","title":"Model versions matter","text":"<p>The same prompt can give different results with different model versions. Document which model you used:</p> <pre><code>## Methods\n\nAnalysis code was developed with assistance from Claude Code (Claude Opus 4.5,\naccessed November 2025). All code was reviewed and verified by the authors.\n</code></pre>"},{"location":"reproducibility/#non-deterministic-ai-outputs","title":"Non-deterministic AI outputs","text":"<p>AI suggestions aren't deterministic. The same prompt might give different code on different days. This is fine if:</p> <ul> <li>You verify the output works</li> <li>You commit the actual code (not the prompt)</li> <li>The code itself is deterministic</li> </ul>"},{"location":"reproducibility/#testing-reproducibility","title":"Testing reproducibility","text":"<p>Before you publish or share:</p> <pre><code># Clone fresh copy\ngit clone your-repo /tmp/fresh-clone\ncd /tmp/fresh-clone\n\n# Follow your own setup instructions\npip install -r requirements.txt\n\n# Run the canonical command\nmake figures\n\n# Compare outputs\ndiff -r results/figures ../original-repo/results/figures\n</code></pre> <p>If this works, you're reproducible. If not, fix it now.</p>"},{"location":"reproducibility/#common-reproducibility-failures","title":"Common reproducibility failures","text":""},{"location":"reproducibility/#it-works-on-my-machine","title":"\"It works on my machine\"","text":"<ul> <li>Missing dependencies not in requirements.txt</li> <li>Hardcoded absolute paths</li> <li>Relying on environment variables not documented</li> </ul>"},{"location":"reproducibility/#it-worked-last-month","title":"\"It worked last month\"","text":"<ul> <li>Dependencies updated and broke things</li> <li>Data source changed</li> <li>External API behavior changed</li> </ul>"},{"location":"reproducibility/#the-figures-look-slightly-different","title":"\"The figures look slightly different\"","text":"<ul> <li>Random seeds not set</li> <li>Floating point non-determinism (especially on GPU)</li> <li>Font/rendering differences (usually okay)</li> </ul>"},{"location":"reproducibility/#a-prompt-for-the-agent","title":"A prompt for the agent","text":"<pre><code>Help me make this project reproducible.\n\nRequirements:\n- Add a Makefile with `make install`, `make test`, and `make figures`\n- Pin all dependencies in requirements.txt\n- Move hardcoded parameters to configs/default.yaml\n- Add a data/README.md documenting data sources\n- Set random seeds in all scripts that use randomness\n\nVerification:\n- Clone to a fresh directory\n- Run make all\n- Confirm outputs match\n</code></pre>"},{"location":"reproducibility/#see-also","title":"See also","text":"<ul> <li>Project Structure</li> <li>Data Analysis</li> <li>Figures and Tables</li> <li>Verification and Rigor</li> <li>Lab Rollout</li> </ul>"},{"location":"safety-privacy/","title":"Safety, Privacy, and Policy","text":"<p>This is the \"don't get fired / don't leak data / don't fool yourself\" page.</p>"},{"location":"safety-privacy/#defaults-recommended","title":"Defaults (recommended)","text":"<ul> <li>Don't put unpublished results, sensitive human-subject data, credentials, or embargoed material into any tool unless your institution explicitly allows it.</li> <li>Treat AI output as untrusted until you verify it.</li> <li>Prefer working in a repository with version control so you can review diffs.</li> </ul>"},{"location":"safety-privacy/#data-classification-simple-version","title":"Data classification (simple version)","text":"<p>Default to these categories:</p> <ul> <li>Public: papers, public code, public datasets</li> <li>Internal: lab notes, non-public drafts, internal docs</li> <li>Sensitive: human-subject data, patient data, credentials, export-controlled data</li> </ul> <p>Rule of thumb:</p> <ul> <li>Public is usually OK.</li> <li>Internal might be OK depending on your institution.</li> <li>Sensitive is usually NOT OK without explicit approvals and the right tooling.</li> </ul>"},{"location":"safety-privacy/#secrets","title":"Secrets","text":"<p>Never paste:</p> <ul> <li>API keys</li> <li>passwords</li> <li>private tokens</li> <li>SSH keys</li> </ul> <p>If the agent needs to access something, use environment variables or local config files that are not committed.</p>"},{"location":"safety-privacy/#human-oversight","title":"Human oversight","text":"<p>Even if agentic AI can do a lot, you still need to:</p> <ul> <li>inspect diffs</li> <li>run checks</li> <li>validate math and statistics</li> <li>verify citations and claims</li> </ul>"},{"location":"safety-privacy/#citations-and-factual-claims","title":"Citations and factual claims","text":"<p>Default rule:</p> <ul> <li>If you did not provide sources, assume citations can be wrong or invented.</li> </ul> <p>Better pattern:</p> <ul> <li>Provide the PDFs or URLs.</li> <li>Ask the agent to quote and attribute specific claims to specific sources.</li> </ul>"},{"location":"safety-privacy/#code-execution-safety","title":"Code execution safety","text":"<p>Agents can run commands. That is powerful and risky.</p> <p>Safe defaults:</p> <ul> <li>run in a repo, not your whole home directory</li> <li>prefer throwaway copies for early experiments</li> <li>review commands before running if you do not recognize them</li> </ul>"},{"location":"safety-privacy/#common-failure-modes","title":"Common failure modes","text":"<ul> <li>Confident wrong answers (especially on niche domain facts)</li> <li>\"Looks right\" plots with incorrect preprocessing</li> <li>Silent changes in assumptions (units, coordinate conventions)</li> <li>Fake citations</li> </ul>"},{"location":"safety-privacy/#a-simple-policy-for-a-lab","title":"A simple policy for a lab","text":"<ul> <li>No sensitive data in external tools.</li> <li>All code changes reviewed via diff.</li> <li>All key results reproducible via a one-command run.</li> <li>All citations verified.</li> </ul>"},{"location":"scaling-up/","title":"Scaling Up Your Usage (Advanced)","text":"<p>Once you have the basics down, the biggest productivity jump comes from running multiple agent sessions in parallel.</p> <p>Example: many terminals open, each running Claude Code on a different task.</p> <p>This page explains how to scale up without losing correctness, burning money, or making a reproducibility mess.</p>"},{"location":"scaling-up/#the-core-idea","title":"The core idea","text":"<p>You are not using \"one assistant\". You are running a small team.</p> <p>That means you need:</p> <ul> <li>clear task boundaries</li> <li>a shared definition of done</li> <li>a verification step per task</li> <li>a way to merge results safely</li> </ul>"},{"location":"scaling-up/#what-parallelism-is-good-for","title":"What parallelism is good for","text":"<ul> <li>\"Do in parallel\" work:</li> <li>writing tests while another session refactors</li> <li>generating a figure script while another session cleans a dataset</li> <li>drafting paper text while another session builds a reproducible pipeline</li> <li> <p>literature summaries in parallel (paper A, paper B, paper C)</p> </li> <li> <p>\"Do not parallelize\" work:</p> </li> <li>editing the same file in multiple sessions</li> <li>changing the same experiment config from multiple places</li> <li>anything where you cannot easily compare outputs</li> </ul>"},{"location":"scaling-up/#a-practical-setup","title":"A practical setup","text":""},{"location":"scaling-up/#1-one-terminal-per-task","title":"1) One terminal per task","text":"<p>Name the job in your first message:</p> <ul> <li>\"Session A: refactor + tests\"</li> <li>\"Session B: figures\"</li> <li>\"Session C: README + reproducibility\"</li> </ul>"},{"location":"scaling-up/#2-one-branch-or-worktree-per-task","title":"2) One branch (or worktree) per task","text":"<p>If you use git, the clean approach is one branch per task.</p> <p>If you are comfortable with git worktrees, they are ideal for parallel agents. Each agent gets its own folder and can edit freely.</p> <p>Rule: never run two agents against the same working directory.</p>"},{"location":"scaling-up/#3-one-verification-command-per-task","title":"3) One verification command per task","text":"<p>Examples:</p> <ul> <li><code>pytest</code></li> <li><code>make figures</code></li> <li><code>python scripts/make_fig_2.py --config configs/fig2.yaml</code></li> </ul> <p>If the agent cannot tell you what command proves success, the task is not ready.</p>"},{"location":"scaling-up/#coordination-patterns","title":"Coordination patterns","text":""},{"location":"scaling-up/#pattern-manager-workers","title":"Pattern: manager + workers","text":"<p>One \"manager\" session:</p> <ul> <li>maintains the plan</li> <li>defines interfaces (file names, function signatures)</li> <li>reviews results from worker sessions</li> </ul> <p>Worker sessions:</p> <ul> <li>implement a specific piece</li> <li>provide diffs and the verification output</li> </ul> <p>This reduces chaos dramatically.</p>"},{"location":"scaling-up/#pattern-critique-session","title":"Pattern: critique session","text":"<p>Keep one session whose only job is:</p> <ul> <li>review diffs</li> <li>look for footguns</li> <li>propose tests</li> </ul> <p>Even if you do not run multiple agents, this pattern is worth it.</p>"},{"location":"scaling-up/#preventing-the-common-disasters","title":"Preventing the common disasters","text":""},{"location":"scaling-up/#disaster-1-two-agents-edit-the-same-file","title":"Disaster 1: two agents edit the same file","text":"<p>Fix:</p> <ul> <li>assign ownership per file</li> <li>split tasks by module</li> <li>use worktrees/branches</li> </ul>"},{"location":"scaling-up/#disaster-2-the-repo-works-but-results-changed-silently","title":"Disaster 2: the repo \"works\" but results changed silently","text":"<p>Fix:</p> <ul> <li>pin dependencies</li> <li>capture configs</li> <li>add regression checks (hashes, summary stats)</li> <li>require the agent to explain any output changes</li> </ul>"},{"location":"scaling-up/#disaster-3-cost-explodes","title":"Disaster 3: cost explodes","text":"<p>Fix:</p> <ul> <li>set a budget per day/week</li> <li>keep tasks small</li> <li>stop runaway sessions</li> <li>do not paste huge context repeatedly</li> </ul> <p>See: Cost Control</p>"},{"location":"scaling-up/#a-concrete-multi-terminal-workflow","title":"A concrete \"multi-terminal\" workflow","text":"<ol> <li>Create a task list for the next 2 hours.</li> <li>Split into 3-5 independent tasks.</li> <li>Create a new branch/worktree per task.</li> <li>Start a session per branch.</li> <li>Require each session to:</li> <li>propose a plan</li> <li>keep changes small</li> <li>run verification</li> <li>summarize what changed</li> <li>Merge one task at a time back into main.</li> </ol>"},{"location":"scaling-up/#useful-prompts","title":"Useful prompts","text":""},{"location":"scaling-up/#session-kickoff-prompt","title":"Session kickoff prompt","text":"<pre><code>You are working in parallel with other agent sessions.\n\nYour task:\n- &lt;one specific task&gt;\n\nRules:\n- Only edit files in &lt;folder/module&gt;.\n- Do not edit files owned by other sessions.\n- Propose a plan first.\n- Provide a verification command and run it.\n- End by summarizing the diff in plain English.\n</code></pre>"},{"location":"scaling-up/#manager-prompt","title":"Manager prompt","text":"<pre><code>You are the \"manager\" agent.\n\nYour job:\n- break work into independent tasks\n- assign file ownership\n- define interfaces between tasks\n- define verification commands\n\nOutput:\n- a numbered task list with owners (Session A/B/C)\n- the expected artifacts per task\n</code></pre>"},{"location":"scaling-up/#if-you-are-doing-science-not-software","title":"If you are doing science (not software)","text":"<p>The same idea applies:</p> <ul> <li>parallelize what is independent</li> <li>centralize decisions about assumptions, units, and definitions</li> <li>treat every output as untrusted until it passes checks</li> </ul>"},{"location":"setup/","title":"Setup Checklist","text":"<p>This page is intentionally practical.</p>"},{"location":"setup/#accounts-and-billing","title":"Accounts and billing","text":"<ul> <li>Pick one primary tool (recommendation: Claude Code).</li> <li>Decide who pays: you personally vs lab vs institution.</li> <li>Turn on billing alerts where possible.</li> </ul>"},{"location":"setup/#local-machine-basics","title":"Local machine basics","text":"<p>Minimum you want:</p> <ul> <li>a terminal you are comfortable using</li> <li>Python (or your language) installed</li> <li>a way to create isolated environments (venv/conda)</li> <li>git installed</li> </ul>"},{"location":"setup/#project-hygiene-do-this-once","title":"Project hygiene (do this once)","text":"<ul> <li>Put the project in a repo (git).</li> <li>Add a <code>README.md</code> with setup and the \"one command\" run.</li> <li>Add a <code>Makefile</code> or similar task runner.</li> <li>Add a tiny test / sanity check.</li> </ul>"},{"location":"setup/#your-first-guardrails","title":"Your first guardrails","text":"<p>In your first sessions, make these rules explicit:</p> <ul> <li>propose a plan before editing</li> <li>keep changes small and reviewable</li> <li>run verification commands</li> <li>do not add citations or claims you cannot verify</li> </ul>"},{"location":"setup/#if-you-are-in-a-regulated-environment","title":"If you are in a regulated environment","text":"<p>Stop and get clarity on:</p> <ul> <li>human-subject data rules</li> <li>patient/clinical data policies</li> <li>export controls / ITAR</li> <li>data retention and sharing policies</li> </ul> <p>Default safe policy: do not paste sensitive data into any external tool.</p>"},{"location":"tooling/","title":"Pick Your Tools","text":"<p>There is no single best tool. Choose based on your comfort level, your workflow, and your institution.</p>"},{"location":"tooling/#recommended-default-claude-code","title":"Recommended default: Claude Code","text":"<p>Why:</p> <ul> <li>works in a terminal (fits research workflows)</li> <li>edits files and runs commands</li> <li>good at larger refactors and multi-step tasks</li> </ul> <p>Start here: Claude Code</p> <p>If you already pay for a ChatGPT plan (Plus/Pro/Team/Edu/Enterprise), you can also use the terminal-based OpenAI Codex CLI without adding a separate Claude subscription. For many people, that is the cheapest way to get a \"Claude Code-like\" workflow.</p>"},{"location":"tooling/#alternatives-common","title":"Alternatives (common)","text":"<ul> <li>Cursor: AI-first code editor with agent features</li> <li>GitHub Copilot: agent/chat inside IDEs + GitHub</li> <li>OpenAI Codex CLI: coding agent that runs in your terminal</li> </ul>"},{"location":"tooling/#what-matters-more-than-the-tool","title":"What matters more than the tool","text":"<ul> <li>Your verification habits</li> <li>A reproducible project structure</li> <li>Good prompts that define constraints and \"done\"</li> </ul>"},{"location":"tooling/#suggested-stack-for-a-typical-lab","title":"Suggested stack for a typical lab","text":"<ul> <li>Agentic coding: Claude Code</li> <li>General assistant + deep research: whichever your institution supports</li> <li>Version control: Git + GitHub (or your institution's GitLab)</li> <li>Reproducibility: pinned environments + a one-command run</li> </ul>"},{"location":"troubleshooting/","title":"Troubleshooting","text":"<p>Agentic tools fail in predictable ways. Most fixes are workflow fixes.</p>"},{"location":"troubleshooting/#when-the-agent-thrashes","title":"When the agent \"thrashes\"","text":"<p>Symptoms:</p> <ul> <li>repeated edits without progress</li> <li>long responses that do not change the outcome</li> </ul> <p>Fix:</p> <ul> <li>stop and restate the goal</li> <li>ask for a smaller plan</li> <li>reduce scope to a minimal reproducible example</li> </ul>"},{"location":"troubleshooting/#when-results-are-wrong-but-plausible","title":"When results are wrong but plausible","text":"<p>Fix:</p> <ul> <li>add explicit sanity checks</li> <li>test on synthetic data</li> <li>require units and assumptions</li> </ul>"},{"location":"troubleshooting/#when-the-environment-breaks","title":"When the environment breaks","text":"<p>Fix:</p> <ul> <li>pin dependencies</li> <li>use a virtual environment</li> <li>add a one-command setup</li> </ul>"},{"location":"troubleshooting/#if-you-get-lost","title":"If you get lost","text":"<ul> <li>use <code>git diff</code> to see what changed</li> <li>make a commit before big changes</li> <li>revert or back out changes rather than trying to patch blindly</li> </ul>"},{"location":"troubleshooting/#recovery-strategies-for-bigger-messes","title":"Recovery strategies for bigger messes","text":""},{"location":"troubleshooting/#the-agent-made-many-wrong-changes","title":"The agent made many wrong changes","text":"<p>If you caught it early: <pre><code>git checkout .          # discard all uncommitted changes\ngit clean -fd           # remove untracked files (careful!)\n</code></pre></p> <p>If you already committed: <pre><code>git log --oneline       # find the last good commit\ngit reset --hard &lt;hash&gt; # go back to it (loses later commits)\n</code></pre></p> <p>If you want to keep some changes: <pre><code>git stash               # set aside current changes\ngit diff HEAD~3         # review last 3 commits\n# cherry-pick what you want to keep\n</code></pre></p>"},{"location":"troubleshooting/#the-agent-introduced-a-subtle-bug-in-mathstatistics","title":"The agent introduced a subtle bug in math/statistics","text":"<p>This is the hardest case because the code \"works\" but produces wrong results.</p> <p>Prevention is better than cure: - Always add sanity checks (known values, limiting cases) - Compare against a reference implementation or hand calculation - Use synthetic data where you know the correct answer</p> <p>If you suspect a bug: 1. Isolate the suspicious section 2. Add print statements or logging for intermediate values 3. Test on a minimal example 4. Ask a different model (or a colleague) to review</p>"},{"location":"troubleshooting/#the-agent-fixed-something-that-wasnt-broken","title":"The agent \"fixed\" something that wasn't broken","text":"<p>Classic symptoms: - A working feature stops working - Tests that passed now fail - Behavior changed in ways you didn't ask for</p> <p>Fix: 1. <code>git diff</code> to see exactly what changed 2. Revert the specific changes that broke things 3. Be more specific in your next prompt: \"Only change X, do not modify Y\"</p>"},{"location":"troubleshooting/#the-session-is-too-long-and-quality-has-dropped","title":"The session is too long and quality has dropped","text":"<p>Signs: - Agent forgets earlier context - Repeated mistakes - Circular conversations</p> <p>Fix: 1. Summarize what you accomplished so far 2. Start a fresh session 3. Paste only the essential context into the new session</p>"},{"location":"troubleshooting/#preventing-problems-before-they-start","title":"Preventing problems before they start","text":"<ul> <li>Commit frequently: Small commits are easy to revert.</li> <li>Review diffs immediately: Don't let changes pile up.</li> <li>Keep tasks small: One clear goal per session.</li> <li>Define \"done\" upfront: A test, a command, a specific output.</li> </ul>"},{"location":"troubleshooting/#see-also","title":"See also","text":"<ul> <li>Workflows (Plan-Do-Verify)</li> <li>Verification and Rigor</li> <li>Git Basics</li> </ul>"},{"location":"verification/","title":"Verification and Rigor (How Not to Fool Yourself)","text":"<p>Agentic AI can be fast. It is not inherently careful.</p> <p>Your job is to make correctness cheap.</p>"},{"location":"verification/#what-to-verify","title":"What to verify","text":""},{"location":"verification/#code","title":"Code","text":"<ul> <li>Does it run?</li> <li>Do tests pass?</li> <li>Are edge cases handled?</li> </ul>"},{"location":"verification/#math-and-statistics","title":"Math and statistics","text":"<ul> <li>Units and dimensional analysis</li> <li>Limiting cases</li> <li>Known benchmarks</li> <li>Synthetic data tests</li> </ul>"},{"location":"verification/#plots-and-figures","title":"Plots and figures","text":"<ul> <li>Are axes labeled correctly?</li> <li>Are you plotting what you think you are plotting?</li> <li>Are preprocessing steps recorded?</li> </ul>"},{"location":"verification/#writing","title":"Writing","text":"<ul> <li>No invented citations</li> <li>Claims match the data</li> <li>Clear separation between results and speculation</li> </ul>"},{"location":"verification/#a-verification-mindset","title":"A verification mindset","text":"<p>Ask:</p> <ul> <li>What would prove this wrong?</li> <li>What is the simplest test that would catch the most likely mistake?</li> </ul>"},{"location":"verification/#cross-checking","title":"Cross-checking","text":"<p>Useful pattern:</p> <ul> <li>Use one model to propose.</li> <li>Use another model (or your own reasoning) to critique.</li> </ul> <p>But do not confuse \"two models agree\" with truth. They can share the same blind spots.</p>"},{"location":"verification/#reproducibility-is-part-of-verification","title":"Reproducibility is part of verification","text":"<p>If you cannot rerun it reliably, you cannot really verify it.</p>"},{"location":"verification/#staying-sharp-avoiding-skill-atrophy","title":"Staying sharp (avoiding skill atrophy)","text":"<p>Heavy AI use can erode your own abilities if you are not deliberate.</p> <p>Habits that help:</p> <ul> <li>Do some work by hand: One derivation per week, one script without AI assistance.</li> <li>Explain it back: After the AI solves something, explain the solution to yourself (or a colleague). If you cannot, you did not learn.</li> <li>Require explanations: Ask the AI to explain its reasoning, then evaluate whether the reasoning is sound.</li> <li>Periodically calibrate: Try a task without AI, then with AI. Notice what you would have missed.</li> </ul> <p>The goal is not to avoid AI, but to ensure you remain capable of catching its mistakes.</p>"},{"location":"verification/#see-also","title":"See also","text":"<ul> <li>Workflows (Plan-Do-Verify)</li> <li>Troubleshooting</li> <li>Reproducibility</li> </ul>"},{"location":"why-agentic/","title":"Why Agentic AI (Instead of Chat)","text":"<p>You've probably used ChatGPT or Claude's web interface. You ask a question, get an answer, copy some code, paste it, run it, hit an error, go back, ask again... it works, but there's friction at every step.</p> <p>Agentic AI is different. Instead of chatting back and forth, you give the agent access to your actual project. It reads your files, writes code, runs commands, sees the errors, and fixes them\u2014all while you supervise.</p> <p>This page explains why that matters for scientists.</p>"},{"location":"why-agentic/#chat-only-ai-vs-agentic-ai","title":"Chat-only AI vs agentic AI","text":""},{"location":"why-agentic/#chat-only-workflow","title":"Chat-only workflow","text":"<ol> <li>Describe your problem in words</li> <li>Get code in a chat response</li> <li>Copy the code</li> <li>Paste into a file</li> <li>Run it</li> <li>Hit an error</li> <li>Copy the error back to chat</li> <li>Get a fix</li> <li>Repeat steps 3-8 until it works</li> <li>Hope you didn't introduce bugs while copy-pasting</li> </ol> <p>This works for small things, but it's exhausting for real projects.</p>"},{"location":"why-agentic/#agentic-workflow","title":"Agentic workflow","text":"<ol> <li>Point the agent at your project folder</li> <li>Describe what you want</li> <li>The agent reads your files, understands the context</li> <li>It writes code directly into your files</li> <li>It runs the code, sees errors, fixes them</li> <li>You review the changes (via diff)</li> <li>You run verification (tests, scripts)</li> <li>Done</li> </ol> <p>The agent handles the mechanical parts. You handle the judgment.</p>"},{"location":"why-agentic/#what-agentic-tools-can-actually-do","title":"What agentic tools can actually do","text":""},{"location":"why-agentic/#read-and-understand-your-project","title":"Read and understand your project","text":"<p>The agent can: - See your file structure - Read your existing code - Understand your dependencies - Know what functions exist and what they do</p> <p>This means you don't have to explain everything from scratch every time.</p>"},{"location":"why-agentic/#edit-files-directly","title":"Edit files directly","text":"<p>Instead of giving you code to copy-paste, the agent edits your actual files. You see a diff of exactly what changed, just like a code review.</p>"},{"location":"why-agentic/#run-commands-and-see-results","title":"Run commands and see results","text":"<p>The agent can: - Run your scripts - Execute tests - See error messages - Check if things work</p> <p>This creates a feedback loop: try something, see if it works, fix it if not.</p>"},{"location":"why-agentic/#iterate-until-it-works","title":"Iterate until it works","text":"<p>When something fails, the agent can: - Read the error message - Understand what went wrong - Propose a fix - Try again</p> <p>This loop\u2014try, fail, fix, retry\u2014is where most coding time goes. The agent can do it faster.</p>"},{"location":"why-agentic/#concrete-examples","title":"Concrete examples","text":""},{"location":"why-agentic/#example-fix-my-broken-script","title":"Example: \"Fix my broken script\"","text":"<p>Chat approach: You paste your script into chat. You paste the error. You get a suggestion. You paste it back into your file. You run it. New error. Paste that. Get another suggestion. Repeat.</p> <p>Agentic approach: You say \"This script is failing with [error]. Fix it.\" The agent reads the script, runs it, sees the error, identifies the problem, fixes it, runs it again, confirms it works. You review the diff and approve.</p>"},{"location":"why-agentic/#example-make-this-reproducible","title":"Example: \"Make this reproducible\"","text":"<p>Chat approach: You ask for advice on making your analysis reproducible. You get a list of suggestions. You implement them yourself, one by one, asking follow-up questions when you get stuck.</p> <p>Agentic approach: You say \"Make this project reproducible: add a Makefile, pin dependencies, create a config file for parameters.\" The agent does it. Creates the Makefile. Generates requirements.txt. Extracts hardcoded values into a config. You review, test, done.</p>"},{"location":"why-agentic/#example-add-tests","title":"Example: \"Add tests\"","text":"<p>Chat approach: You paste a function. Ask for tests. Get tests back. Create a test file. Paste them in. Run pytest. Some fail because of import issues. Ask for fixes. Repeat.</p> <p>Agentic approach: You say \"Add tests for the functions in src/analysis.py.\" The agent reads your code, writes tests, runs them, fixes import issues, runs again until they pass. You review the tests, verify they make sense, done.</p>"},{"location":"why-agentic/#the-real-shift","title":"The real shift","text":"<p>When you use agentic AI well, your job changes. You spend less time on:</p> <ul> <li>Typing code</li> <li>Debugging syntax errors</li> <li>Setting up project structure</li> <li>Writing boilerplate</li> </ul> <p>You spend more time on:</p> <ul> <li>Defining the goal - What exactly should this do?</li> <li>Setting constraints - What must not change? What matters most?</li> <li>Verifying results - Is this actually correct? Does it match expectations?</li> <li>Making decisions - Which approach should we take?</li> </ul> <p>This is a managerial skill, not a coding skill. You're directing and reviewing, not typing.</p>"},{"location":"why-agentic/#when-agentic-ai-helps-most","title":"When agentic AI helps most","text":""},{"location":"why-agentic/#setup-and-infrastructure","title":"Setup and infrastructure","text":"<p>The \"yak shaving\" that eats your time: - Setting up a new project - Configuring environments - Writing Makefiles - Creating CLI interfaces - Organizing messy code</p>"},{"location":"why-agentic/#refactoring","title":"Refactoring","text":"<p>Making code better without changing behavior: - Extracting functions - Renaming for clarity - Adding type hints - Splitting large files</p>"},{"location":"why-agentic/#debugging","title":"Debugging","text":"<p>When you have an error and need to fix it: - Reading stack traces - Identifying root causes - Proposing and testing fixes</p>"},{"location":"why-agentic/#documentation","title":"Documentation","text":"<p>Generating docs from existing code: - README files - Docstrings - Usage examples</p>"},{"location":"why-agentic/#when-not-to-use-agentic-ai","title":"When NOT to use agentic AI","text":""},{"location":"why-agentic/#sensitive-data-you-cannot-share","title":"Sensitive data you cannot share","text":"<p>If your data contains: - Patient information - Classified material - Proprietary industry data - Anything your institution prohibits sharing</p> <p>Then don't put it in an external tool. See Safety &amp; Privacy.</p>"},{"location":"why-agentic/#high-stakes-decisions-without-verification","title":"High-stakes decisions without verification","text":"<p>Don't blindly trust AI output for: - Clinical decisions - Safety-critical systems - Published results (without verification) - Anything where being wrong has serious consequences</p>"},{"location":"why-agentic/#tasks-where-you-cannot-define-a-test","title":"Tasks where you cannot define a test","text":"<p>If you can't articulate what \"correct\" looks like, you can't verify the output. And if you can't verify, you shouldn't delegate.</p> <p>The rule: If you cannot verify it, do not delegate it.</p>"},{"location":"why-agentic/#getting-started","title":"Getting started","text":"<p>If this sounds useful, the next step is to try it:</p> <ol> <li>Pick a tool</li> <li>Set it up</li> <li>Do the first-hour exercise</li> </ol> <p>You'll learn more from 30 minutes of hands-on use than from reading about it.</p>"},{"location":"why-agentic/#see-also","title":"See also","text":"<ul> <li>What This Guide Is</li> <li>Workflows (Plan-Do-Verify)</li> <li>Pick Your Tools</li> </ul>"},{"location":"workflows/","title":"Workflows (Plan \u2192 Do \u2192 Verify)","text":"<p>Agentic tools feel magical when you treat them like a junior colleague: they move fast, but you own correctness.</p> <p>The core workflow is simple: Plan \u2192 Do \u2192 Verify \u2192 Record. This page explains each step and how to apply it in scientific work.</p>"},{"location":"workflows/#the-default-loop","title":"The default loop","text":""},{"location":"workflows/#1-plan","title":"1. Plan","text":"<p>Before the agent changes anything, ask for a plan:</p> <pre><code>Before making any changes, propose a plan:\n- What files will you modify?\n- What's your approach?\n- What could go wrong?\n- How will we verify it worked?\n</code></pre> <p>Review the plan. Does it make sense? Is the scope right? Will it touch things you don't want touched?</p> <p>Why this matters: Agents can move fast in the wrong direction. A 30-second plan review saves 30 minutes of cleanup.</p>"},{"location":"workflows/#2-do","title":"2. Do","text":"<p>Let the agent implement in small, reviewable chunks. Not everything at once.</p> <pre><code>Implement step 1 of the plan.\nStop after that step so I can review before continuing.\n</code></pre> <p>For larger tasks: <pre><code>Implement this in stages. After each stage:\n- Show me what changed\n- Run a quick verification\n- Wait for my approval before continuing\n</code></pre></p> <p>Why this matters: Small changes are reviewable. Large changes are overwhelming. You want to catch mistakes before they compound.</p>"},{"location":"workflows/#3-verify","title":"3. Verify","text":"<p>Run checks to confirm the changes work:</p> <ul> <li>Tests: <code>pytest tests/</code></li> <li>Scripts: Run them and check outputs</li> <li>Diffs: Review what actually changed</li> <li>Sanity checks: Do the numbers make sense?</li> </ul> <pre><code># See what changed\ngit diff\n\n# Run tests\npytest tests/ -v\n\n# Run the analysis and check outputs\npython scripts/analyze.py\n</code></pre> <p>Why this matters: \"It should work\" is not verification. Running it is verification.</p>"},{"location":"workflows/#4-record","title":"4. Record","text":"<p>Document what happened:</p> <ul> <li>Commit with a clear message</li> <li>Note any assumptions made</li> <li>Record how to reproduce</li> </ul> <pre><code>git add .\ngit commit -m \"Add data normalization step\n\n- Normalizes columns A-D by internal standard\n- Verified: outputs match expected values within 0.1%\n- Config: configs/normalization.yaml\n\nCo-Authored-By: Claude &lt;noreply@anthropic.com&gt;\"\n</code></pre> <p>Why this matters: Future you (and collaborators) need to know what was done and why.</p>"},{"location":"workflows/#what-to-verify-in-science-work","title":"What to verify in science work","text":"<p>Scientific verification is more demanding than typical software verification.</p>"},{"location":"workflows/#data-provenance","title":"Data provenance","text":"<ul> <li>Which exact files/versions were used?</li> <li>Were any transformations applied?</li> <li>Can you trace back to the raw data?</li> </ul> <pre><code>Before running this analysis, confirm:\n- Which data files you'll use\n- What preprocessing has been applied\n- Where outputs will be saved\n</code></pre>"},{"location":"workflows/#determinism","title":"Determinism","text":"<ul> <li>Are random seeds fixed?</li> <li>Are dependencies pinned?</li> <li>Are configs saved?</li> </ul> <pre><code>Add determinism to this analysis:\n- Set random seed to 42 at the start\n- Save the config used to results/run_config.yaml\n- Log the dependency versions\n</code></pre>"},{"location":"workflows/#sanity-checks","title":"Sanity checks","text":"<ul> <li>Do units make sense?</li> <li>Do limiting cases behave correctly?</li> <li>Do back-of-the-envelope estimates match?</li> </ul> <pre><code>Add sanity checks to this analysis:\n- Print min/max/mean of key variables\n- Verify units are consistent (all in SI)\n- Check that output is in expected range [0, 1]\n</code></pre>"},{"location":"workflows/#reproducibility","title":"Reproducibility","text":"<p>The gold standard: \"fresh clone \u2192 one command \u2192 same figures.\"</p> <pre><code>Verify reproducibility:\n- Clone to /tmp/test-repo\n- Run: pip install -r requirements.txt &amp;&amp; make figures\n- Compare outputs to the original\n</code></pre>"},{"location":"workflows/#example-workflows","title":"Example workflows","text":""},{"location":"workflows/#workflow-1-reproducible-analysis","title":"Workflow 1: Reproducible analysis","text":"<pre><code>You are helping me make this analysis reproducible.\n\nPlan first:\n- Identify all hardcoded parameters\n- Find all data dependencies\n- Check for random seeds\n\nRules:\n- Do not change scientific logic without asking\n- Move parameters to a config file\n- Add a single command that reproduces the main figure(s)\n- Add quick sanity checks (units, basic invariants)\n\nGoal:\n- When I run `make figures`, it produces the same outputs\n</code></pre>"},{"location":"workflows/#workflow-2-refactoring-for-a-new-lab-member","title":"Workflow 2: Refactoring for a new lab member","text":"<pre><code>Please refactor this project so a new lab member can run it.\n\nPlan first:\n- What's unclear about the current structure?\n- What's the minimum viable documentation?\n\nDeliverables:\n- README with setup + one-command run\n- Pinned dependencies (requirements.txt)\n- Scripts organized into a minimal pipeline\n- A short checklist for verifying outputs\n\nDo not change:\n- Scientific logic\n- Numerical outputs (verify they match before/after)\n</code></pre>"},{"location":"workflows/#workflow-3-debugging-a-failing-analysis","title":"Workflow 3: Debugging a failing analysis","text":"<pre><code>This analysis is producing wrong results.\n\nExpected: [describe expected output]\nActual: [describe actual output]\nError (if any): [paste error]\n\nApproach:\n1. First, understand the code and identify likely causes\n2. Propose a debugging plan\n3. Make minimal changes to fix the issue\n4. Verify the output is now correct\n\nDo not:\n- Refactor unrelated code\n- Change things that aren't broken\n</code></pre>"},{"location":"workflows/#workflow-4-adding-tests-to-existing-code","title":"Workflow 4: Adding tests to existing code","text":"<pre><code>Add tests for the core functions in src/analysis.py.\n\nPlan first:\n- Which functions are most critical to test?\n- What edge cases should be covered?\n\nRequirements:\n- Use pytest\n- Each test should run in under 1 second\n- Test both normal cases and edge cases\n- Include at least one test that verifies numerical accuracy\n\nRun the tests after writing them.\n</code></pre>"},{"location":"workflows/#when-to-break-the-loop","title":"When to break the loop","text":"<p>Sometimes you need to diverge from plan-do-verify:</p>"},{"location":"workflows/#exploration-mode","title":"Exploration mode","text":"<p>When you're exploring possibilities, not building:</p> <pre><code>I'm exploring different approaches. Don't implement anything yet.\nJust describe options for [X] and their tradeoffs.\n</code></pre>"},{"location":"workflows/#quick-fixes","title":"Quick fixes","text":"<p>For tiny, obvious fixes:</p> <pre><code>This is a one-line fix: [describe].\nJust make the change and verify it works.\n</code></pre>"},{"location":"workflows/#emergency-rollback","title":"Emergency rollback","text":"<p>When things are broken and you need to recover:</p> <pre><code>Stop. Don't make more changes.\nShow me git status and the last 5 commits.\nHelp me understand what went wrong.\n</code></pre>"},{"location":"workflows/#common-workflow-mistakes","title":"Common workflow mistakes","text":""},{"location":"workflows/#skipping-the-plan","title":"Skipping the plan","text":"<p>\"Just do it\" leads to surprises. Even for small tasks, a one-sentence plan helps.</p>"},{"location":"workflows/#too-much-at-once","title":"Too much at once","text":"<p>\"Refactor everything\" is not reviewable. \"Refactor the data loading function\" is.</p>"},{"location":"workflows/#trusting-without-verifying","title":"Trusting without verifying","text":"<p>\"The agent said it works\" is not verification. Run it yourself.</p>"},{"location":"workflows/#not-recording","title":"Not recording","text":"<p>If you don't commit and document, you'll forget what was done and why.</p>"},{"location":"workflows/#see-also","title":"See also","text":"<ul> <li>First Hour</li> <li>Verification and Rigor</li> <li>Checklists</li> <li>Troubleshooting</li> </ul>"},{"location":"writing/","title":"Writing and Grants","text":"<p>AI is very good at clarity and structure. It's also very good at sounding confident while being wrong.</p> <p>This page covers how to use AI for scientific writing without introducing errors or compromising integrity.</p>"},{"location":"writing/#what-ai-does-well","title":"What AI does well","text":""},{"location":"writing/#improving-clarity","title":"Improving clarity","text":"<p>AI excels at making dense prose more readable:</p> <ul> <li>Shortening long sentences</li> <li>Breaking up walls of text</li> <li>Improving flow between paragraphs</li> <li>Making passive voice active</li> <li>Removing jargon where simpler words work</li> </ul>"},{"location":"writing/#improving-structure","title":"Improving structure","text":"<p>AI can help organize your thoughts:</p> <ul> <li>Suggesting better section order</li> <li>Identifying gaps in logic</li> <li>Creating outlines from rough notes</li> <li>Ensuring consistent formatting</li> </ul>"},{"location":"writing/#mechanical-tasks","title":"Mechanical tasks","text":"<p>AI handles tedious formatting:</p> <ul> <li>LaTeX syntax and equation formatting</li> <li>Citation formatting (but not finding citations!)</li> <li>Table formatting</li> <li>Consistent capitalization and style</li> </ul>"},{"location":"writing/#what-ai-does-poorly","title":"What AI does poorly","text":""},{"location":"writing/#adding-factual-claims","title":"Adding factual claims","text":"<p>AI will confidently generate false information. Never let it add claims you haven't verified.</p> <p>Dangerous: <pre><code>Expand this methods section with more detail.\n</code></pre></p> <p>Safe: <pre><code>Improve the clarity of this methods section.\nDo not add any new claims or details.\nIf something is unclear, ask me to provide the information.\n</code></pre></p>"},{"location":"writing/#citations","title":"Citations","text":"<p>AI invents plausible-sounding but nonexistent references. Every single citation must be verified by a human.</p> <p>Bad: <pre><code>Add citations to support these claims.\n</code></pre></p> <p>Good: <pre><code>Flag where citations are needed. I will add them myself.\n</code></pre></p>"},{"location":"writing/#summarizing-sources-you-didnt-provide","title":"Summarizing sources you didn't provide","text":"<p>If you ask AI to summarize \"the literature on X,\" it will make things up. Only ask it to summarize documents you've actually provided.</p>"},{"location":"writing/#evaluating-scientific-correctness","title":"Evaluating scientific correctness","text":"<p>AI can't reliably tell if your science is right. It can make your prose clearer, but you must verify the content.</p>"},{"location":"writing/#a-workflow-that-works","title":"A workflow that works","text":""},{"location":"writing/#step-1-you-provide-the-facts","title":"Step 1: You provide the facts","text":"<p>Write a rough draft with all the key points, even if it's messy:</p> <ul> <li>Your results (numbers, figures, findings)</li> <li>Your methods (what you actually did)</li> <li>Your interpretations (what you think it means)</li> <li>Your references (papers you actually read)</li> </ul>"},{"location":"writing/#step-2-ai-improves-clarity-and-structure","title":"Step 2: AI improves clarity and structure","text":"<pre><code>Edit this draft for clarity and structure.\n\nRules:\n- Do not add any new claims or information\n- Do not add or modify citations\n- Do not change scientific conclusions\n- If something is unclear, ask me rather than guessing\n- Preserve my voice and style\n\nFocus on:\n- Sentence clarity\n- Paragraph flow\n- Removing redundancy\n- Consistent terminology\n</code></pre>"},{"location":"writing/#step-3-you-verify-everything","title":"Step 3: You verify everything","text":"<p>Read the edited version carefully: - Did it change any meanings? - Did it add anything that wasn't in the original? - Does every claim still match your data?</p> <p>This step is not optional.</p>"},{"location":"writing/#prompts-for-different-writing-tasks","title":"Prompts for different writing tasks","text":""},{"location":"writing/#abstract-editing","title":"Abstract editing","text":"<pre><code>Edit this abstract for clarity and impact.\n\nRules:\n- Keep it under [X] words\n- Do not change any claims or numbers\n- Preserve the structure: background, methods, results, conclusion\n- Make every sentence earn its place\n</code></pre>"},{"location":"writing/#methods-section","title":"Methods section","text":"<pre><code>Improve the clarity of this methods section.\n\nRules:\n- Do not add details I haven't provided\n- If something is unclear or missing, note it with [NEED: ...]\n- Ensure consistent past tense\n- Use active voice where appropriate\n</code></pre>"},{"location":"writing/#introduction-structure","title":"Introduction structure","text":"<pre><code>Suggest a better structure for this introduction.\n\nCurrent content: [paste your draft]\n\nI want to:\n- Start with [broad context]\n- Narrow to [specific problem]\n- End with [our contribution]\n\nGive me an outline, then I'll fill in the details.\n</code></pre>"},{"location":"writing/#results-description","title":"Results description","text":"<pre><code>Help me describe this figure clearly.\n\nFigure shows: [describe what the figure shows]\nKey finding: [what I want readers to take away]\n\nWrite a clear paragraph describing this result.\nDo not add interpretation beyond what I've stated.\nI will add the actual numbers.\n</code></pre>"},{"location":"writing/#response-to-reviewers","title":"Response to reviewers","text":"<pre><code>Help me draft a response to this reviewer comment.\n\nReviewer said: [paste comment]\n\nMy response points:\n- [point 1]\n- [point 2]\n- [what we changed]\n\nWrite a professional, clear response.\nKeep it respectful but don't be obsequious.\n</code></pre>"},{"location":"writing/#grant-writing","title":"Grant writing","text":"<p>Grant writing has additional considerations: you're making promises about future work.</p>"},{"location":"writing/#what-ai-can-help-with","title":"What AI can help with","text":"<ul> <li>Structuring the narrative</li> <li>Clarifying aims and significance</li> <li>Improving readability scores</li> <li>Formatting and compliance checks</li> </ul>"},{"location":"writing/#what-ai-should-not-do","title":"What AI should not do","text":"<ul> <li>Claim capabilities you don't have</li> <li>Promise results you can't deliver</li> <li>Generate preliminary data descriptions</li> <li>Write letters of support</li> </ul>"},{"location":"writing/#a-grant-specific-prompt","title":"A grant-specific prompt","text":"<pre><code>Edit this grant section for clarity and persuasiveness.\n\nRules:\n- Do not add claims about our capabilities\n- Do not add or modify any preliminary data descriptions\n- Do not change budget justifications\n- Flag any claims that seem unsupported with [VERIFY: ...]\n\nFocus on:\n- Clear, active prose\n- Logical flow between sections\n- Strong topic sentences\n- Eliminating jargon\n</code></pre>"},{"location":"writing/#disclosure","title":"Disclosure","text":"<p>When you use AI for writing, you may need to disclose it. See Disclosure and Attribution for guidance.</p> <p>Short version: - Check your target journal/funder's policy - When in doubt, disclose - Common language: \"AI writing assistance was used for clarity editing. All scientific content is the work of the authors.\"</p>"},{"location":"writing/#red-flags","title":"Red flags","text":"<p>Stop and reconsider if:</p> <ul> <li>The AI added a citation you don't recognize</li> <li>The AI made a claim you didn't provide</li> <li>The AI \"improved\" a number or statistic</li> <li>The AI changed the meaning of a result</li> <li>You're not sure if a sentence is true</li> </ul> <p>When in doubt: check the original, or delete the addition.</p>"},{"location":"writing/#the-bottom-line","title":"The bottom line","text":"<p>AI is a good editor, not a good author.</p> <ul> <li>Use it for: clarity, structure, formatting, mechanical tasks</li> <li>Don't use it for: adding content, finding sources, making claims</li> <li>Always: verify the output against your original intent</li> </ul> <p>Your name is on the paper. You are responsible for every word.</p>"},{"location":"writing/#see-also","title":"See also","text":"<ul> <li>Disclosure and Attribution</li> <li>Literature and Notes</li> <li>Prompt Templates</li> <li>Safety, Privacy, and Policy</li> </ul>"}]}