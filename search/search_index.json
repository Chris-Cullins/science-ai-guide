{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Agentic AI for Scientists","text":"<p>This guide is for scientists who are not professional software developers, but who do write code, analyze data, and produce papers.</p> <p>The core idea: instead of using an AI model like a chat box, you use an agent that can take actions (read/write files, run commands, iterate) with you supervising.</p>"},{"location":"#recommended-reading-path","title":"Recommended reading path","text":"<p>If you are new:</p> <ol> <li>What This Is</li> <li>Why Agentic AI</li> <li>Pick Your Tools</li> <li>Oh I Get It (Guided Tour)</li> <li>Bootcamp (2 Days)</li> <li>Quick Win (First Hour)</li> <li>Workflows (Plan-Do-Verify)</li> <li>Verification and Rigor</li> </ol> <p>If you are leading a lab:</p> <ol> <li>Lab Rollout</li> <li>Lab Policy Template</li> <li>Reproducibility</li> <li>Safety, Privacy, and Policy</li> </ol>"},{"location":"#where-to-start","title":"Where to start","text":"<ol> <li>Install and try a terminal agent on a small, non-sensitive project: Claude Code</li> <li>If you already pay for ChatGPT, you can use OpenAI Codex CLI instead.</li> <li>Learn the core workflow loop (plan -&gt; do -&gt; verify): Workflows</li> <li>Set guardrails for privacy, safety, and reproducibility: Safety &amp; Privacy</li> <li>Copy/paste prompt templates you can actually use: Prompt Templates</li> <li>Understand costs and avoid surprises: Pricing</li> </ol> <p>If you are onboarding a lab:</p> <ul> <li>First hour checklist: First Hour</li> <li>Lab rollout: Lab Rollout</li> <li>Disclosure/attribution: Disclosure</li> <li>Reproducibility habits: Reproducibility</li> </ul>"},{"location":"#a-quick-mental-model","title":"A quick mental model","text":"<ul> <li>Chat-only AI: you ask questions; you copy/paste results.</li> <li>Agentic AI: you give a task; it edits files and runs commands; you review diffs and outputs.</li> </ul> <p>If you can supervise work and verify results, agentic tools can compress days of \"yak shaving\" (setup, plumbing, debugging, refactors) into hours.</p>"},{"location":"ai-fluency/","title":"AI Fluency (A 1-Week Ramp)","text":"<p>The biggest gains come after you build a few habits.</p>"},{"location":"ai-fluency/#day-1-quick-win","title":"Day 1: Quick win","text":"<ul> <li>Do the \"First Hour\" task: First Hour</li> </ul>"},{"location":"ai-fluency/#day-2-make-verification-cheap","title":"Day 2: Make verification cheap","text":"<ul> <li>Add a <code>make test</code> and a <code>make run</code>.</li> <li>Add one tiny sanity check.</li> </ul>"},{"location":"ai-fluency/#day-3-convert-one-notebook","title":"Day 3: Convert one notebook","text":"<ul> <li>Turn one notebook into a script + config.</li> <li>Require identical outputs.</li> </ul>"},{"location":"ai-fluency/#day-4-refactor-for-a-new-lab-member","title":"Day 4: Refactor for a new lab member","text":"<ul> <li>Improve README.</li> <li>Pin dependencies.</li> <li>One-command run.</li> </ul>"},{"location":"ai-fluency/#day-5-literature-workflow","title":"Day 5: Literature workflow","text":"<ul> <li>Summarize 3 papers you provide.</li> <li>Produce a comparison table of assumptions and failure modes.</li> </ul>"},{"location":"ai-fluency/#day-6-writing-workflow","title":"Day 6: Writing workflow","text":"<ul> <li>Use AI for clarity-only editing.</li> <li>Verify every claim.</li> </ul>"},{"location":"ai-fluency/#day-7-make-a-lab-policy","title":"Day 7: Make a lab policy","text":"<ul> <li>Fill in: Lab Policy Template</li> </ul> <p>If you do just this week, you will be far ahead of most people.</p>"},{"location":"bootcamp/","title":"Bootcamp: Agentic AI for Scientists (2 Days)","text":"<p>This is a practical bootcamp plan you can run solo or as a lab.</p> <p>The goal is not to \"learn AI\". The goal is to build habits that produce correct, reproducible work faster.</p>"},{"location":"bootcamp/#day-0-30-minutes-safety-first","title":"Day 0 (30 minutes): Safety first","text":"<ol> <li>Decide what data you will NOT share.</li> <li>Default: no unpublished results, no human-subject data, no credentials.</li> <li>Decide whether you want a sandbox setup.</li> <li>See: Burner Machine and Sandboxes</li> <li>Pick one primary tool.</li> <li>Recommended: Claude Code (Claude Code)</li> <li>If you already pay for ChatGPT, consider OpenAI Codex CLI as a Claude Code alternative.</li> </ol>"},{"location":"bootcamp/#day-1-get-a-real-win-with-guardrails","title":"Day 1: Get a real win with guardrails","text":""},{"location":"bootcamp/#module-1-install-and-run-your-first-session-30-minutes","title":"Module 1: Install and run your first session (30 minutes)","text":"<ul> <li>Follow: Claude Code</li> <li>If you get stuck, use: Troubleshooting</li> </ul>"},{"location":"bootcamp/#module-2-first-win-60-minutes","title":"Module 2: First win (60 minutes)","text":"<p>Use: First Hour</p> <p>Target outcome:</p> <ul> <li>a README</li> <li>a one-command run</li> <li>a tiny sanity check</li> </ul>"},{"location":"bootcamp/#module-3-learn-the-workflow-loop-60-minutes","title":"Module 3: Learn the workflow loop (60 minutes)","text":"<p>Read: Workflows Practice:</p> <ul> <li>Ask for a plan.</li> <li>Make one small edit.</li> <li>Run one verification command.</li> <li>Review diffs.</li> </ul>"},{"location":"bootcamp/#module-4-verification-mindset-60-minutes","title":"Module 4: Verification mindset (60 minutes)","text":"<p>Read: Verification and Rigor Practice:</p> <ul> <li>Add one limiting-case check or synthetic-data test.</li> <li>Write down assumptions and units.</li> </ul>"},{"location":"bootcamp/#day-2-use-it-on-real-science","title":"Day 2: Use it on real science","text":""},{"location":"bootcamp/#module-5-a-literature-workflow-60-minutes","title":"Module 5: A literature workflow (60 minutes)","text":"<p>Read: Literature and Notes Practice:</p> <ul> <li>Pick 2-3 papers.</li> <li>Create structured notes.</li> <li>Build a comparison table (assumptions, failure modes).</li> </ul>"},{"location":"bootcamp/#module-6-a-reproducible-analysis-workflow-90-minutes","title":"Module 6: A reproducible analysis workflow (90 minutes)","text":"<p>Read: Data Analysis Practice:</p> <ul> <li>Convert one notebook or script into a pipeline.</li> <li>Add a config file.</li> <li>Make \"fresh clone -&gt; one command\" work.</li> </ul>"},{"location":"bootcamp/#module-7-figures-you-can-trust-60-minutes","title":"Module 7: Figures you can trust (60 minutes)","text":"<p>Read: Figures and Tables Practice:</p> <ul> <li>Add labels, units, and provenance.</li> <li>Add a lightweight sanity summary (counts, means, ranges).</li> </ul>"},{"location":"bootcamp/#module-8-cost-and-multi-model-usage-30-minutes","title":"Module 8: Cost and multi-model usage (30 minutes)","text":"<p>Read: - Cost Control - Multi-Model Strategy</p> <p>Goal:</p> <ul> <li>know when a second tool is worth paying for</li> <li>know how to avoid runaway usage</li> </ul>"},{"location":"bootcamp/#graduation-criteria","title":"Graduation criteria","text":"<p>You are \"agentic AI fluent\" when:</p> <ul> <li>you can define \"done\" as a command that passes</li> <li>you can read diffs and explain changes</li> <li>you can identify at least 3 ways an output could be wrong</li> <li>you have a reproducible workflow for one real project</li> </ul>"},{"location":"burner-machine/","title":"Burner Machine and Sandboxes","text":"<p>Do you need a \"burner machine\"?</p> <p>Usually: no. Sometimes: yes.</p> <p>This page is a practical way to think about risk.</p>"},{"location":"burner-machine/#what-people-mean-by-burner","title":"What people mean by \"burner\"","text":"<ul> <li>A dedicated laptop or desktop used for AI-assisted work</li> <li>A separate OS account</li> <li>A VM (virtual machine)</li> <li>A cloud dev environment</li> </ul> <p>The point is to reduce blast radius:</p> <ul> <li>fewer sensitive files accessible</li> <li>fewer saved credentials in browsers</li> <li>less risk if you mis-click \"yes\" on something</li> </ul>"},{"location":"burner-machine/#when-you-should-consider-it","title":"When you should consider it","text":"<ul> <li>You routinely handle sensitive human-subject or clinical data.</li> <li>You have export-controlled or proprietary data.</li> <li>Your institution has strict compliance requirements.</li> <li>You want to try agentic tools before you trust them.</li> </ul>"},{"location":"burner-machine/#lightweight-option-recommended-for-most","title":"Lightweight option (recommended for most)","text":"<ol> <li>Create a dedicated folder for AI-assisted projects.</li> <li>Use a separate browser profile for AI tools.</li> <li>Keep secrets out of repos.</li> <li>Work in copies of projects until you trust the workflow.</li> </ol>"},{"location":"burner-machine/#stronger-option-separate-os-user","title":"Stronger option: separate OS user","text":"<ul> <li>Create a new user account on your machine.</li> <li>Use it only for agentic AI work.</li> <li>Do not sign into personal email or password managers there.</li> </ul>"},{"location":"burner-machine/#strongest-option-vm-or-cloud-environment","title":"Strongest option: VM or cloud environment","text":"<ul> <li>Use a VM (or a cloud dev box) that contains only the project.</li> <li>Destroy and recreate when you are done.</li> </ul> <p>This is higher effort, but it is clean.</p>"},{"location":"burner-machine/#the-bigger-win-permissions-discipline","title":"The bigger win: permissions discipline","text":"<p>Even with a burner machine, you still need:</p> <ul> <li>diffs</li> <li>verification</li> <li>no secrets in prompts</li> </ul> <p>Burner setups reduce risk. They do not replace good habits.</p>"},{"location":"checklists/","title":"Checklists","text":"<p>These are the habits that make agentic AI safe and useful.</p>"},{"location":"checklists/#pre-flight-before-you-delegate","title":"Pre-flight (before you delegate)","text":"<ul> <li>Is the data allowed to be shared with this tool?</li> <li>Is the task small enough to review?</li> <li>Do you have a definition of done?</li> <li>Do you have a verification command or sanity check?</li> <li>Is the project under version control?</li> </ul>"},{"location":"checklists/#during-flight-while-the-agent-works","title":"During flight (while the agent works)","text":"<ul> <li>Ask for a plan before large edits.</li> <li>Keep changes in small steps.</li> <li>Require it to explain assumptions and units.</li> <li>Stop if you do not understand what changed.</li> </ul>"},{"location":"checklists/#post-flight-before-you-trust-results","title":"Post-flight (before you trust results)","text":"<ul> <li>Review diffs.</li> <li>Run tests / scripts.</li> <li>Check units, limiting cases, and basic invariants.</li> <li>Verify citations manually.</li> <li>Record how to reproduce the result.</li> </ul>"},{"location":"checklists/#red-flags","title":"Red flags","text":"<ul> <li>\"It should work\" without running anything</li> <li>new citations you did not provide</li> <li>big refactors without tests</li> <li>plots with missing units or unclear preprocessing</li> </ul>"},{"location":"claude-code/","title":"Claude Code (Recommended)","text":"<p>Claude Code is an agentic coding tool that runs in your terminal and can edit files, run commands, and iterate.</p>"},{"location":"claude-code/#what-you-need","title":"What you need","text":"<ul> <li>A Claude subscription (Pro/Max/Team/Enterprise) or a Claude Console account</li> </ul> <p>Notes:</p> <ul> <li>If you are just getting started, Pro is often enough.</li> <li>If you use it heavily (long sessions, large repos), you may need a higher tier.</li> <li>Pricing changes; verify here: https://www.anthropic.com/pricing</li> </ul> <p>Alternative if you already pay for ChatGPT</p> <ul> <li>If you already have a ChatGPT plan (Plus/Pro/Team/Edu/Enterprise), consider OpenAI Codex CLI as a Claude Code alternative. It is also a terminal-based coding agent and can be used by signing in with your ChatGPT account.</li> </ul> <p>Official docs: - Claude Code overview</p>"},{"location":"claude-code/#install","title":"Install","text":"<p>From the official instructions:</p> <p>macOS / Linux / WSL</p> <pre><code>curl -fsSL https://claude.ai/install.sh | bash\n</code></pre> <p>Windows PowerShell</p> <pre><code>irm https://claude.ai/install.ps1 | iex\n</code></pre> <p>Windows CMD</p> <pre><code>curl -fsSL https://claude.ai/install.cmd -o install.cmd &amp;&amp; install.cmd &amp;&amp; del install.cmd\n</code></pre> <p>Windows (WinGet)</p> <pre><code>winget install Anthropic.ClaudeCode\n</code></pre> <p>macOS (Homebrew)</p> <pre><code>brew install --cask claude-code\n</code></pre> <p>Then:</p> <pre><code>cd your-project\nclaude\n</code></pre> <p>If you're prompted to log in on first use, follow the browser flow.</p>"},{"location":"claude-code/#how-scientists-should-use-it-default-guardrails","title":"How scientists should use it (default guardrails)","text":"<ul> <li>Start with a throwaway repo or a copy of your project.</li> <li>Tell it to propose a plan before editing.</li> <li>Require it to run tests / a minimal validation script.</li> <li>Review diffs for every change.</li> </ul>"},{"location":"claude-code/#the-30-minute-starter-task","title":"The 30-minute starter task","text":"<p>Pick one:</p> <ul> <li>\"Add a <code>Makefile</code> (or <code>justfile</code>) that runs <code>pytest</code>, <code>ruff</code>, and a quick smoke test.\"</li> <li>\"Turn my one-off analysis script into a reproducible pipeline with a config file and pinned dependencies.\"</li> <li>\"Write a small CLI that loads my CSV and produces the exact plot I need for Figure 2.\"</li> </ul>"},{"location":"cli-basics/","title":"Terminal Basics (For Non-Developers)","text":"<p>You do not need to become a software engineer. But agentic tools often live in the terminal.</p> <p>If you do not know how to open a terminal, start here: Open a Terminal</p>"},{"location":"cli-basics/#three-commands-you-should-know","title":"Three commands you should know","text":"<pre><code>pwd   # where am I?\nls    # what files are here?\ncd .. # go up one folder\n</code></pre>"},{"location":"cli-basics/#paths","title":"Paths","text":"<ul> <li>A \"path\" is just a file location.</li> <li><code>.</code> means \"current folder\".</li> <li><code>..</code> means \"parent folder\".</li> </ul>"},{"location":"cli-basics/#a-safe-habit","title":"A safe habit","text":"<p>Before you run any command you do not recognize:</p> <ol> <li>ask the agent what it will do</li> <li>run it on a copy of the project first</li> </ol>"},{"location":"cli-basics/#common-research-commands","title":"Common research commands","text":"<pre><code>python3 script.py\npython3 -m venv .venv\nsource .venv/bin/activate\npip install -r requirements.txt\npytest\n</code></pre> <p>If those look unfamiliar, that is normal. You only need a small subset.</p>"},{"location":"coding/","title":"Coding and Refactors","text":"<p>Agentic AI is especially strong at:</p> <ul> <li>refactoring</li> <li>adding tests</li> <li>fixing errors</li> <li>wiring up CLIs</li> </ul>"},{"location":"coding/#your-job","title":"Your job","text":"<ul> <li>define what must not change (scientific assumptions)</li> <li>define what must improve (reproducibility, readability, speed)</li> <li>require verification</li> </ul>"},{"location":"coding/#a-safe-refactor-prompt","title":"A safe refactor prompt","text":"<pre><code>Refactor this project for readability and reproducibility.\n\nConstraints:\n- Do not change scientific logic without asking.\n- Keep outputs identical unless you explain why.\n\nDefinition of done:\n- `make test` passes\n- `make figures` regenerates the main figure(s)\n</code></pre>"},{"location":"coding/#when-to-stop","title":"When to stop","text":"<p>If you cannot explain what changed, you are moving too fast.</p>"},{"location":"context/","title":"Why This Guide Exists","text":"<p>This guide started from a YouTube video (https://www.youtube.com/watch?v=PctlBxRh0p4).</p> <p>We intentionally do not store the full transcript in this public repo.</p> <p>In that transcript, a scientist describes attending an internal meeting at the Institute for Advanced Study focused on how \"agentic AI\" tools (named examples: Claude and Cursor) are changing research work. Several themes show up repeatedly:</p> <ul> <li>The tools are now strong enough at coding (and often math/reasoning) to materially change day-to-day research workflows.</li> <li>Getting value requires AI fluency: learning how to define tasks, break problems down, and iterate.</li> <li>Human oversight is still necessary (diff review, cross-checks, validation), but the human role shifts toward \"manager / verifier.\"</li> <li>Privacy, ethics, and cost are real concerns; people will make different tradeoffs.</li> <li>Skill atrophy is a legitimate risk; you need deliberate habits to stay sharp.</li> </ul> <p>This guide tries to turn those themes into concrete, low-friction steps a working scientist can apply.</p>"},{"location":"cost-control/","title":"Cost Control (Avoid Surprises)","text":"<p>Costs can creep up, especially if you use multiple tools or run big jobs.</p>"},{"location":"cost-control/#the-two-main-cost-drivers","title":"The two main cost drivers","text":"<ol> <li>Volume: how many requests you make</li> <li>Size: how much context you feed each request (tokens)</li> </ol>"},{"location":"cost-control/#practical-ways-to-reduce-cost","title":"Practical ways to reduce cost","text":"<ul> <li>Keep tasks small and incremental.</li> <li>Reuse instructions instead of repeating long context.</li> <li>Provide small samples instead of full datasets.</li> <li>Ask for a plan before expensive execution.</li> </ul>"},{"location":"cost-control/#a-good-default-tier-your-work","title":"A good default: tier your work","text":"<ul> <li>Cheap model for drafting/refactors</li> <li>Strong model for final reasoning and tricky debugging</li> </ul>"},{"location":"cost-control/#institutional-budgeting","title":"Institutional budgeting","text":"<p>If your lab is paying:</p> <ul> <li>pick a single primary tool</li> <li>track usage monthly</li> <li>decide in advance when to approve upgrades</li> </ul> <p>See also: Pricing</p>"},{"location":"data-analysis/","title":"Data Analysis (AI-Assisted)","text":"<p>AI can help you write analysis code quickly. The risk is silent wrongness.</p>"},{"location":"data-analysis/#what-to-insist-on","title":"What to insist on","text":"<ul> <li>a minimal reproducible script</li> <li>a config file for parameters</li> <li>sanity checks on shapes, units, and ranges</li> <li>deterministic outputs (seeded randomness)</li> </ul>"},{"location":"data-analysis/#typical-wins","title":"Typical wins","text":"<ul> <li>cleaning up messy scripts</li> <li>turning notebooks into pipelines</li> <li>adding tests and validations</li> <li>speeding up plotting and reporting</li> </ul>"},{"location":"data-analysis/#typical-traps","title":"Typical traps","text":"<ul> <li>incorrect joins / merges</li> <li>wrong filtering</li> <li>subtle unit conversions</li> <li>plotting post-processed data without recording steps</li> </ul>"},{"location":"data-analysis/#a-practical-definition-of-done","title":"A practical definition of done","text":"<ul> <li>\"Fresh clone -&gt; install deps -&gt; run one command -&gt; produces figure/table\"</li> </ul>"},{"location":"disclosure/","title":"Disclosure and Attribution","text":"<p>Norms are evolving. Your field, journal, and institution may have specific policies.</p>"},{"location":"disclosure/#safe-default","title":"Safe default","text":"<ul> <li>Disclose meaningful AI assistance (especially if it generated text, code, or figures).</li> <li>Do not list an AI system as an author.</li> <li>Do not allow AI to invent citations; verify every reference.</li> </ul>"},{"location":"disclosure/#suggested-disclosure-language-adapt","title":"Suggested disclosure language (adapt)","text":"<pre><code>We used AI-assisted tools to help with code refactoring and/or drafting text. All scientific claims, analyses, and final wording were reviewed and verified by the authors.\n</code></pre> <p>If a journal has a specific required statement, use theirs.</p>"},{"location":"faq/","title":"FAQ","text":""},{"location":"faq/#is-this-going-to-replace-scientists","title":"Is this going to replace scientists?","text":"<p>No one knows. But it is already changing the day-to-day work.</p> <p>The most robust stance is: learn to use it, keep your verification habits strong, and keep your scientific judgment sharp.</p>"},{"location":"faq/#will-i-lose-my-skills","title":"Will I lose my skills?","text":"<p>Skill atrophy is real if you stop thinking.</p> <p>Mitigations:</p> <ul> <li>keep doing some work \"by hand\" (derivations, small scripts)</li> <li>require the agent to explain reasoning</li> <li>use it to teach you, not just to produce output</li> </ul>"},{"location":"faq/#can-i-trust-citations","title":"Can I trust citations?","text":"<p>Not by default.</p> <p>If you did not provide sources, assume citations may be invented.</p>"},{"location":"figures/","title":"Figures and Tables","text":"<p>Figures are where incorrect code becomes persuasive.</p>"},{"location":"figures/#the-standard","title":"The standard","text":"<ul> <li>One command regenerates figures.</li> <li>Every figure has a clear source script.</li> <li>Inputs and parameters are recorded.</li> </ul>"},{"location":"figures/#a-useful-pattern","title":"A useful pattern","text":"<ul> <li><code>scripts/make_fig_2.py</code></li> <li><code>configs/fig_2.yaml</code></li> <li><code>results/fig_2.png</code></li> </ul>"},{"location":"figures/#verification-checks","title":"Verification checks","text":"<ul> <li>plot a small random subsample to ensure it behaves</li> <li>include axis labels and units</li> <li>store intermediate summaries (counts, means) for sanity</li> </ul>"},{"location":"first-hour/","title":"First Hour: A Safe, Useful Win","text":"<p>Goal: get one small, real task done with an agentic tool, while keeping risk low.</p>"},{"location":"first-hour/#setup","title":"Setup","text":"<ul> <li>Use a non-sensitive project (or a copy).</li> <li>Make sure it's under version control.</li> </ul>"},{"location":"first-hour/#pick-one-task-30-60-minutes","title":"Pick one task (30-60 minutes)","text":"<ol> <li>\"Add a <code>README.md</code> that explains setup + a one-command run.\"</li> <li>\"Add a minimal test that checks the main function runs on a tiny sample.\"</li> <li>\"Make a <code>Makefile</code> (or <code>justfile</code>) with <code>make format</code>, <code>make test</code>, <code>make run</code>.\"</li> </ol>"},{"location":"first-hour/#the-prompt","title":"The prompt","text":"<pre><code>Act like a careful research software engineer.\n\nBefore editing anything:\n- summarize what you think this project does\n- propose a short plan\n\nRules:\n- keep changes small and reviewable\n- run a quick verification step\n- explain how to undo changes\n\nTask:\n&lt;paste the task you chose&gt;\n</code></pre>"},{"location":"first-hour/#what-success-looks-like","title":"What \"success\" looks like","text":"<ul> <li>You can point to a diff and say what changed.</li> <li>You can run one command and see it work.</li> <li>You didn't paste any sensitive data.</li> </ul>"},{"location":"git-basics/","title":"Git Basics (So You Can Review and Undo)","text":"<p>Git is the safety harness for agentic AI.</p>"},{"location":"git-basics/#the-mental-model","title":"The mental model","text":"<ul> <li>A repo is a folder where git tracks changes.</li> <li>A commit is a snapshot.</li> <li>A diff shows what changed.</li> </ul>"},{"location":"git-basics/#minimal-commands","title":"Minimal commands","text":"<pre><code>git status\ngit diff\ngit add -A\ngit commit -m \"message\"\n</code></pre>"},{"location":"git-basics/#why-scientists-should-care","title":"Why scientists should care","text":"<ul> <li>You can always see what changed.</li> <li>You can undo mistakes.</li> <li>You can reproduce exactly what produced a figure.</li> </ul>"},{"location":"git-basics/#recommended-workflow","title":"Recommended workflow","text":"<ul> <li>Make small commits.</li> <li>Keep analysis outputs out of the repo unless needed.</li> <li>Use branches for experiments.</li> </ul>"},{"location":"how-it-works/","title":"How Agentic AI Works (Mental Model)","text":"<p>You do not need deep ML knowledge. But you do need a usable mental model.</p>"},{"location":"how-it-works/#chat-model-vs-agent","title":"Chat model vs agent","text":"<ul> <li>Chat model: generates text.</li> <li>Agent: uses a chat model plus tools (file edits, commands, web, etc.) to do multi-step work.</li> </ul>"},{"location":"how-it-works/#the-agent-loop","title":"The agent loop","text":"<p>Most agentic systems follow a loop like:</p> <ol> <li>Read context (files, your instructions)</li> <li>Plan</li> <li>Take an action (edit file, run command)</li> <li>Observe the result (diffs, errors, output)</li> <li>Iterate until \"done\"</li> </ol>"},{"location":"how-it-works/#why-errors-happen","title":"Why errors happen","text":"<p>Common causes:</p> <ul> <li>Missing context (the agent did not see the relevant file)</li> <li>Ambiguous goal (no definition of done)</li> <li>Overconfident guesses (hallucinations)</li> <li>Hidden assumptions (units, conventions)</li> </ul>"},{"location":"how-it-works/#context-window-and-tokens","title":"Context window and tokens","text":"<ul> <li>Models do not see your whole computer.</li> <li>They only see what is placed in their context.</li> <li>Longer context generally costs more and can be noisier.</li> </ul>"},{"location":"how-it-works/#what-makes-agentic-ai-powerful","title":"What makes agentic AI powerful","text":"<ul> <li>It can try something, see it fail, and fix it.</li> <li>It can make consistent changes across many files.</li> <li>It can automate repetitive steps.</li> </ul>"},{"location":"how-it-works/#what-makes-it-dangerous","title":"What makes it dangerous","text":"<ul> <li>It can change many files quickly.</li> <li>It can produce outputs that look right.</li> <li>It can run commands you did not understand.</li> </ul> <p>Your control points are: scope, diffs, and verification.</p>"},{"location":"install-order/","title":"Installation Order (Recommended)","text":"<p>There are many tools. Installing everything at once creates confusion.</p>"},{"location":"install-order/#recommended-order","title":"Recommended order","text":"<ol> <li>Start with one chat tool you already use.</li> <li>Use it for planning, explanations, and writing.</li> <li>Add one agentic tool that can edit files and run commands.</li> <li>Recommended: Claude Code.</li> <li>If you already pay for ChatGPT, consider OpenAI Codex CLI: https://github.com/openai/codex</li> <li>Only then add an IDE-based agent (optional).</li> <li>Example: Cursor or Copilot in your IDE.</li> <li>Add multi-model workflows only after you have verification habits.</li> </ol>"},{"location":"install-order/#why-this-order-works","title":"Why this order works","text":"<ul> <li>Most failures come from weak workflow and verification, not from \"the wrong model\".</li> <li>Agentic tools amplify your habits.</li> </ul>"},{"location":"install-order/#minimum-setup-for-a-scientist","title":"Minimum setup for a scientist","text":"<ul> <li>A repo (git)</li> <li>A virtual environment</li> <li>A one-command run</li> <li>A sanity check</li> </ul> <p>See: Setup Checklist</p>"},{"location":"install-order/#installing-claude-code","title":"Installing Claude Code","text":"<p>See: Claude Code</p>"},{"location":"lab-policy-template/","title":"Lab Policy Template (Fill In)","text":"<p>This is a starting point. Adapt it to your institution and field.</p>"},{"location":"lab-policy-template/#purpose","title":"Purpose","text":"<p>We use AI tools to improve productivity while maintaining scientific integrity, privacy, and reproducibility.</p>"},{"location":"lab-policy-template/#allowed-tools","title":"Allowed tools","text":"<ul> <li>Primary tool(s): ______</li> <li>Secondary tool(s): ____</li> </ul>"},{"location":"lab-policy-template/#data-rules","title":"Data rules","text":"<p>Never share:</p> <ul> <li>credentials / API keys</li> <li>patient data / human-subject raw data</li> <li>embargoed collaborator material</li> </ul> <p>Allowed to share:</p> <ul> <li>public papers</li> <li>public code</li> <li>synthetic data</li> <li>small anonymized examples (if permitted)</li> </ul>"},{"location":"lab-policy-template/#verification-rules","title":"Verification rules","text":"<ul> <li>Any AI-generated code must be reviewed via diff.</li> <li>Any analysis must have a reproducible run command.</li> <li>Any citations must be verified.</li> </ul>"},{"location":"lab-policy-template/#disclosure","title":"Disclosure","text":"<p>We disclose meaningful AI assistance in manuscripts and proposals according to venue requirements.</p>"},{"location":"lab-policy-template/#storage-and-logging","title":"Storage and logging","text":"<ul> <li>Store prompts and outputs for important analyses: yes/no</li> <li>Store the exact commands used to generate figures: yes/no</li> </ul>"},{"location":"lab-policy-template/#contact","title":"Contact","text":"<p>If unsure, ask: ______</p>"},{"location":"lab-rollout/","title":"Lab Rollout Playbook","text":"<p>This is a lightweight way to adopt agentic AI tools without creating chaos.</p>"},{"location":"lab-rollout/#1-decide-what-is-allowed","title":"1) Decide what is allowed","text":"<ul> <li>Allowed: public papers, public code, synthetic data, toy examples</li> <li>Caution: unpublished results, collaborator material, embargoed data</li> <li>Usually not allowed without explicit approval: human-subject data, patient data, credentials, proprietary industry data</li> </ul> <p>Write the decision down (one page) and make it easy to follow.</p>"},{"location":"lab-rollout/#2-standardize-the-workflow","title":"2) Standardize the workflow","text":"<ul> <li>Use repos for analysis (even if small).</li> <li>Require diffs and \"verification commands\" for code changes.</li> <li>Prefer small PRs / small changes.</li> </ul>"},{"location":"lab-rollout/#3-standardize-prompts-seriously","title":"3) Standardize prompts (seriously)","text":"<p>Put a few prompt templates in a shared doc and encourage people to reuse them. See: Prompt Templates.</p>"},{"location":"lab-rollout/#4-track-what-the-tool-did","title":"4) Track what the tool did","text":"<ul> <li>For analysis: record parameters, versions, seeds, and data hashes.</li> <li>For writing: record which sections were AI-assisted and how you validated claims.</li> </ul>"},{"location":"lab-rollout/#5-teach-verification-thinking","title":"5) Teach \"verification thinking\"","text":"<ul> <li>Always ask: \"What would prove this wrong?\"</li> <li>Build tiny checks: limiting cases, invariants, synthetic datasets.</li> </ul>"},{"location":"latex/","title":"LaTeX and Math with Agentic AI","text":"<p>Agentic AI tools can help a lot with LaTeX: drafting sections, formatting equations, cleaning up tables, and converting sketches into typeset math.</p> <p>The key idea: models can read and write raw <code>.tex</code> files directly, and many \"harnesses\" can also accept images (screenshots, PDFs, whiteboard photos).</p>"},{"location":"latex/#what-ai-is-good-at","title":"What AI is good at","text":"<ul> <li>Converting plain English into LaTeX prose</li> <li>Converting equations in text form into LaTeX math</li> <li>Cleaning up LaTeX formatting (environments, alignment, tables)</li> <li>Refactoring a messy preamble and macros (carefully)</li> <li>Turning rough notes into a clean derivation outline</li> </ul>"},{"location":"latex/#what-ai-is-risky-at","title":"What AI is risky at","text":"<ul> <li>Inventing steps in a derivation</li> <li>\"Fixing\" equations incorrectly while making them look nicer</li> <li>Producing plausible but wrong notation</li> <li>Adding citations or claims without sources</li> </ul> <p>Your defense is the usual loop: diff + compile + sanity checks.</p>"},{"location":"latex/#working-with-raw-latex","title":"Working with raw LaTeX","text":"<p>You can paste LaTeX directly into the agent or point it at a <code>.tex</code> file.</p> <p>Good tasks:</p> <ul> <li>\"Rewrite this paragraph for clarity but keep the math and meaning unchanged.\"</li> <li>\"Turn this inline equation into a properly aligned display equation.\"</li> <li>\"Make this table readable and consistent with the paper style.\"</li> </ul>"},{"location":"latex/#image-latex-whiteboard-screenshots-pdfs","title":"Image -&gt; LaTeX (whiteboard, screenshots, PDFs)","text":"<p>Many AI interfaces can accept images.</p> <p>Practical workflow:</p> <ol> <li>Write an equation on a whiteboard (or notebook).</li> <li>Take a photo.</li> <li>Give the image to the tool (or save it into your project folder).</li> <li>Ask the agent to convert it into LaTeX.</li> </ol> <p>Notes:</p> <ul> <li>If the tool cannot accept images directly, you can often still do this by saving the image and giving the agent the file path.</li> <li>Always verify the result. OCR + math parsing is good, but not perfect.</li> </ul>"},{"location":"latex/#a-minimal-compile-loop","title":"A minimal compile loop","text":"<p>If you have a local TeX install:</p> <pre><code>latexmk -pdf main.tex\n</code></pre> <p>If you do not, consider Overleaf as the simplest path.</p>"},{"location":"latex/#prompt-templates","title":"Prompt templates","text":""},{"location":"latex/#1-convert-a-whiteboard-equation-to-latex-with-verification","title":"1) Convert a whiteboard equation to LaTeX (with verification)","text":"<pre><code>I am going to provide an image of a handwritten equation.\n\nTask:\n- Convert the equation into LaTeX.\n- If any symbols are ambiguous, list the ambiguity and provide 2-3 possible interpretations.\n- Output both:\n  1) a standalone LaTeX equation\n  2) the same equation inside an `align` environment\n\nRules:\n- Do not \"fix\" the math.\n- Preserve the structure as written.\n</code></pre>"},{"location":"latex/#2-clean-up-a-derivation-without-changing-meaning","title":"2) Clean up a derivation without changing meaning","text":"<pre><code>I will provide a LaTeX snippet.\n\nGoal:\n- Improve readability and formatting.\n\nConstraints:\n- Do not change the meaning.\n- Do not change variable names unless you ask.\n\nDefinition of done:\n- It compiles.\n- The math is structurally identical.\n</code></pre>"},{"location":"latex/#3-turn-rough-notes-into-a-paper-ready-subsection","title":"3) Turn rough notes into a paper-ready subsection","text":"<pre><code>Turn these rough notes into a LaTeX subsection.\n\nConstraints:\n- Do not add citations.\n- Do not invent results.\n- If a claim is not supported by what I provided, mark it as \"needs source\".\n\nDeliverable:\n- LaTeX text using standard environments (equation/align, itemize).\n</code></pre>"},{"location":"latex/#recommended-habits","title":"Recommended habits","text":"<ul> <li>Keep equations close to the code that generated results (where applicable).</li> <li>Use consistent notation; ask the agent to build a notation table.</li> <li>Compile frequently.</li> <li>When the math is important, cross-check with a second method (manual check, symbolic tool, or a second model).</li> </ul>"},{"location":"literature/","title":"Literature and Notes","text":"<p>This is an area where AI can help a lot, but it is also where it hallucinates the most.</p>"},{"location":"literature/#safe-approach","title":"Safe approach","text":"<ul> <li>Use AI to summarize papers you provide.</li> <li>Use AI to generate questions, hypotheses, and comparisons.</li> <li>Do not trust it to \"know\" the literature without sources.</li> </ul>"},{"location":"literature/#good-tasks","title":"Good tasks","text":"<ul> <li>\"Summarize this paper in 10 bullets, then list 10 weaknesses.\"</li> <li>\"Compare these two methods and tell me when each fails.\"</li> <li>\"Extract all datasets, hyperparameters, and evaluation metrics.\"</li> </ul>"},{"location":"literature/#bad-tasks-unless-you-verify","title":"Bad tasks (unless you verify)","text":"<ul> <li>\"Give me citations for X\"</li> <li>\"What is the state of the art in Y\" (without forcing sources)</li> </ul>"},{"location":"literature/#a-workflow-that-works","title":"A workflow that works","text":"<ol> <li>Put PDFs in a folder.</li> <li>Ask the agent to create structured notes per paper.</li> <li>Ask for a synthesis across papers, explicitly citing which paper supports which claim.</li> </ol>"},{"location":"literature/#output-format-suggestion","title":"Output format suggestion","text":"<ul> <li>One note per paper</li> <li>One synthesis note per topic</li> <li>A table of methods vs assumptions vs failure modes</li> </ul>"},{"location":"mcp/","title":"MCP and Connectors (Advanced)","text":"<p>MCP (Model Context Protocol) is a way for agentic tools to use external tools and data sources.</p> <p>Examples of what connectors can enable:</p> <ul> <li>read Google Drive docs</li> <li>pull issues from Jira/GitHub</li> <li>use internal datasets or search indexes</li> </ul>"},{"location":"mcp/#why-scientists-should-care","title":"Why scientists should care","text":"<p>The biggest productivity wins often come from connecting the agent to your actual working context:</p> <ul> <li>lab docs</li> <li>protocols</li> <li>shared notes</li> <li>code repos</li> </ul>"},{"location":"mcp/#the-risk","title":"The risk","text":"<p>More access increases blast radius.</p> <p>Rules of thumb:</p> <ul> <li>start with read-only</li> <li>avoid connecting anything sensitive until you understand the permissions</li> <li>log what the agent did</li> </ul> <p>If your institution has policies, follow them.</p>"},{"location":"multi-model/","title":"Multi-Model Strategy (When and Why)","text":"<p>Some power users run the same problem through multiple systems (for example: Claude, Cursor, ChatGPT).</p> <p>This can improve reliability, but it can also waste time and money.</p>"},{"location":"multi-model/#when-it-is-worth-it","title":"When it is worth it","text":"<ul> <li>High-stakes correctness (math derivations, key results)</li> <li>Critical code paths</li> <li>You suspect hallucinations</li> <li>You want a second opinion on design decisions</li> </ul>"},{"location":"multi-model/#when-it-is-not-worth-it","title":"When it is not worth it","text":"<ul> <li>Routine refactors</li> <li>Simple scripts with good tests</li> <li>Tasks where you can quickly verify by running code</li> </ul>"},{"location":"multi-model/#the-best-cross-check-is-still-a-test","title":"The best cross-check is still a test","text":"<p>Two models agreeing is not proof.</p> <p>Best practice:</p> <ul> <li>define a verification command</li> <li>build a small test</li> <li>use a second model for critique, not as a replacement for testing</li> </ul>"},{"location":"multi-model/#subscription-stacking-common-patterns","title":"Subscription stacking (common patterns)","text":"<p>Typical combinations people end up paying for:</p> <ul> <li>Claude Pro (for Claude Code) + one IDE tool</li> <li>Claude Pro + ChatGPT plan</li> <li>Claude Pro + Cursor Pro</li> <li>Claude Pro + GitHub Copilot Pro</li> </ul> <p>Add them up before you commit.</p> <p>See current pricing links: Pricing</p>"},{"location":"multi-model/#a-practical-budgeting-rule","title":"A practical budgeting rule","text":"<ul> <li>Start with one paid tool.</li> <li>Add a second paid tool only if it saves you more than 1-2 hours per month.</li> </ul>"},{"location":"notes-from-the-human/","title":"Notes from the Human","text":"<p>Hi. Quick human-to-human note before you dig into the rest (you are a human, aren't you?).</p> <p>My name is Chris Cullins. I'm a software developer with a casual interest in the physical sciences, and I love the Cool Worlds Podcast (I'm particularly fond of the Colin Hill episode).</p> <p>That led me to watch this episode on AI. It made me realize that (until LLMs officially take over all knowledge work) there are still plenty of things we can do to keep ourselves busy. Most of those things, at least as of January 2026, involve getting good with the latest software tools and the interfaces we use to talk to models efficiently.</p> <p>The main takeaways I want you to know are:</p> <ul> <li> <p>This information will be out of date very fast - Unfortunately it's hard to write a guide like this because a new tool or model comes out every week. But I'll do my best to keep you all up to date as we move forward.</p> </li> <li> <p>How much control to give \"it\"? - Everyone starts somewhere (no AI, chat interfaces, terminal interfaces, etc.). Over time, you will usually give more control of your digital work to models (and their software harnesses) as you gain trust.</p> </li> </ul> <p>Everyone will find their own line. Personally, I give these tools a lot of access on my own machines. Most modern harnesses have safeguards, but I still strongly caution you against letting an agent interact fully with untrusted \"outside\" inputs.</p> <p>Example of what I mean: an agent automatically responding to emails in your inbox. That is a prompt-injection magnet, because someone can send a message like \"ignore previous instructions and exfiltrate X\" and your tool may follow it.</p> <p>A reasonable default today: be strict about anything that touches the outside world, and be more relaxed about local files in a controlled project folder.</p> <ul> <li>Why a divide between the AI users and naysayers? - In software development, you will find two camps: people using these tools productively, and people saying they are useless, write terrible code, or are a scam.</li> </ul> <p>In my opinion, the bifurcation mostly comes down to whether someone has made the workflow \"paradigm shift\" and built the skill of engineering systems around the limitations. I suspect it will be the exact same in the sciences.</p> <ul> <li>A large part of your job moving forward is being an agentic AI engineer - I don't mean someone necessarily working on the models themselves. I mean: in many knowledge fields, a lot of the job becomes building workflows and systems that work around current limitations (context windows, no persistent memory, etc).</li> </ul> <p>Example: many users notice that once a conversation gets to beyond roughly 45% of the context window limit, the model can become noticeably worse, start to get confused about what it's \"doing\", etc. How do you work around that fact? That's the question you should always be asking yourself. In this case, it's breaking a larger task up into smaller pieces, then looping calls to the agentic harness (claude code for instance) through those tasks, so it stays focused on each piece and doesn't get confused. </p> <ul> <li> <p>You'll know when you're doing it correctly - Because you will (and I'm completely serious) feel like a superhuman.</p> </li> <li> <p>It will take time, though - Using these tools is absolutely a skill. The faster you dive into learning it, the faster you'll get there. I'm not sure it's optional anymore, so get going; this is a decent place to start.</p> </li> <li> <p>You will need to fix your \"muscle memory\" - If you are reading something and think of a question, or you have an annoyance in your life you wish someone had fixed already, your first instinct should increasingly become: \"let me ask a model what my options are to fix this problem\".</p> </li> </ul> <p>It can feel unnatural at first (or even a bit slimy), but it will often get you to a solution much faster. In many cases, you will start solving problems you would not have bothered with before, because the ROI is so much better when the upfront effort drops close to zero.</p>"},{"location":"notes-from-the-human/#where-to-go-next","title":"Where to go next","text":"<ul> <li>Start reading: What This Guide Is</li> <li>Do the practical ramp: Bootcamp (2 Days)</li> <li>If you are very new to terminals: Open a Terminal</li> </ul>"},{"location":"oh-i-get-it/","title":"Oh I Get It (Guided Tour)","text":"<p>This is a deliberately \"aha\"-style experience.</p> <p>You will use an agentic tool (Claude Code) to download this guide onto your computer, then have the agent walk you through it interactively.</p>"},{"location":"oh-i-get-it/#what-you-will-do","title":"What you will do","text":"<ol> <li>Install Claude Code</li> <li>Start Claude Code in a fresh folder</li> <li>Paste a single prompt</li> <li>Let the agent:</li> <li>download the guide (from GitHub)</li> <li>open the docs locally</li> <li>propose a fast learning path</li> <li>answer questions as you go</li> </ol>"},{"location":"oh-i-get-it/#safety-note","title":"Safety note","text":"<p>The prompt below asks the agent to run shell commands (<code>curl</code>, <code>tar</code>, etc.).</p> <p>If you do not recognize a command, ask it to explain before you approve it.</p>"},{"location":"oh-i-get-it/#step-1-install-claude-code","title":"Step 1: Install Claude Code","text":"<p>See: Claude Code</p> <p>If you already pay for ChatGPT, you can do a very similar experience with OpenAI Codex CLI. This page uses Claude Code as the default path.</p>"},{"location":"oh-i-get-it/#step-2-start-claude-code","title":"Step 2: Start Claude Code","text":"<p>Open a terminal: Open a Terminal</p> <p>Then run:</p> <pre><code>mkdir -p ~/agentic-ai-guide-tour\ncd ~/agentic-ai-guide-tour\nclaude\n</code></pre>"},{"location":"oh-i-get-it/#step-3-paste-this-prompt-into-claude-code","title":"Step 3: Paste this prompt into Claude Code","text":"<p>Replace nothing; just paste.</p> <pre><code>I want an interactive walkthrough of the \"Science + Agentic AI Guide\".\n\nPlease do the following carefully:\n\n0) First, propose a short plan and list the exact commands you intend to run.\n1) Create a new subfolder called `science-ai-guide` inside the current directory.\n2) Download the latest guide content from GitHub into that folder (no git required).\n   - Use the repository tarball: https://github.com/Chris-Cullins/science-ai-guide/archive/refs/heads/main.tar.gz\n   - Use curl and tar.\n   - Extract it so that `science-ai-guide/docs/` exists and contains the Markdown files.\n3) After download, open and read:\n   - `science-ai-guide/docs/index.md`\n   - `science-ai-guide/docs/notes-from-the-human.md`\n4) Give me a 10-minute \"orientation\" of how this guide is structured and what to read first.\n5) Ask me 3 questions to personalize a learning path (my OS, how technical I am, what I want to use this for).\n6) Based on my answers, give me a short plan for the next 60 minutes.\n\nRules:\n- Keep it beginner-friendly.\n- Do not ask me to do complex setup unless it is necessary.\n- When you recommend running a command, explain what it does in one sentence.\n</code></pre>"},{"location":"oh-i-get-it/#if-you-are-on-windows","title":"If you are on Windows","text":"<p>Claude Code can run in Windows shells. If the <code>tar</code> command is not available, ask the agent to use a zip download + PowerShell <code>Expand-Archive</code> instead.</p>"},{"location":"oh-i-get-it/#what-success-looks-like","title":"What success looks like","text":"<ul> <li>You have a local copy of the guide in <code>~/agentic-ai-guide-tour/science-ai-guide/</code></li> <li>You understand the \"plan -&gt; do -&gt; verify\" loop</li> <li>You have one small task you can delegate safely today</li> </ul>"},{"location":"open-terminal/","title":"Open a Terminal (macOS, Windows, Linux)","text":"<p>Agentic tools like Claude Code run in a terminal.</p> <p>If you have never used one, that's normal. This page gets you to a working prompt.</p>"},{"location":"open-terminal/#macos","title":"macOS","text":"<p>Built-in Terminal (fastest)</p> <ol> <li>Press Command + Space (Spotlight Search)</li> <li>Type: Terminal</li> <li>Press Enter</li> </ol> <p>Alternative terminals (optional)</p> <ul> <li>Ghostty: https://ghostty.org/</li> <li>iTerm2: https://iterm2.com/</li> </ul> <p>Any of these work. Pick one and stick with it.</p>"},{"location":"open-terminal/#windows","title":"Windows","text":"<p>Windows Terminal (recommended)</p> <ol> <li>Press the Windows key</li> <li>Type: Windows Terminal</li> <li>Press Enter</li> </ol> <p>Then choose one shell:</p> <ul> <li>PowerShell (common default)</li> <li>Command Prompt (cmd)</li> </ul> <p>If you need Linux-style tooling</p> <ul> <li>Install WSL (Windows Subsystem for Linux) and use an Ubuntu shell inside Windows Terminal.</li> </ul>"},{"location":"open-terminal/#linux","title":"Linux","text":"<p>Most desktop Linux distributions include a terminal.</p> <p>Common ways to open it:</p> <ul> <li>Press Ctrl + Alt + T (works on many distros)</li> <li>Use the application launcher and search for: Terminal</li> </ul>"},{"location":"open-terminal/#a-quick-sanity-check","title":"A quick sanity check","text":"<p>Once the terminal opens, type:</p> <pre><code>pwd\n</code></pre> <p>If it prints a folder path, you are good.</p> <p>Next: Terminal Basics</p>"},{"location":"overview/","title":"What This Guide Is","text":"<p>This is a practical guide for scientists adopting agentic AI tools.</p> <p>It assumes:</p> <ul> <li>You write some code (often Python/R/Matlab) but you are not a professional software engineer.</li> <li>You care about correctness, reproducibility, and not embarrassing yourself in a paper.</li> <li>You want a workflow that is faster, not just \"cool\".</li> </ul>"},{"location":"overview/#the-promise","title":"The promise","text":"<p>Agentic AI can:</p> <ul> <li>turn vague goals into concrete code changes</li> <li>automate the boring parts (setup, refactors, glue code)</li> <li>accelerate debugging</li> <li>help you explore literature and write more clearly</li> </ul>"},{"location":"overview/#the-catch","title":"The catch","text":"<p>Agentic AI also:</p> <ul> <li>makes mistakes confidently</li> <li>can create plausible but wrong plots, stats, or citations</li> <li>can leak data if you paste sensitive content</li> <li>can change many files quickly (reproducibility risk)</li> </ul> <p>The goal of this guide is to help you get the upside without eating the downside.</p>"},{"location":"overview/#a-simple-rule","title":"A simple rule","text":"<p>If the agent can take actions, you must:</p> <ol> <li>review diffs</li> <li>run verification</li> <li>keep a reproducible record</li> </ol>"},{"location":"overview/#glossary-quick","title":"Glossary (quick)","text":"<ul> <li>Agentic AI: an AI system that can take actions (edit files, run commands, call tools).</li> <li>Diff: a view of what changed in files.</li> <li>Repo: a project folder tracked by git (version control).</li> <li>Context window: how much information the model can consider at once.</li> <li>Tokens: the model's \"units\" of text; cost is often per token.</li> </ul>"},{"location":"pricing/","title":"Pricing (Double-Check Before Publishing)","text":"<p>Pricing changes frequently. This page is a snapshot of publicly listed pricing as of 2026-02-01.</p>"},{"location":"pricing/#claude-subscriptions-includes-claude-code","title":"Claude subscriptions (includes Claude Code)","text":"<p>From Anthropic's pricing page (Individual plans):</p> <ul> <li>Free: $0</li> <li>Pro: $17/month with annual discount ($200 billed up front) or $20 billed monthly; includes access to Claude Code</li> <li>Max: from $100/month</li> </ul> <p>Source: https://www.anthropic.com/pricing</p>"},{"location":"pricing/#claude-api-pricing-if-you-build-custom-tools","title":"Claude API pricing (if you build custom tools)","text":"<p>From Anthropic's pricing page (API):</p> <ul> <li>Opus 4.5: $5/MTok input, $25/MTok output</li> <li>Sonnet 4.5: $3/MTok input and $15/MTok output for prompts &lt;= 200K tokens (higher prices for &gt;200K)</li> <li>Haiku 4.5: $1/MTok input, $5/MTok output</li> </ul> <p>Tools pricing shown there also includes (examples):</p> <ul> <li>Web search: $10 / 1K searches (not including tokens)</li> <li>Code execution: $0.05 per hour per container (after free daily hours per org)</li> </ul> <p>Source: https://www.anthropic.com/pricing</p>"},{"location":"pricing/#alternatives-for-comparison","title":"Alternatives (for comparison)","text":"<ul> <li> <p>Cursor: Free tier; Pro $20/month; Pro+ $60/month; Ultra $200/month   Source: https://cursor.com/pricing</p> </li> <li> <p>GitHub Copilot (individual): Free; Pro $10/month; Pro+ $39/month   Source: https://github.com/features/copilot/plans</p> </li> <li> <p>ChatGPT plans are listed at: https://openai.com/pricing</p> </li> </ul>"},{"location":"pricing/#what-people-actually-end-up-paying-examples","title":"What people actually end up paying (examples)","text":"<p>These are example monthly totals based on the subscription prices listed above. Pricing changes often; verify before publishing.</p> <p>Starter (single tool)</p> <ul> <li>Claude Pro ($20/month billed monthly)</li> </ul> <p>Common \"two-tool\" stacks</p> <ul> <li>Claude Pro ($20) + GitHub Copilot Pro ($10) = $30/month</li> <li>Claude Pro ($20) + Cursor Pro ($20) = $40/month</li> </ul> <p>Heavy use</p> <ul> <li>Claude Pro ($20) + Cursor Pro+ ($60) = $80/month</li> </ul> <p>If you also add a ChatGPT plan, include that amount in your budget.</p>"},{"location":"pricing/#cost-control-tips","title":"Cost control tips","text":"<ul> <li>Prefer smaller tasks and incremental diffs (reduces rework).</li> <li>Save reusable instructions in a project-level \"rules\" file (reduces repeated context).</li> <li>Don't upload giant datasets when a small sample + schema is enough.</li> </ul>"},{"location":"project-structure/","title":"Project Structure That Works With Agents","text":"<p>Most pain comes from messy structure. Fixing structure pays off.</p>"},{"location":"project-structure/#a-simple-layout","title":"A simple layout","text":"<p>This works for many labs:</p> <pre><code>project/\n  README.md\n  pyproject.toml (or requirements.txt)\n  data/            # raw or external data references\n  src/             # code\n  notebooks/       # exploratory work\n  scripts/         # entry points\n  results/         # generated outputs (often gitignored)\n  configs/         # parameter sets for runs\n  tests/           # sanity checks\n</code></pre>"},{"location":"project-structure/#one-command-runs","title":"One-command runs","text":"<p>Pick a canonical command, for example:</p> <ul> <li><code>make figures</code></li> <li><code>make test</code></li> <li><code>python -m yourpackage.run --config configs/paper.yaml</code></li> </ul> <p>Agents are much more reliable when \"done\" is defined as \"this command passes\".</p>"},{"location":"prompting/","title":"Prompting Patterns (That Actually Work)","text":"<p>Good prompting is not poetry. It is specifications.</p>"},{"location":"prompting/#the-5-things-to-include","title":"The 5 things to include","text":"<ol> <li>Goal: what you want</li> <li>Context: what the agent should look at</li> <li>Constraints: what it must not do</li> <li>Definition of done: how you will verify</li> <li>Output format: what artifacts you want</li> </ol>"},{"location":"prompting/#a-default-template","title":"A default template","text":"<pre><code>You are helping me with a scientific project.\n\nGoal:\n- &lt;what you want&gt;\n\nContext:\n- &lt;where to look, what files exist&gt;\n\nConstraints:\n- Do not change scientific assumptions without asking.\n- Do not invent citations or factual claims.\n- Keep changes small and reviewable.\n\nDefinition of done:\n- &lt;tests / commands / checks that must pass&gt;\n\nDeliverables:\n- &lt;files or outputs&gt;\n</code></pre>"},{"location":"prompting/#high-leverage-patterns","title":"High-leverage patterns","text":""},{"location":"prompting/#ask-for-a-plan-first","title":"Ask for a plan first","text":"<p>\"Propose a plan before editing files.\" reduces thrash.</p>"},{"location":"prompting/#force-the-agent-to-be-explicit-about-assumptions","title":"Force the agent to be explicit about assumptions","text":"<p>\"List assumptions and units.\" catches many scientific errors early.</p>"},{"location":"prompting/#add-an-adversarial-check","title":"Add an adversarial check","text":"<p>\"Tell me how this could be wrong.\" makes verification easier.</p>"},{"location":"prompting/#common-failure-patterns","title":"Common failure patterns","text":"<ul> <li>Vague tasks: \"make this better\"</li> <li>No definition of done</li> <li>No tests or sanity checks</li> <li>Asking for citations without giving sources</li> </ul>"},{"location":"prompts/","title":"Prompt Templates for Scientists","text":"<p>These are designed to be copy/pasted into an agentic tool like Claude Code.</p>"},{"location":"prompts/#1-paper-to-code-replication","title":"1) Paper-to-code replication","text":"<pre><code>I want to replicate a figure from a paper.\n\nContext:\n- I will provide the paper PDF (or key equations) and my dataset.\n\nRules:\n- Start by listing all assumptions you are making.\n- Implement a minimal, reproducible script first.\n- Add unit tests or numeric spot-checks against limiting cases.\n\nDeliverables:\n- `src/` code\n- `data/README.md` describing inputs\n- `results/` with generated figure\n- `README.md` with exact run steps\n</code></pre>"},{"location":"prompts/#2-convert-my-messy-notebook-into-a-pipeline","title":"2) \"Convert my messy notebook into a pipeline\"","text":"<pre><code>Turn this notebook into a reproducible pipeline.\n\nConstraints:\n- Keep outputs identical unless you explain why they change.\n- Add a config file for parameters.\n- Pin dependencies.\n- Add a `make run` (or equivalent).\n\nDeliverables:\n- `pipeline/` or `src/`\n- `configs/`\n- `README.md`\n</code></pre>"},{"location":"prompts/#3-grantpaper-writing-assistant-safe-mode","title":"3) Grant/paper writing assistant (safe mode)","text":"<pre><code>Help me improve clarity without inventing facts.\n\nRules:\n- Do not add citations.\n- Do not change scientific claims.\n- Only propose edits that improve structure, clarity, and readability.\n\nOutput:\n- Provide a revised version and a short list of what changed.\n</code></pre>"},{"location":"publishing/","title":"Publishing as a GitHub Page","text":"<p>This repo is set up to publish an MkDocs site (nice theme, sidebar navigation, built-in search).</p>"},{"location":"publishing/#option-a-github-actions-recommended","title":"Option A: GitHub Actions (recommended)","text":"<p>This repo includes a workflow that builds MkDocs and deploys to the <code>gh-pages</code> branch:</p> <ul> <li><code>.github/workflows/deploy-mkdocs.yml</code></li> </ul> <p>Steps:</p> <ol> <li>Push to a GitHub repo.</li> <li>Ensure your default branch is <code>main</code>.</li> <li>In GitHub: Settings -&gt; Pages.</li> <li>Set Source to \"Deploy from a branch\".</li> <li>Select branch <code>gh-pages</code> and folder <code>/ (root)</code>.</li> </ol> <p>Every push to <code>main</code> will rebuild and redeploy.</p>"},{"location":"publishing/#option-b-plain-markdown-from-docs-simpler-fewer-features","title":"Option B: Plain Markdown from /docs (simpler, fewer features)","text":"<p>If you do not want a build step, GitHub Pages can render Markdown directly from <code>/docs</code>, but you lose nice navigation/search.</p> <p>Steps:</p> <ol> <li>In GitHub: Settings -&gt; Pages.</li> <li>Set Source to \"Deploy from a branch\".</li> <li>Choose your default branch and select the <code>/docs</code> folder.</li> </ol>"},{"location":"reproducibility/","title":"Reproducibility Habits (AI-Assisted Work)","text":"<p>Agentic AI can change many files quickly. Reproducibility is how you keep that power from becoming chaos.</p>"},{"location":"reproducibility/#the-minimum-bar","title":"The minimum bar","text":"<ul> <li>\"Fresh clone -&gt; one command -&gt; same key outputs.\"</li> </ul>"},{"location":"reproducibility/#what-to-capture","title":"What to capture","text":"<ul> <li>Inputs: where data came from, which version, any preprocessing</li> <li>Parameters: config files, command-line flags</li> <li>Environment: pinned dependencies, OS assumptions</li> <li>Randomness: seeds and deterministic settings</li> <li>Outputs: figures/tables written to a predictable location</li> </ul>"},{"location":"reproducibility/#two-practical-patterns","title":"Two practical patterns","text":"<ol> <li>A <code>Makefile</code> (or <code>justfile</code>) that encodes the canonical commands.</li> <li>A <code>configs/</code> folder with \"paper-ready\" configs checked into the repo.</li> </ol>"},{"location":"safety-privacy/","title":"Safety, Privacy, and Policy","text":"<p>This is the \"don't get fired / don't leak data / don't fool yourself\" page.</p>"},{"location":"safety-privacy/#defaults-recommended","title":"Defaults (recommended)","text":"<ul> <li>Don't put unpublished results, sensitive human-subject data, credentials, or embargoed material into any tool unless your institution explicitly allows it.</li> <li>Treat AI output as untrusted until you verify it.</li> <li>Prefer working in a repository with version control so you can review diffs.</li> </ul>"},{"location":"safety-privacy/#data-classification-simple-version","title":"Data classification (simple version)","text":"<p>Default to these categories:</p> <ul> <li>Public: papers, public code, public datasets</li> <li>Internal: lab notes, non-public drafts, internal docs</li> <li>Sensitive: human-subject data, patient data, credentials, export-controlled data</li> </ul> <p>Rule of thumb:</p> <ul> <li>Public is usually OK.</li> <li>Internal might be OK depending on your institution.</li> <li>Sensitive is usually NOT OK without explicit approvals and the right tooling.</li> </ul>"},{"location":"safety-privacy/#secrets","title":"Secrets","text":"<p>Never paste:</p> <ul> <li>API keys</li> <li>passwords</li> <li>private tokens</li> <li>SSH keys</li> </ul> <p>If the agent needs to access something, use environment variables or local config files that are not committed.</p>"},{"location":"safety-privacy/#human-oversight","title":"Human oversight","text":""},{"location":"safety-privacy/#human-oversight_1","title":"Human oversight","text":"<p>Even if agentic AI can do a lot, you still need to:</p> <ul> <li>inspect diffs</li> <li>run checks</li> <li>validate math and statistics</li> <li>verify citations and claims</li> </ul>"},{"location":"safety-privacy/#citations-and-factual-claims","title":"Citations and factual claims","text":"<p>Default rule:</p> <ul> <li>If you did not provide sources, assume citations can be wrong or invented.</li> </ul> <p>Better pattern:</p> <ul> <li>Provide the PDFs or URLs.</li> <li>Ask the agent to quote and attribute specific claims to specific sources.</li> </ul>"},{"location":"safety-privacy/#code-execution-safety","title":"Code execution safety","text":"<p>Agents can run commands. That is powerful and risky.</p> <p>Safe defaults:</p> <ul> <li>run in a repo, not your whole home directory</li> <li>prefer throwaway copies for early experiments</li> <li>review commands before running if you do not recognize them</li> </ul>"},{"location":"safety-privacy/#common-failure-modes","title":"Common failure modes","text":""},{"location":"safety-privacy/#common-failure-modes_1","title":"Common failure modes","text":"<ul> <li>Confident wrong answers (especially on niche domain facts)</li> <li>\"Looks right\" plots with incorrect preprocessing</li> <li>Silent changes in assumptions (units, coordinate conventions)</li> <li>Fake citations</li> </ul>"},{"location":"safety-privacy/#a-simple-policy-for-a-lab","title":"A simple policy for a lab","text":"<ul> <li>No sensitive data in external tools.</li> <li>All code changes reviewed via diff.</li> <li>All key results reproducible via a one-command run.</li> <li>All citations verified.</li> </ul>"},{"location":"scaling-up/","title":"Scaling Up Your Usage (Advanced)","text":"<p>Once you have the basics down, the biggest productivity jump comes from running multiple agent sessions in parallel.</p> <p>Example: many terminals open, each running Claude Code on a different task.</p> <p>This page explains how to scale up without losing correctness, burning money, or making a reproducibility mess.</p>"},{"location":"scaling-up/#the-core-idea","title":"The core idea","text":"<p>You are not using \"one assistant\". You are running a small team.</p> <p>That means you need:</p> <ul> <li>clear task boundaries</li> <li>a shared definition of done</li> <li>a verification step per task</li> <li>a way to merge results safely</li> </ul>"},{"location":"scaling-up/#what-parallelism-is-good-for","title":"What parallelism is good for","text":"<ul> <li>\"Do in parallel\" work:</li> <li>writing tests while another session refactors</li> <li>generating a figure script while another session cleans a dataset</li> <li>drafting paper text while another session builds a reproducible pipeline</li> <li> <p>literature summaries in parallel (paper A, paper B, paper C)</p> </li> <li> <p>\"Do not parallelize\" work:</p> </li> <li>editing the same file in multiple sessions</li> <li>changing the same experiment config from multiple places</li> <li>anything where you cannot easily compare outputs</li> </ul>"},{"location":"scaling-up/#a-practical-setup","title":"A practical setup","text":""},{"location":"scaling-up/#1-one-terminal-per-task","title":"1) One terminal per task","text":"<p>Name the job in your first message:</p> <ul> <li>\"Session A: refactor + tests\"</li> <li>\"Session B: figures\"</li> <li>\"Session C: README + reproducibility\"</li> </ul>"},{"location":"scaling-up/#2-one-branch-or-worktree-per-task","title":"2) One branch (or worktree) per task","text":"<p>If you use git, the clean approach is one branch per task.</p> <p>If you are comfortable with git worktrees, they are ideal for parallel agents. Each agent gets its own folder and can edit freely.</p> <p>Rule: never run two agents against the same working directory.</p>"},{"location":"scaling-up/#3-one-verification-command-per-task","title":"3) One verification command per task","text":"<p>Examples:</p> <ul> <li><code>pytest</code></li> <li><code>make figures</code></li> <li><code>python scripts/make_fig_2.py --config configs/fig2.yaml</code></li> </ul> <p>If the agent cannot tell you what command proves success, the task is not ready.</p>"},{"location":"scaling-up/#coordination-patterns","title":"Coordination patterns","text":""},{"location":"scaling-up/#pattern-manager-workers","title":"Pattern: manager + workers","text":"<p>One \"manager\" session:</p> <ul> <li>maintains the plan</li> <li>defines interfaces (file names, function signatures)</li> <li>reviews results from worker sessions</li> </ul> <p>Worker sessions:</p> <ul> <li>implement a specific piece</li> <li>provide diffs and the verification output</li> </ul> <p>This reduces chaos dramatically.</p>"},{"location":"scaling-up/#pattern-critique-session","title":"Pattern: critique session","text":"<p>Keep one session whose only job is:</p> <ul> <li>review diffs</li> <li>look for footguns</li> <li>propose tests</li> </ul> <p>Even if you do not run multiple agents, this pattern is worth it.</p>"},{"location":"scaling-up/#preventing-the-common-disasters","title":"Preventing the common disasters","text":""},{"location":"scaling-up/#disaster-1-two-agents-edit-the-same-file","title":"Disaster 1: two agents edit the same file","text":"<p>Fix:</p> <ul> <li>assign ownership per file</li> <li>split tasks by module</li> <li>use worktrees/branches</li> </ul>"},{"location":"scaling-up/#disaster-2-the-repo-works-but-results-changed-silently","title":"Disaster 2: the repo \"works\" but results changed silently","text":"<p>Fix:</p> <ul> <li>pin dependencies</li> <li>capture configs</li> <li>add regression checks (hashes, summary stats)</li> <li>require the agent to explain any output changes</li> </ul>"},{"location":"scaling-up/#disaster-3-cost-explodes","title":"Disaster 3: cost explodes","text":"<p>Fix:</p> <ul> <li>set a budget per day/week</li> <li>keep tasks small</li> <li>stop runaway sessions</li> <li>do not paste huge context repeatedly</li> </ul> <p>See: Cost Control</p>"},{"location":"scaling-up/#a-concrete-multi-terminal-workflow","title":"A concrete \"multi-terminal\" workflow","text":"<ol> <li>Create a task list for the next 2 hours.</li> <li>Split into 3-5 independent tasks.</li> <li>Create a new branch/worktree per task.</li> <li>Start a session per branch.</li> <li>Require each session to:</li> <li>propose a plan</li> <li>keep changes small</li> <li>run verification</li> <li>summarize what changed</li> <li>Merge one task at a time back into main.</li> </ol>"},{"location":"scaling-up/#useful-prompts","title":"Useful prompts","text":""},{"location":"scaling-up/#session-kickoff-prompt","title":"Session kickoff prompt","text":"<pre><code>You are working in parallel with other agent sessions.\n\nYour task:\n- &lt;one specific task&gt;\n\nRules:\n- Only edit files in &lt;folder/module&gt;.\n- Do not edit files owned by other sessions.\n- Propose a plan first.\n- Provide a verification command and run it.\n- End by summarizing the diff in plain English.\n</code></pre>"},{"location":"scaling-up/#manager-prompt","title":"Manager prompt","text":"<pre><code>You are the \"manager\" agent.\n\nYour job:\n- break work into independent tasks\n- assign file ownership\n- define interfaces between tasks\n- define verification commands\n\nOutput:\n- a numbered task list with owners (Session A/B/C)\n- the expected artifacts per task\n</code></pre>"},{"location":"scaling-up/#if-you-are-doing-science-not-software","title":"If you are doing science (not software)","text":"<p>The same idea applies:</p> <ul> <li>parallelize what is independent</li> <li>centralize decisions about assumptions, units, and definitions</li> <li>treat every output as untrusted until it passes checks</li> </ul>"},{"location":"setup/","title":"Setup Checklist","text":"<p>This page is intentionally practical.</p>"},{"location":"setup/#accounts-and-billing","title":"Accounts and billing","text":"<ul> <li>Pick one primary tool (recommendation: Claude Code).</li> <li>Decide who pays: you personally vs lab vs institution.</li> <li>Turn on billing alerts where possible.</li> </ul>"},{"location":"setup/#local-machine-basics","title":"Local machine basics","text":"<p>Minimum you want:</p> <ul> <li>a terminal you are comfortable using</li> <li>Python (or your language) installed</li> <li>a way to create isolated environments (venv/conda)</li> <li>git installed</li> </ul>"},{"location":"setup/#project-hygiene-do-this-once","title":"Project hygiene (do this once)","text":"<ul> <li>Put the project in a repo (git).</li> <li>Add a <code>README.md</code> with setup and the \"one command\" run.</li> <li>Add a <code>Makefile</code> or similar task runner.</li> <li>Add a tiny test / sanity check.</li> </ul>"},{"location":"setup/#your-first-guardrails","title":"Your first guardrails","text":"<p>In your first sessions, make these rules explicit:</p> <ul> <li>propose a plan before editing</li> <li>keep changes small and reviewable</li> <li>run verification commands</li> <li>do not add citations or claims you cannot verify</li> </ul>"},{"location":"setup/#if-you-are-in-a-regulated-environment","title":"If you are in a regulated environment","text":"<p>Stop and get clarity on:</p> <ul> <li>human-subject data rules</li> <li>patient/clinical data policies</li> <li>export controls / ITAR</li> <li>data retention and sharing policies</li> </ul> <p>Default safe policy: do not paste sensitive data into any external tool.</p>"},{"location":"tooling/","title":"Pick Your Tools","text":"<p>There is no single best tool. Choose based on your comfort level, your workflow, and your institution.</p>"},{"location":"tooling/#recommended-default-claude-code","title":"Recommended default: Claude Code","text":"<p>Why:</p> <ul> <li>works in a terminal (fits research workflows)</li> <li>edits files and runs commands</li> <li>good at larger refactors and multi-step tasks</li> </ul> <p>Start here: Claude Code</p> <p>If you already pay for a ChatGPT plan (Plus/Pro/Team/Edu/Enterprise), you can also use the terminal-based OpenAI Codex CLI without adding a separate Claude subscription. For many people, that is the cheapest way to get a \"Claude Code-like\" workflow.</p>"},{"location":"tooling/#alternatives-common","title":"Alternatives (common)","text":"<ul> <li>Cursor: AI-first code editor with agent features</li> <li>GitHub Copilot: agent/chat inside IDEs + GitHub</li> <li>OpenAI Codex CLI: coding agent that runs in your terminal</li> </ul>"},{"location":"tooling/#what-matters-more-than-the-tool","title":"What matters more than the tool","text":"<ul> <li>Your verification habits</li> <li>A reproducible project structure</li> <li>Good prompts that define constraints and \"done\"</li> </ul>"},{"location":"tooling/#suggested-stack-for-a-typical-lab","title":"Suggested stack for a typical lab","text":"<ul> <li>Agentic coding: Claude Code</li> <li>General assistant + deep research: whichever your institution supports</li> <li>Version control: Git + GitHub (or your institution's GitLab)</li> <li>Reproducibility: pinned environments + a one-command run</li> </ul>"},{"location":"troubleshooting/","title":"Troubleshooting","text":"<p>Agentic tools fail in predictable ways. Most fixes are workflow fixes.</p>"},{"location":"troubleshooting/#when-the-agent-thrashes","title":"When the agent \"thrashes\"","text":"<p>Symptoms:</p> <ul> <li>repeated edits without progress</li> <li>long responses that do not change the outcome</li> </ul> <p>Fix:</p> <ul> <li>stop and restate the goal</li> <li>ask for a smaller plan</li> <li>reduce scope to a minimal reproducible example</li> </ul>"},{"location":"troubleshooting/#when-results-are-wrong-but-plausible","title":"When results are wrong but plausible","text":"<p>Fix:</p> <ul> <li>add explicit sanity checks</li> <li>test on synthetic data</li> <li>require units and assumptions</li> </ul>"},{"location":"troubleshooting/#when-the-environment-breaks","title":"When the environment breaks","text":"<p>Fix:</p> <ul> <li>pin dependencies</li> <li>use a virtual environment</li> <li>add a one-command setup</li> </ul>"},{"location":"troubleshooting/#if-you-get-lost","title":"If you get lost","text":"<ul> <li>use <code>git diff</code> to see what changed</li> <li>make a commit before big changes</li> <li>revert or back out changes rather than trying to patch blindly</li> </ul>"},{"location":"verification/","title":"Verification and Rigor (How Not to Fool Yourself)","text":"<p>Agentic AI can be fast. It is not inherently careful.</p> <p>Your job is to make correctness cheap.</p>"},{"location":"verification/#what-to-verify","title":"What to verify","text":""},{"location":"verification/#code","title":"Code","text":"<ul> <li>Does it run?</li> <li>Do tests pass?</li> <li>Are edge cases handled?</li> </ul>"},{"location":"verification/#math-and-statistics","title":"Math and statistics","text":"<ul> <li>Units and dimensional analysis</li> <li>Limiting cases</li> <li>Known benchmarks</li> <li>Synthetic data tests</li> </ul>"},{"location":"verification/#plots-and-figures","title":"Plots and figures","text":"<ul> <li>Are axes labeled correctly?</li> <li>Are you plotting what you think you are plotting?</li> <li>Are preprocessing steps recorded?</li> </ul>"},{"location":"verification/#writing","title":"Writing","text":"<ul> <li>No invented citations</li> <li>Claims match the data</li> <li>Clear separation between results and speculation</li> </ul>"},{"location":"verification/#a-verification-mindset","title":"A verification mindset","text":"<p>Ask:</p> <ul> <li>What would prove this wrong?</li> <li>What is the simplest test that would catch the most likely mistake?</li> </ul>"},{"location":"verification/#cross-checking","title":"Cross-checking","text":"<p>Useful pattern:</p> <ul> <li>Use one model to propose.</li> <li>Use another model (or your own reasoning) to critique.</li> </ul> <p>But do not confuse \"two models agree\" with truth. They can share the same blind spots.</p>"},{"location":"verification/#reproducibility-is-part-of-verification","title":"Reproducibility is part of verification","text":"<p>If you cannot rerun it reliably, you cannot really verify it.</p>"},{"location":"why-agentic/","title":"Why Agentic AI (Instead of Chat)","text":"<p>Chat-only AI is useful for:</p> <ul> <li>explaining concepts</li> <li>brainstorming</li> <li>writing help</li> </ul> <p>But for real research work, the friction is often:</p> <ul> <li>your messy file system</li> <li>inconsistent scripts</li> <li>environment setup</li> <li>refactors and reproducibility</li> </ul> <p>Agentic tools reduce that friction because they can:</p> <ul> <li>inspect your project structure</li> <li>edit the actual files</li> <li>run commands (tests, scripts)</li> <li>iterate until it works</li> </ul>"},{"location":"why-agentic/#the-real-shift","title":"The real shift","text":"<p>Your job becomes less \"do every step\" and more:</p> <ul> <li>define the goal</li> <li>define constraints</li> <li>verify the result</li> </ul> <p>That is a managerial skill, not a coding trick.</p>"},{"location":"why-agentic/#when-not-to-use-agentic-ai","title":"When NOT to use agentic AI","text":"<ul> <li>Sensitive data you are not allowed to share</li> <li>High-stakes decisions without verification (clinical, safety-critical)</li> <li>Tasks where you cannot define a test or check</li> </ul> <p>If you cannot verify it, do not delegate it.</p>"},{"location":"workflows/","title":"Workflows (Plan -&gt; Do -&gt; Verify)","text":"<p>Agentic tools feel magical when you treat them like a junior colleague: they move fast, but you own correctness.</p>"},{"location":"workflows/#the-default-loop","title":"The default loop","text":"<ol> <li>Plan: ask for a short plan and the expected artifacts.</li> <li>Do: let it implement in small chunks.</li> <li>Verify: run checks (tests, plots, unit sanity checks) and review diffs.</li> <li>Record: write down what changed and how to reproduce it.</li> </ol>"},{"location":"workflows/#what-to-verify-in-science-work","title":"What to verify in science work","text":"<ul> <li>Data provenance: exactly which files/versions were used</li> <li>Determinism: fixed seeds, pinned versions, saved configs</li> <li>Sanity checks: units, limiting cases, back-of-the-envelope estimates</li> <li>Reproducibility: \"fresh clone -&gt; one command -&gt; same figures\"</li> </ul>"},{"location":"workflows/#two-example-task-prompts","title":"Two example task prompts","text":""},{"location":"workflows/#reproducible-analysis","title":"Reproducible analysis","text":"<pre><code>You are helping me make this analysis reproducible.\n\nRules:\n- Propose a plan first.\n- Do not change scientific logic without asking.\n- Add a single command that reproduces the main figure(s).\n- Add quick sanity checks (units, basic invariants).\n\nGoal:\n- When I run `make figures` (or similar), it produces the same outputs.\n</code></pre>"},{"location":"workflows/#take-over-the-annoying-parts","title":"\"Take over the annoying parts\"","text":"<pre><code>Please refactor this project so a new lab member can run it.\n\nDeliverables:\n- README with setup + one-command run\n- pinned dependencies\n- scripts organized into a minimal pipeline\n- a short checklist for verifying outputs are sensible\n</code></pre>"},{"location":"writing/","title":"Writing and Grants","text":"<p>AI is very good at clarity and structure. It is also very good at sounding confident while being wrong.</p>"},{"location":"writing/#safe-uses","title":"Safe uses","text":"<ul> <li>rewrite for clarity</li> <li>improve structure</li> <li>tighten abstract/intro</li> <li>generate outlines</li> </ul>"},{"location":"writing/#risky-uses","title":"Risky uses","text":"<ul> <li>adding claims</li> <li>adding citations</li> <li>summarizing things you did not provide as sources</li> </ul>"},{"location":"writing/#a-workflow-that-works","title":"A workflow that works","text":"<ol> <li>You provide the facts (results, figures, key points).</li> <li>The AI improves clarity and structure.</li> <li>You verify every claim.</li> </ol>"},{"location":"writing/#a-good-prompt","title":"A good prompt","text":"<pre><code>Edit for clarity and structure only.\n\nRules:\n- Do not add citations.\n- Do not change scientific claims.\n- If something is unclear, ask questions instead of guessing.\n</code></pre>"}]}